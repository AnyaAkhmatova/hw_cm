{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778},{"sourceId":7190288,"sourceType":"datasetVersion","datasetId":4157447},{"sourceId":7191819,"sourceType":"datasetVersion","datasetId":4158630},{"sourceId":7200398,"sourceType":"datasetVersion","datasetId":4164847}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/cm-project-exp/cm_project/. .\n!pip install -r requirements.txt\n!pip install .\nimport wandb\nwandb.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T08:20:14.191717Z","iopub.execute_input":"2023-12-14T08:20:14.191998Z","iopub.status.idle":"2023-12-14T08:21:49.760972Z","shell.execute_reply.started":"2023-12-14T08:20:14.191973Z","shell.execute_reply":"2023-12-14T08:21:49.760091Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.0.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.24.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.0.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.4)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.5.16)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.16.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (2023.11.17)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (2.31.0)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (6.0.0)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (3.1.32)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.38.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (3.20.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->-r requirements.txt (line 8)) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->-r requirements.txt (line 8)) (3.4)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->-r requirements.txt (line 8)) (0.5.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->-r requirements.txt (line 8)) (1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (5.0.0)\nProcessing /kaggle/working\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: hw-cm\n  Building wheel for hw-cm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hw-cm: filename=hw_cm-0.0-py3-none-any.whl size=18053 sha256=ed08fcdead80052698248657ced7f59d5e705238fe266aa441cf515c26051a83\n  Stored in directory: /tmp/pip-ephem-wheel-cache-6dm8g900/wheels/f5/8c/ca/4f95231da13b8fb9207b24da4e2d5b53ed7cee9f9f88bb6cc5\nSuccessfully built hw-cm\nInstalling collected packages: hw-cm\nSuccessfully installed hw-cm-0.0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!python3 train.py -c ./hw_cm/configs/exp1.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T08:30:05.265570Z","iopub.execute_input":"2023-12-13T08:30:05.266474Z","iopub.status.idle":"2023-12-13T11:43:28.596396Z","shell.execute_reply.started":"2023-12-13T08:30:05.266436Z","shell.execute_reply":"2023-12-13T11:43:28.595204Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_083016-z0rb797u\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrare-bee-4\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/z0rb797u\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.693130\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:38<01:40,  5.95it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.357818\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:11<01:06,  5.96it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.116876\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:44<00:33,  5.96it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.066045\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:18<00:00,  6.04it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.208977\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:18<00:00,  5.73it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 1\n    loss           : 0.15795796288346703\n    grad norm      : 9.347480121134508\n    accuracy       : 0.9480744949494949\n    dev_loss       : 0.16024398792743624\n    dev_accuracy   : 0.946415165216306\n    dev_eer        : 0.08085712342401563\n    dev_frr        : 0.08084772370486656\n    dev_far        : 0.0808665231431647\n    dev_thr        : 0.1944974809885025\n    eval_loss      : 0.30543564619403624\n    eval_accuracy  : 0.9155674674449933\n    eval_eer       : 0.10047900285049267\n    eval_frr       : 0.10047586675730795\n    eval_far       : 0.1004821389436774\n    eval_thr       : 0.24890606105327606\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.051445\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.029861\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.042633\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.013133\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.145163\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.81it/s]\n    epoch          : 2\n    loss           : 0.10705091578020441\n    grad norm      : 6.920652091277368\n    accuracy       : 0.9640151515151515\n    dev_loss       : 0.09416580074835339\n    dev_accuracy   : 0.9651034963790668\n    dev_eer        : 0.06270323812227549\n    dev_frr        : 0.06279434850863422\n    dev_far        : 0.06261212773591676\n    dev_thr        : 0.12955285608768463\n    eval_loss      : 0.24617575859541402\n    eval_accuracy  : 0.9475415357036017\n    eval_eer       : 0.07301058411762798\n    eval_frr       : 0.07301155676410605\n    eval_far       : 0.07300961147114993\n    eval_thr       : 0.2407274693250656\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.037159\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.005849\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.044397\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.078393\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.024064\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 3\n    loss           : 0.08417629860129884\n    grad norm      : 5.770148353293688\n    accuracy       : 0.9745896464646465\n    dev_loss       : 0.0862332142174377\n    dev_accuracy   : 0.968884062659633\n    dev_eer        : 0.044353120481445865\n    dev_frr        : 0.04434850863422292\n    dev_far        : 0.04435773232866882\n    dev_thr        : 0.20845377445220947\n    eval_loss      : 0.2063303965947423\n    eval_accuracy  : 0.9344634036874364\n    eval_eer       : 0.06635307118233437\n    eval_frr       : 0.0663494221617947\n    eval_far       : 0.06635672020287404\n    eval_thr       : 0.48023876547813416\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.032309\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.141600\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.090732\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.051617\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.00it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.033335\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.81it/s]\n    epoch          : 4\n    loss           : 0.06731248210358311\n    grad norm      : 4.606886176524138\n    accuracy       : 0.9791666666666666\n    dev_loss       : 0.16111068952690205\n    dev_accuracy   : 0.9423396611152315\n    dev_eer        : 0.04397748376488958\n    dev_frr        : 0.04395604395604396\n    dev_far        : 0.0439989235737352\n    dev_thr        : 0.7078841328620911\n    eval_loss      : 0.23144209588370585\n    eval_accuracy  : 0.9028682083520431\n    eval_eer       : 0.06529264602004235\n    eval_frr       : 0.06526172671651938\n    eval_far       : 0.06532356532356533\n    eval_thr       : 0.8942129611968994\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.014510\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.003456\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.041539\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.020494\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.007908\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 5\n    loss           : 0.04811295068727552\n    grad norm      : 4.309674114722646\n    accuracy       : 0.985479797979798\n    dev_loss       : 0.0975116524868435\n    dev_accuracy   : 0.9651437151692855\n    dev_eer        : 0.050632414512546756\n    dev_frr        : 0.05062794348508634\n    dev_far        : 0.05063688554000718\n    dev_thr        : 0.14523433148860931\n    eval_loss      : 0.22987775638903193\n    eval_accuracy  : 0.9284912438257746\n    eval_eer       : 0.07042750217722764\n    eval_frr       : 0.07042828008157716\n    eval_far       : 0.07042672427287812\n    eval_thr       : 0.521007776260376\nSaving checkpoint: saved/models/exp1_hints_no_abs/1213_083010/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.165897\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.009514\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.016934\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.440577\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.002778\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 6\n    loss           : 0.03875093057124306\n    grad norm      : 2.807195784152495\n    accuracy       : 0.9870580808080808\n    dev_loss       : 0.09250476776072634\n    dev_accuracy   : 0.9744342557098261\n    dev_eer        : 0.04278329697367065\n    dev_frr        : 0.04277864992150707\n    dev_far        : 0.04278794402583423\n    dev_thr        : 0.09294168651103973\n    eval_loss      : 0.27996144671126183\n    eval_accuracy  : 0.9214470139200719\n    eval_eer       : 0.06718361124312074\n    eval_frr       : 0.0671651937457512\n    eval_far       : 0.06720202874049028\n    eval_thr       : 0.7478477954864502\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.018836\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.009254\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.077686\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.008123\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.001611\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 7\n    loss           : 0.028298656151170203\n    grad norm      : 2.4324870390742266\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.05128923466512193\n    dev_accuracy   : 0.985145860197001\n    dev_eer        : 0.02991634883646263\n    dev_frr        : 0.029827315541601257\n    dev_far        : 0.030005382131324004\n    dev_thr        : 0.02128213830292225\n    eval_loss      : 0.22440673652552295\n    eval_accuracy  : 0.9344549842837898\n    eval_eer       : 0.05941871156011197\n    eval_frr       : 0.05941536369816451\n    eval_far       : 0.05942205942205942\n    eval_thr       : 0.6786489486694336\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.001751\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:34<01:40,  5.92it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.009365\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.006312\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:41<00:33,  5.94it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.006366\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.03it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.002335\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.89it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 8\n    loss           : 0.023297967741411706\n    grad norm      : 2.6019605400247707\n    accuracy       : 0.9917929292929293\n    dev_loss       : 0.060806771926083684\n    dev_accuracy   : 0.9824512012523421\n    dev_eer        : 0.03022470891146887\n    dev_frr        : 0.03021978021978022\n    dev_far        : 0.030229637603157517\n    dev_thr        : 0.00551249086856842\n    eval_loss      : 0.22561662828075718\n    eval_accuracy  : 0.9441232599910193\n    eval_eer       : 0.058311324812396814\n    eval_frr       : 0.05832766825288919\n    eval_far       : 0.05829498137190445\n    eval_thr       : 0.40665295720100403\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.033667\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.004885\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000743\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.049102\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.008118\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 9\n    loss           : 0.02059467922273795\n    grad norm      : 3.021106075784756\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.6220050067200351\n    dev_accuracy   : 0.861191548694745\n    dev_eer        : 0.07614765290068996\n    dev_frr        : 0.076138147566719\n    dev_far        : 0.07615715823466093\n    dev_thr        : 0.9926961660385132\n    eval_loss      : 0.4130951670482738\n    eval_accuracy  : 0.8529411764705882\n    eval_eer       : 0.08767853569924375\n    eval_frr       : 0.08769544527532291\n    eval_far       : 0.08766162612316458\n    eval_thr       : 0.9914208650588989\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.014032\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.074891\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.91it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.002788\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.003047\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.002903\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 10\n    loss           : 0.024724181147934305\n    grad norm      : 2.5351631928122407\n    accuracy       : 0.991635101010101\n    dev_loss       : 0.04077480628081457\n    dev_accuracy   : 0.9855346418102122\n    dev_eer        : 0.022728802541965697\n    dev_frr        : 0.022762951334379906\n    dev_far        : 0.02269465374955149\n    dev_thr        : 0.10061216354370117\n    eval_loss      : 0.17950082630043257\n    eval_accuracy  : 0.9365878985181859\n    eval_eer       : 0.05494466439663323\n    eval_frr       : 0.054928619986403804\n    eval_far       : 0.05496070880686265\n    eval_thr       : 0.6949900984764099\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.007222\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.90it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.005762\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.000625\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.000610\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.054868\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 11\n    loss           : 0.027324221269387782\n    grad norm      : 2.737868460124556\n    accuracy       : 0.9925820707070707\n    dev_loss       : 0.08151867136593993\n    dev_accuracy   : 0.9765390390901799\n    dev_eer        : 0.03880267433627421\n    dev_frr        : 0.03885400313971742\n    dev_far        : 0.038751345532831\n    dev_thr        : 0.1126243844628334\n    eval_loss      : 0.25267793276951983\n    eval_accuracy  : 0.9262039739559946\n    eval_eer       : 0.06242489046180935\n    eval_frr       : 0.06240652617267165\n    eval_far       : 0.06244325475094706\n    eval_thr       : 0.7708821296691895\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.002338\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.002941\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.009192\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000123\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.003745\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 12\n    loss           : 0.015795312857767155\n    grad norm      : 1.618384150908719\n    accuracy       : 0.9952651515151515\n    dev_loss       : 0.0726998029813389\n    dev_accuracy   : 0.980024667550238\n    dev_eer        : 0.020009643337338248\n    dev_frr        : 0.020015698587127158\n    dev_far        : 0.020003588087549335\n    dev_thr        : 0.48752152919769287\n    eval_loss      : 0.29475513435635703\n    eval_accuracy  : 0.9102492141894926\n    eval_eer       : 0.05394439326876706\n    eval_frr       : 0.0539768864717879\n    eval_far       : 0.05391190006574622\n    eval_thr       : 0.9938545227050781\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.002575\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.001249\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.002378\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.001420\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.006329\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 13\n    loss           : 0.019378444463140427\n    grad norm      : 1.5268000536010309\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.04917660928490132\n    dev_accuracy   : 0.9832019519775224\n    dev_eer        : 0.0255152383881432\n    dev_frr        : 0.025510204081632654\n    dev_far        : 0.02552027269465375\n    dev_thr        : 0.09216136485338211\n    eval_loss      : 0.1602410703301965\n    eval_accuracy  : 0.9395767849124382\n    eval_eer       : 0.054007008715997895\n    eval_frr       : 0.0539768864717879\n    eval_far       : 0.05403713096020788\n    eval_thr       : 0.6398685574531555\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.006169\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.000229\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000401\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.003616\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.002967\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 14\n    loss           : 0.023907892483303023\n    grad norm      : 1.9390194009133437\n    accuracy       : 0.9935290404040404\n    dev_loss       : 0.049670989491285795\n    dev_accuracy   : 0.9820758258513962\n    dev_eer        : 0.02748312415965807\n    dev_frr        : 0.027472527472527472\n    dev_far        : 0.027493720846788663\n    dev_thr        : 0.1339544951915741\n    eval_loss      : 0.18571692731691572\n    eval_accuracy  : 0.9288981814099686\n    eval_eer       : 0.05748078475161046\n    eval_frr       : 0.0575118966689327\n    eval_far       : 0.05744967283428822\n    eval_thr       : 0.7830102443695068\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.026879\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.003594\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.002576\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.034019\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.001979\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 15\n    loss           : 0.02169008961157883\n    grad norm      : 1.6092639607847716\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.04354125466661068\n    dev_accuracy   : 0.9878673316429021\n    dev_eer        : 0.02345765042789493\n    dev_frr        : 0.023547880690737835\n    dev_far        : 0.023367420165052027\n    dev_thr        : 0.2557547390460968\n    eval_loss      : 0.20958315313944897\n    eval_accuracy  : 0.9156376290974405\n    eval_eer       : 0.05832697867420453\n    eval_frr       : 0.05832766825288919\n    eval_far       : 0.058326289095519866\n    eval_thr       : 0.8266415596008301\nSaving checkpoint: saved/models/exp1_hints_no_abs/1213_083010/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.015770\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.86it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000739\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.003510\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.032054\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  5.99it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.002579\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:50<00:00,  9.68it/s]\n    epoch          : 16\n    loss           : 0.02310998571111769\n    grad norm      : 2.2468197961700045\n    accuracy       : 0.9935290404040404\n    dev_loss       : 0.07529502508232455\n    dev_accuracy   : 0.9799308236808236\n    dev_eer        : 0.027858760876214358\n    dev_frr        : 0.027864992150706435\n    dev_far        : 0.02785252960172228\n    dev_thr        : 0.10477790981531143\n    eval_loss      : 0.28894056794530537\n    eval_accuracy  : 0.909323080377189\n    eval_eer       : 0.0680977861310445\n    eval_frr       : 0.0681169272603671\n    eval_far       : 0.06807864500172192\n    eval_thr       : 0.9369708299636841\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.002720\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.072553\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.001026\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000854\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000568\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 17\n    loss           : 0.017303807366518258\n    grad norm      : 1.4830225982063572\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.038193096889110746\n    dev_accuracy   : 0.990226833976834\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.010737010277807713\n    eval_loss      : 0.20279526475067192\n    eval_accuracy  : 0.9435984508360669\n    eval_eer       : 0.04841774787390015\n    eval_frr       : 0.04840244731475187\n    eval_far       : 0.04843304843304843\n    eval_thr       : 0.7837556004524231\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000284\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000110\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.001594\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.001856\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000167\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 18\n    loss           : 0.005101677895410574\n    grad norm      : 0.7657707072841474\n    accuracy       : 0.9982638888888888\n    dev_loss       : 0.04477015110940069\n    dev_accuracy   : 0.9900659588159588\n    dev_eer        : 0.018439819829563026\n    dev_frr        : 0.018445839874411302\n    dev_far        : 0.01843379978471475\n    dev_thr        : 0.002660053549334407\n    eval_loss      : 0.262154764088155\n    eval_accuracy  : 0.9381174225415357\n    eval_eer       : 0.045518684592051745\n    eval_frr       : 0.045547246770904146\n    eval_far       : 0.04549012241319934\n    eval_thr       : 0.9710672497749329\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.000183\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.004324\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.025217\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.001393\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.000193\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 19\n    loss           : 0.008791902189088175\n    grad norm      : 0.778701835329\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.05208585706237907\n    dev_accuracy   : 0.9856955169710874\n    dev_eer        : 0.023194141447255394\n    dev_frr        : 0.02315541601255887\n    dev_far        : 0.02323286688195192\n    dev_thr        : 0.06073298305273056\n    eval_loss      : 0.26287869396477836\n    eval_accuracy  : 0.9261618769645262\n    eval_eer       : 0.050577732853003474\n    eval_frr       : 0.05057783820530252\n    eval_far       : 0.05057762750070442\n    eval_thr       : 0.9750667214393616\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000280\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000078\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.001292\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.89it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000695\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000162\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 20\n    loss           : 0.006530098289989506\n    grad norm      : 0.5494798758229467\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.05397451581582905\n    dev_accuracy   : 0.986969111969112\n    dev_eer        : 0.025913300651882847\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.025923932543954073\n    dev_thr        : 0.009933332912623882\n    eval_loss      : 0.2976786672646387\n    eval_accuracy  : 0.9347356308935788\n    eval_eer       : 0.0585881714993256\n    eval_frr       : 0.058599592114208024\n    eval_far       : 0.05857675088444319\n    eval_thr       : 0.7479523420333862\nSaving checkpoint: saved/models/exp1_hints_no_abs/1213_083010/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000394\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000130\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.046275\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.002935\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000122\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 21\n    loss           : 0.00743386493441637\n    grad norm      : 0.6585875795977755\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.06117890646058969\n    dev_accuracy   : 0.9877734877734877\n    dev_eer        : 0.02987149774209593\n    dev_frr        : 0.029827315541601257\n    dev_far        : 0.0299156799425906\n    dev_thr        : 0.0006455849506892264\n    eval_loss      : 0.26656486384089273\n    eval_accuracy  : 0.9522002694260983\n    eval_eer       : 0.05032436695878624\n    eval_frr       : 0.05030591434398368\n    eval_far       : 0.050342819573588805\n    eval_thr       : 0.3368857502937317\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000181\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.001024\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.004856\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.001770\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000121\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 22\n    loss           : 0.004476268428389272\n    grad norm      : 0.7191722906450976\n    accuracy       : 0.9981060606060606\n    dev_loss       : 0.04559317200798117\n    dev_accuracy   : 0.9882695195450899\n    dev_eer        : 0.015698235077752223\n    dev_frr        : 0.015698587127158554\n    dev_far        : 0.01569788302834589\n    dev_thr        : 0.19092127680778503\n    eval_loss      : 0.26116093417399944\n    eval_accuracy  : 0.9293752806466098\n    eval_eer       : 0.04337435347475613\n    eval_frr       : 0.0433718558803535\n    eval_far       : 0.04337685106915876\n    eval_thr       : 0.9932795166969299\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.008433\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000301\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.90it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000470\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.001206\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000982\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 23\n    loss           : 0.009688415927439105\n    grad norm      : 0.8206037992806728\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.045680809068206006\n    dev_accuracy   : 0.9914736164736164\n    dev_eer        : 0.02668699963217878\n    dev_frr        : 0.026687598116169546\n    dev_far        : 0.026686401148188016\n    dev_thr        : 0.0009490465745329857\n    eval_loss      : 0.2253738988173861\n    eval_accuracy  : 0.9496099012123933\n    eval_eer       : 0.04418141274283093\n    eval_frr       : 0.04418762746430999\n    eval_far       : 0.04417519802135187\n    eval_thr       : 0.7724578380584717\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.000417\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.114621\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.002210\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.001139\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.002062\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:52<00:00,  9.57it/s]\n    epoch          : 24\n    loss           : 0.020769664996263638\n    grad norm      : 1.8581466063436103\n    accuracy       : 0.9943181818181818\n    dev_loss       : 0.04971203527431962\n    dev_accuracy   : 0.98371138996139\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.17582520842552185\n    eval_loss      : 0.24947480950537212\n    eval_accuracy  : 0.9200999101930849\n    eval_eer       : 0.05818855533074013\n    eval_frr       : 0.05819170632222977\n    eval_far       : 0.05818540433925049\n    eval_thr       : 0.9313293099403381\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.002369\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000329\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000303\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.96it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.000149\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.000423\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 25\n    loss           : 0.01500959914891141\n    grad norm      : 1.1717613474895114\n    accuracy       : 0.9958964646464646\n    dev_loss       : 0.0352453711952753\n    dev_accuracy   : 0.9913529601029601\n    dev_eer        : 0.016185999530225273\n    dev_frr        : 0.01609105180533752\n    dev_far        : 0.016280947255113025\n    dev_thr        : 0.001107446034438908\n    eval_loss      : 0.19423618698594516\n    eval_accuracy  : 0.9536175348055326\n    eval_eer       : 0.046226455171181416\n    eval_frr       : 0.046227056424201225\n    eval_far       : 0.046225853918161613\n    eval_thr       : 0.5064396858215332\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 26 [0/794 (0%)] Loss: 0.002947\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 26 [198/794 (25%)] Loss: 0.010728\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 26 [396/794 (50%)] Loss: 0.001063\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.94it/s]Train Epoch: 26 [594/794 (75%)] Loss: 0.000192\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.08it/s]Train Epoch: 26 [792/794 (100%)] Loss: 0.000497\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 26\n    loss           : 0.005701112046649955\n    grad norm      : 0.5511123988474014\n    accuracy       : 0.9982638888888888\n    dev_loss       : 0.039665149716068694\n    dev_accuracy   : 0.9894894895406303\n    dev_eer        : 0.018064183113006733\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018074991029781128\n    dev_thr        : 0.03827996924519539\n    eval_loss      : 0.23481629179034347\n    eval_accuracy  : 0.9325044903457567\n    eval_eer       : 0.04691074495759953\n    eval_frr       : 0.0469068660774983\n    eval_far       : 0.04691462383770076\n    eval_thr       : 0.9742523431777954\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 27 [0/794 (0%)] Loss: 0.000285\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 27 [198/794 (25%)] Loss: 0.002690\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 27 [396/794 (50%)] Loss: 0.000576\ntrain:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 413/794 [01:09<01:03,  5.96it/s]^C\nException in thread Thread-82 (_pin_memory_loop):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n    do_one_step()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n    fd = df.detach()\n  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n    with _resource_sharer.get_connection(self._id) as conn:\n  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n    c = Client(address, authkey=process.current_process().authkey)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n    c = SocketClient(address)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n    s.connect(address)\nFileNotFoundError: [Errno 2] No such file or directory\ntrain:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 413/794 [01:10<01:04,  5.90it/s]\nSaving model on keyboard interrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp3.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:46:10.531206Z","iopub.execute_input":"2023-12-13T11:46:10.532131Z","iopub.status.idle":"2023-12-13T16:38:00.357686Z","shell.execute_reply.started":"2023-12-13T11:46:10.532095Z","shell.execute_reply":"2023-12-13T16:38:00.356624Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(512, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_114616-xyub597e\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgraceful-disco-6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/xyub597e\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.707216\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:17<03:48,  2.60it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.438846\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:34<02:33,  2.60it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.082436\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:50<01:16,  2.61it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.257733\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.61it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.094030\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 1\n    loss           : 0.13802271653578213\n    grad norm      : 4.818329669459902\n    accuracy       : 0.9524936868686869\n    dev_loss       : 0.1065720329906173\n    dev_accuracy   : 0.9640444015444015\n    dev_eer        : 0.05808346978768322\n    dev_frr        : 0.058084772370486655\n    dev_far        : 0.0580821672048798\n    dev_thr        : 0.18743324279785156\n    eval_loss      : 0.20272232656842612\n    eval_accuracy  : 0.9270459137853615\n    eval_eer       : 0.07520187682034672\n    eval_frr       : 0.0751869476546567\n    eval_far       : 0.07521680598603675\n    eval_thr       : 0.4595956802368164\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.127807\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.021507\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.60it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.100064\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:48<01:17,  2.60it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.094627\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.62it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.380685\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:05<00:00,  2.60it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 2\n    loss           : 0.07614742892893088\n    grad norm      : 2.982955706653872\n    accuracy       : 0.9772727272727273\n    dev_loss       : 0.3127143595185181\n    dev_accuracy   : 0.911009223534794\n    dev_eer        : 0.03847188871408462\n    dev_frr        : 0.038461538461538464\n    dev_far        : 0.038482238966630784\n    dev_thr        : 0.97599196434021\n    eval_loss      : 0.2959699157458577\n    eval_accuracy  : 0.8961326897171082\n    eval_eer       : 0.05414543205946229\n    eval_frr       : 0.05411284840244732\n    eval_far       : 0.054178015716477256\n    eval_thr       : 0.9932281374931335\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.002043\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:48,  2.60it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.194704\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.60it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.035778\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.011876\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.016851\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:05<00:00,  2.60it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 3\n    loss           : 0.07470250230710578\n    grad norm      : 3.700335103134164\n    accuracy       : 0.9717487373737373\n    dev_loss       : 0.05342315962373164\n    dev_accuracy   : 0.9806011369022777\n    dev_eer        : 0.02511717612440356\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.025116612845353426\n    dev_thr        : 0.21711373329162598\n    eval_loss      : 0.16942816688056048\n    eval_accuracy  : 0.9359143466546924\n    eval_eer       : 0.04797117011989155\n    eval_frr       : 0.04799456152277362\n    eval_far       : 0.04794777871700948\n    eval_thr       : 0.8650938272476196\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.047877\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:20<07:47,  1.28it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.003448\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:36<02:33,  2.60it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.022529\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:53<01:17,  2.59it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.002529\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:09<00:00,  2.61it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.328331\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:10<00:00,  2.56it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.73it/s]\n    epoch          : 4\n    loss           : 0.05584775056922808\n    grad norm      : 1.8330086969177832\n    accuracy       : 0.9834280303030303\n    dev_loss       : 0.06891354329810936\n    dev_accuracy   : 0.9753190690946395\n    dev_eer        : 0.04081541120215578\n    dev_frr        : 0.04081632653061224\n    dev_far        : 0.04081449587369932\n    dev_thr        : 0.07520519196987152\n    eval_loss      : 0.20838468373708383\n    eval_accuracy  : 0.9453581050740907\n    eval_eer       : 0.0685287100232454\n    eval_frr       : 0.06852481305234534\n    eval_far       : 0.06853260699414546\n    eval_thr       : 0.24038252234458923\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.016824\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.004195\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.59it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.199323\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.143779\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.003195\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:05<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.72it/s]\n    epoch          : 5\n    loss           : 0.04897541074538509\n    grad norm      : 1.6595597422183161\n    accuracy       : 0.9853219696969697\n    dev_loss       : 0.0451349800818654\n    dev_accuracy   : 0.9849179536679536\n    dev_eer        : 0.024253774955374216\n    dev_frr        : 0.02433281004709576\n    dev_far        : 0.024174739863652674\n    dev_thr        : 0.019040022045373917\n    eval_loss      : 0.20133126732232748\n    eval_accuracy  : 0.9510973282442748\n    eval_eer       : 0.058334805605108384\n    eval_frr       : 0.05832766825288919\n    eval_far       : 0.05834194295732757\n    eval_thr       : 0.19826391339302063\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.002054\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.006234\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.027764\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.60it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.003905\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.61it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.076888\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 6\n    loss           : 0.04850717147032029\n    grad norm      : 2.1417451148142455\n    accuracy       : 0.9848484848484849\n    dev_loss       : 0.13589508210304654\n    dev_accuracy   : 0.9584137709137709\n    dev_eer        : 0.11307214365418272\n    dev_frr        : 0.1130298273155416\n    dev_far        : 0.11311445999282382\n    dev_thr        : 0.023873835802078247\n    eval_loss      : 0.36155857972204386\n    eval_accuracy  : 0.9482712168890529\n    eval_eer       : 0.09503599228276319\n    eval_frr       : 0.09503738953093134\n    eval_far       : 0.09503459503459503\n    eval_thr       : 0.08622931689023972\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.008199\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.001974\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:34,  2.58it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.002424\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.60it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.004444\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.024737\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:54<00:00,  7.56it/s]\n    epoch          : 7\n    loss           : 0.032594886648255834\n    grad norm      : 1.3547443393900087\n    accuracy       : 0.9913194444444444\n    dev_loss       : 0.03816952830052574\n    dev_accuracy   : 0.9889532389788094\n    dev_eer        : 0.01609629734149187\n    dev_frr        : 0.01609105180533752\n    dev_far        : 0.016101542877646216\n    dev_thr        : 0.28222566843032837\n    eval_loss      : 0.1726922825383224\n    eval_accuracy  : 0.9292349573417154\n    eval_eer       : 0.049478173036192175\n    eval_frr       : 0.049490142760027195\n    eval_far       : 0.04946620331235716\n    eval_thr       : 0.8966513276100159\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.010012\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.044534\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.60it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.000991\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.396976\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.61it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.001114\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 8\n    loss           : 0.022403955138203185\n    grad norm      : 1.071773297440336\n    accuracy       : 0.9917929292929293\n    dev_loss       : 0.02855838764315445\n    dev_accuracy   : 0.9919160231660231\n    dev_eer        : 0.01255858806220178\n    dev_frr        : 0.012558869701726845\n    dev_far        : 0.012558306422676713\n    dev_thr        : 0.007042485289275646\n    eval_loss      : 0.21061666776498567\n    eval_accuracy  : 0.9472103726986978\n    eval_eer       : 0.04868676762992508\n    eval_frr       : 0.0486743711760707\n    eval_far       : 0.048699164083779466\n    eval_thr       : 0.7073972821235657\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.009780\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.004112\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.59it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.001646\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.60it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.001594\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:09<00:00,  2.61it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.074839\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:09<00:00,  2.56it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.72it/s]\n    epoch          : 9\n    loss           : 0.043393213268383544\n    grad norm      : 1.705672572573854\n    accuracy       : 0.9881628787878788\n    dev_loss       : 0.46403305600926176\n    dev_accuracy   : 0.8186668811924516\n    dev_eer        : 0.032966293663279675\n    dev_frr        : 0.03296703296703297\n    dev_far        : 0.032965554359526375\n    dev_thr        : 0.9771864414215088\n    eval_loss      : 0.3768706700020626\n    eval_accuracy  : 0.8268213965028832\n    eval_eer       : 0.061179080370629815\n    eval_frr       : 0.061182868796736914\n    eval_far       : 0.06117529194452272\n    eval_thr       : 0.9895403981208801\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.086698\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.003970\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.001664\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.000609\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.003021\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 10\n    loss           : 0.016036930329088744\n    grad norm      : 0.7588518463049291\n    accuracy       : 0.9951073232323232\n    dev_loss       : 0.07584593799161114\n    dev_accuracy   : 0.9797833548089252\n    dev_eer        : 0.02699535970718502\n    dev_frr        : 0.02708006279434851\n    dev_far        : 0.02691065662002153\n    dev_thr        : 0.11086203902959824\n    eval_loss      : 0.22690325555831553\n    eval_accuracy  : 0.9232852492141895\n    eval_eer       : 0.06347748869319753\n    eval_frr       : 0.06349422161794697\n    eval_far       : 0.06346075576844808\n    eval_thr       : 0.8405252695083618\nSaving checkpoint: saved/models/exp3_hints_no_abs_no_2021_style/1213_114614/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.003641\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000181\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.006605\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.001601\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.008389\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 11\n    loss           : 0.02857249540293288\n    grad norm      : 1.0922092460566248\n    accuracy       : 0.990530303030303\n    dev_loss       : 0.1055898057274623\n    dev_accuracy   : 0.9587757400257401\n    dev_eer        : 0.01923594435704231\n    dev_frr        : 0.019230769230769232\n    dev_far        : 0.019241119483315392\n    dev_thr        : 0.864183247089386\n    eval_loss      : 0.22346042039588582\n    eval_accuracy  : 0.8905899191737764\n    eval_eer       : 0.045680588728227695\n    eval_frr       : 0.04568320870156356\n    eval_far       : 0.04567796875489183\n    eval_thr       : 0.9745722413063049\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.005946\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.010923\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.004572\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.58it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.001153\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.029397\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:41<00:00,  7.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:49<00:00,  7.68it/s]\n    epoch          : 12\n    loss           : 0.019330137461671403\n    grad norm      : 0.9170411350323132\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.02660727313429925\n    dev_accuracy   : 0.9910848348604052\n    dev_eer        : 0.014924536097456288\n    dev_frr        : 0.014913657770800628\n    dev_far        : 0.014935414424111948\n    dev_thr        : 0.1310126632452011\n    eval_loss      : 0.15546534036845094\n    eval_accuracy  : 0.9415974405029187\n    eval_eer       : 0.04160615773333443\n    eval_frr       : 0.0416043507817811\n    eval_far       : 0.04160796468488776\n    eval_thr       : 0.8915286660194397\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.002497\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:17<03:50,  2.59it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.001784\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.60it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.244845\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:50<01:17,  2.59it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.030285\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.61it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.000557\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:49<00:00,  7.70it/s]\n    epoch          : 13\n    loss           : 0.01096491955626095\n    grad norm      : 0.41498519558309005\n    accuracy       : 0.9984217171717171\n    dev_loss       : 0.035728223703575694\n    dev_accuracy   : 0.9909239596995301\n    dev_eer        : 0.023149290352888693\n    dev_frr        : 0.02315541601255887\n    dev_far        : 0.023143164693218515\n    dev_thr        : 0.00652045663446188\n    eval_loss      : 0.1938157634650163\n    eval_accuracy  : 0.9431690615177368\n    eval_eer       : 0.04554999231566716\n    eval_frr       : 0.045547246770904146\n    eval_far       : 0.04555273786043017\n    eval_thr       : 0.8581167459487915\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.114190\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.001061\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.024539\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000900\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.60it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.001283\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 14\n    loss           : 0.02593347627855955\n    grad norm      : 0.9746213375045119\n    accuracy       : 0.9933712121212122\n    dev_loss       : 0.029284811408562823\n    dev_accuracy   : 0.9916344916344917\n    dev_eer        : 0.014526473833716644\n    dev_frr        : 0.014521193092621664\n    dev_far        : 0.014531754574811625\n    dev_thr        : 0.007790320552885532\n    eval_loss      : 0.2144578979215889\n    eval_accuracy  : 0.9430427705433319\n    eval_eer       : 0.05452156743533619\n    eval_frr       : 0.05452073419442556\n    eval_far       : 0.05452240067624683\n    eval_thr       : 0.6024900674819946\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.002294\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.000652\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.60it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.002777\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.000131\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000941\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:49<00:00,  7.71it/s]\n    epoch          : 15\n    loss           : 0.01697129606658233\n    grad norm      : 1.0176856366146092\n    accuracy       : 0.9940025252525253\n    dev_loss       : 0.03983326780629189\n    dev_accuracy   : 0.9906290218790219\n    dev_eer        : 0.022375591372592755\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.02238069608898457\n    dev_thr        : 0.008947530761361122\n    eval_loss      : 0.24093695234535395\n    eval_accuracy  : 0.9343006286484059\n    eval_eer       : 0.0527533716939145\n    eval_frr       : 0.052753229095853164\n    eval_far       : 0.052753514291975834\n    eval_thr       : 0.9169974327087402\nSaving checkpoint: saved/models/exp3_hints_no_abs_no_2021_style/1213_114614/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.000444\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.049632\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.60it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.009353\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:16,  2.60it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000589\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:06<00:00,  2.61it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.001406\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:49<00:00,  7.70it/s]\n    epoch          : 16\n    loss           : 0.020744985266047122\n    grad norm      : 0.8200977536957862\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.03704771327895821\n    dev_accuracy   : 0.9887387387387387\n    dev_eer        : 0.02905294766743329\n    dev_frr        : 0.029042386185243328\n    dev_far        : 0.02906350914962325\n    dev_thr        : 0.023701950907707214\n    eval_loss      : 0.1730585734477381\n    eval_accuracy  : 0.9430006735518635\n    eval_eer       : 0.051230714915806164\n    eval_frr       : 0.05125764785859959\n    eval_far       : 0.051203781973012744\n    eval_thr       : 0.6938490271568298\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.041455\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:20<03:49,  2.59it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.341713\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:36<02:33,  2.59it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.045204\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:53<01:17,  2.60it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.007836\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:09<00:00,  2.61it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.002144\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:10<00:00,  2.56it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 17\n    loss           : 0.02098116519004859\n    grad norm      : 0.8023579963671063\n    accuracy       : 0.9951073232323232\n    dev_loss       : 0.02205325622325661\n    dev_accuracy   : 0.9931628056628057\n    dev_eer        : 0.012160525798462135\n    dev_frr        : 0.01216640502354788\n    dev_far        : 0.01215464657337639\n    dev_thr        : 0.1434990018606186\n    eval_loss      : 0.15756717505147594\n    eval_accuracy  : 0.9363914458913336\n    eval_eer       : 0.03955328837408009\n    eval_frr       : 0.03956492182188987\n    eval_far       : 0.03954165492627031\n    eval_thr       : 0.9466478228569031\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.001725\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000371\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000582\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.002475\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000768\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 18\n    loss           : 0.02316746970513986\n    grad norm      : 0.7964800083092555\n    accuracy       : 0.9930555555555556\n    dev_loss       : 0.06073433334276461\n    dev_accuracy   : 0.9845157657657657\n    dev_eer        : 0.027858760876214358\n    dev_frr        : 0.027864992150706435\n    dev_far        : 0.02785252960172228\n    dev_thr        : 0.07311878353357315\n    eval_loss      : 0.4319259109295633\n    eval_accuracy  : 0.9026521104678585\n    eval_eer       : 0.07263444874175408\n    eval_frr       : 0.0726036709721278\n    eval_far       : 0.07266522651138035\n    eval_thr       : 0.9506523609161377\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.030386\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.000308\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.60it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.004020\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.131671\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.009610\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.72it/s]\n    epoch          : 19\n    loss           : 0.026839606290388583\n    grad norm      : 0.9279528912368484\n    accuracy       : 0.9910037878787878\n    dev_loss       : 0.019359073108180885\n    dev_accuracy   : 0.9936052123552124\n    dev_eer        : 0.007451055275136469\n    dev_frr        : 0.007456828885400314\n    dev_far        : 0.007445281664872623\n    dev_thr        : 0.023624153807759285\n    eval_loss      : 0.13187814597316164\n    eval_accuracy  : 0.9555736416704086\n    eval_eer       : 0.04337435347475613\n    eval_frr       : 0.0433718558803535\n    eval_far       : 0.04337685106915876\n    eval_thr       : 0.5387916564941406\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.005212\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.010299\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:33,  2.59it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000391\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000620\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000561\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.72it/s]\n    epoch          : 20\n    loss           : 0.010142378402146867\n    grad norm      : 0.2974477791582526\n    accuracy       : 0.9977904040404041\n    dev_loss       : 0.027190952083773725\n    dev_accuracy   : 0.9929617117117117\n    dev_eer        : 0.016471934058048157\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016460351632579834\n    dev_thr        : 0.007204687222838402\n    eval_loss      : 0.14763010895298626\n    eval_accuracy  : 0.9548158958239784\n    eval_eer       : 0.03548668431009068\n    eval_frr       : 0.03548606390210741\n    eval_far       : 0.03548730471807395\n    eval_thr       : 0.8628541231155396\nSaving checkpoint: saved/models/exp3_hints_no_abs_no_2021_style/1213_114614/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.005665\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:50,  2.59it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.022071\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.59it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.000447\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000201\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.023392\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.71it/s]\n    epoch          : 21\n    loss           : 0.017589630231466598\n    grad norm      : 0.44959192840509454\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.06867486288780172\n    dev_accuracy   : 0.9831885456885456\n    dev_eer        : 0.03495660498197789\n    dev_frr        : 0.034929356357927786\n    dev_far        : 0.03498385360602799\n    dev_thr        : 0.0019808756187558174\n    eval_loss      : 0.21459950789092336\n    eval_accuracy  : 0.9641894925909295\n    eval_eer       : 0.04854051735555684\n    eval_frr       : 0.048538409245411286\n    eval_far       : 0.048542625465702385\n    eval_thr       : 0.06172630563378334\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.001037\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.030888\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:33<02:32,  2.60it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.002974\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.59it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000271\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.061250\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:48<00:00,  7.73it/s]\n    epoch          : 22\n    loss           : 0.022186202326577247\n    grad norm      : 0.9598777322804161\n    accuracy       : 0.9936868686868687\n    dev_loss       : 0.03418409345585234\n    dev_accuracy   : 0.989261583011583\n    dev_eer        : 0.018439819829563026\n    dev_frr        : 0.018445839874411302\n    dev_far        : 0.01843379978471475\n    dev_thr        : 0.10786567628383636\n    eval_loss      : 0.14237713771834062\n    eval_accuracy  : 0.9532583071396498\n    eval_eer       : 0.03888465244946969\n    eval_frr       : 0.03888511216859279\n    eval_far       : 0.03888419273034658\n    eval_thr       : 0.7634080052375793\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.001327\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.001341\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.60it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000558\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:48<01:16,  2.60it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.001422\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.001393\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:05<00:00,  2.60it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 23\n    loss           : 0.01838168199512181\n    grad norm      : 0.7840218691030668\n    accuracy       : 0.99447601010101\n    dev_loss       : 0.05099619938203127\n    dev_accuracy   : 0.9834030459286163\n    dev_eer        : 0.016073871794308518\n    dev_frr        : 0.01609105180533752\n    dev_far        : 0.016056691783279512\n    dev_thr        : 0.5583170652389526\n    eval_loss      : 0.20333808249185262\n    eval_accuracy  : 0.9197070049393803\n    eval_eer       : 0.04146773438987004\n    eval_frr       : 0.04146838885112169\n    eval_far       : 0.04146707992861839\n    eval_thr       : 0.9845501780509949\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.002227\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.59it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000508\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:33,  2.60it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000134\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:49<01:17,  2.60it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.009823\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.131231\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:06<00:00,  2.59it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 24\n    loss           : 0.013890062366210093\n    grad norm      : 0.46798773340862054\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.028961409453273856\n    dev_accuracy   : 0.9908435221190925\n    dev_eer        : 0.018439819829563026\n    dev_frr        : 0.018445839874411302\n    dev_far        : 0.01843379978471475\n    dev_thr        : 0.032129015773534775\n    eval_loss      : 0.15237515085342507\n    eval_accuracy  : 0.9452879434216435\n    eval_eer       : 0.0447351061166885\n    eval_frr       : 0.04473147518694765\n    eval_far       : 0.044738737046429354\n    eval_thr       : 0.7547197937965393\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.001660\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:49,  2.60it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.016631\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:32<02:32,  2.60it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.001900\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:48<01:17,  2.59it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.001433\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [05:05<00:00,  2.61it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.000869\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [05:05<00:00,  2.60it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:40<00:00,  7.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:47<00:00,  7.74it/s]\n    epoch          : 25\n    loss           : 0.005212215215395171\n    grad norm      : 0.19979951803741808\n    accuracy       : 0.998895202020202\n    dev_loss       : 0.03247974259954566\n    dev_accuracy   : 0.9913127413127413\n    dev_eer        : 0.01649435960523151\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016505202726946538\n    dev_thr        : 0.013219624757766724\n    eval_loss      : 0.19114621314145377\n    eval_accuracy  : 0.9465789178266727\n    eval_eer       : 0.040806925396163485\n    eval_frr       : 0.04078857919782461\n    eval_far       : 0.04082527159450236\n    eval_thr       : 0.944068968296051\nSaving checkpoint: saved/models/exp3_hints_no_abs_no_2021_style/1213_114614/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp5.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:36:09.427562Z","iopub.execute_input":"2023-12-13T17:36:09.427979Z","iopub.status.idle":"2023-12-13T20:39:33.583651Z","shell.execute_reply.started":"2023-12-13T17:36:09.427947Z","shell.execute_reply":"2023-12-13T20:39:33.582355Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_173618-tuowb6us\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mastral-lion-8\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/tuowb6us\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.693130\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:37<01:39,  6.00it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.285018\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:10<01:06,  6.00it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.091386\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:43<00:33,  5.99it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.120791\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:16<00:00,  6.11it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.112479\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:17<00:00,  5.79it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.85it/s]\n    epoch          : 1\n    loss           : 0.1705275710032444\n    grad norm      : 10.902255495690335\n    accuracy       : 0.9420770202020202\n    dev_loss       : 0.14308415357313542\n    dev_accuracy   : 0.947809416584987\n    dev_eer        : 0.08914915432099808\n    dev_frr        : 0.0890894819466248\n    dev_far        : 0.08920882669537136\n    dev_thr        : 0.13593599200248718\n    eval_loss      : 0.3108878222665928\n    eval_accuracy  : 0.922050404131118\n    eval_eer       : 0.0984339604221422\n    eval_frr       : 0.09843643779741672\n    eval_far       : 0.09843148304686766\n    eval_thr       : 0.22109857201576233\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.024914\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.012625\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.101127\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.013514\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.102501\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 2\n    loss           : 0.1043499362951314\n    grad norm      : 7.153669759932191\n    accuracy       : 0.9655934343434344\n    dev_loss       : 0.09091441804423875\n    dev_accuracy   : 0.9667658730670139\n    dev_eer        : 0.052975937000617916\n    dev_frr        : 0.052982731554160126\n    dev_far        : 0.05296914244707571\n    dev_thr        : 0.18134263157844543\n    eval_loss      : 0.21633258020462653\n    eval_accuracy  : 0.9379770992366412\n    eval_eer       : 0.07355645056058172\n    eval_frr       : 0.0735554044867437\n    eval_far       : 0.07355749663441971\n    eval_thr       : 0.30446821451187134\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.014791\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.004128\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.224129\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.069081\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.005728\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 3\n    loss           : 0.07891474537036354\n    grad norm      : 5.462493534792554\n    accuracy       : 0.9741161616161617\n    dev_loss       : 0.08868653643933998\n    dev_accuracy   : 0.9679590304846009\n    dev_eer        : 0.04318135923741029\n    dev_frr        : 0.04317111459968603\n    dev_far        : 0.04319160387513455\n    dev_thr        : 0.24440337717533112\n    eval_loss      : 0.18932994691055766\n    eval_accuracy  : 0.9311293219577907\n    eval_eer       : 0.06036419417165116\n    eval_frr       : 0.06036709721278042\n    eval_far       : 0.060361291130521896\n    eval_thr       : 0.6754727363586426\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.025786\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.02it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.016816\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.02it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.014834\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.052163\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.036818\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 4\n    loss           : 0.057176049865166084\n    grad norm      : 4.354845032077095\n    accuracy       : 0.9805871212121212\n    dev_loss       : 0.11337886179199477\n    dev_accuracy   : 0.9668329043584748\n    dev_eer        : 0.060359715634204336\n    dev_frr        : 0.06043956043956044\n    dev_far        : 0.060279870828848225\n    dev_thr        : 0.01482872199267149\n    eval_loss      : 0.3386408037791829\n    eval_accuracy  : 0.934553210597216\n    eval_eer       : 0.08103667662575784\n    eval_frr       : 0.08103331067301156\n    eval_far       : 0.08104004257850411\n    eval_thr       : 0.14567866921424866\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.021461\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.005440\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.009585\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.069436\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.002221\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 5\n    loss           : 0.06910432505449562\n    grad norm      : 5.03604036079475\n    accuracy       : 0.9791666666666666\n    dev_loss       : 0.06740366483529421\n    dev_accuracy   : 0.9780003217503217\n    dev_eer        : 0.03610594067883011\n    dev_frr        : 0.03610675039246468\n    dev_far        : 0.03610513096519555\n    dev_thr        : 0.10853288322687149\n    eval_loss      : 0.19080522752604914\n    eval_accuracy  : 0.9370229007633588\n    eval_eer       : 0.058734421773693854\n    eval_frr       : 0.05873555404486744\n    eval_far       : 0.05873328950252027\n    eval_thr       : 0.5914192795753479\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.180415\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.021754\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.005749\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.026595\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.008396\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 6\n    loss           : 0.026113664384121712\n    grad norm      : 3.045662403849866\n    accuracy       : 0.9908459595959596\n    dev_loss       : 0.11369166807017841\n    dev_accuracy   : 0.9715519091030499\n    dev_eer        : 0.042076874634924766\n    dev_frr        : 0.041993720565149134\n    dev_far        : 0.0421600287047004\n    dev_thr        : 0.08282773196697235\n    eval_loss      : 0.2875869603072804\n    eval_accuracy  : 0.9288841490794791\n    eval_eer       : 0.061032830096261564\n    eval_frr       : 0.0610469068660775\n    eval_far       : 0.061018753326445636\n    eval_thr       : 0.834748387336731\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.020389\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.016078\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.03it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.193448\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.008605\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.10it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.007716\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 7\n    loss           : 0.04058337351630649\n    grad norm      : 3.511499922064067\n    accuracy       : 0.9903724747474747\n    dev_loss       : 0.05303276822094846\n    dev_accuracy   : 0.9814859502870911\n    dev_eer        : 0.029826646647729226\n    dev_frr        : 0.029827315541601257\n    dev_far        : 0.029825977753857195\n    dev_thr        : 0.09162366390228271\n    eval_loss      : 0.18355110377724837\n    eval_accuracy  : 0.9390295240233498\n    eval_eer       : 0.05965642359252149\n    eval_frr       : 0.05968728755948335\n    eval_far       : 0.059625559625559627\n    eval_thr       : 0.5390612483024597\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.007995\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.020907\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.030178\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.024456\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.000644\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 8\n    loss           : 0.019887177537549924\n    grad norm      : 2.0956230761784345\n    accuracy       : 0.9930555555555556\n    dev_loss       : 0.0887907818875835\n    dev_accuracy   : 0.9797297297297297\n    dev_eer        : 0.04086026229652248\n    dev_frr        : 0.04081632653061224\n    dev_far        : 0.04090419806243272\n    dev_thr        : 0.0011337018804624677\n    eval_loss      : 0.34013784645185074\n    eval_accuracy  : 0.9498905478221823\n    eval_eer       : 0.06893615312273473\n    eval_frr       : 0.06893269884432358\n    eval_far       : 0.06893960740114587\n    eval_thr       : 0.045626185834407806\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.004675\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.02it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.000662\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.001692\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.002012\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.000102\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 9\n    loss           : 0.014083116648933613\n    grad norm      : 1.6110129183960251\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.058588476565802204\n    dev_accuracy   : 0.9838052338308042\n    dev_eer        : 0.029826646647729226\n    dev_frr        : 0.029827315541601257\n    dev_far        : 0.029825977753857195\n    dev_thr        : 0.012083422392606735\n    eval_loss      : 0.26511540451522714\n    eval_accuracy  : 0.9303294791198923\n    eval_eer       : 0.0561513398332935\n    eval_frr       : 0.05615227736233855\n    eval_far       : 0.056150402304248455\n    eval_thr       : 0.883876621723175\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.003462\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.006810\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.001486\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.003549\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.02it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.000809\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 10\n    loss           : 0.022352899362408377\n    grad norm      : 1.7224629781787482\n    accuracy       : 0.9921085858585859\n    dev_loss       : 0.05300522569082655\n    dev_accuracy   : 0.984676640926641\n    dev_eer        : 0.02279607918351575\n    dev_frr        : 0.022762951334379906\n    dev_far        : 0.022829207032651597\n    dev_thr        : 0.004433483351022005\n    eval_loss      : 0.2329666869546748\n    eval_accuracy  : 0.9538055680287382\n    eval_eer       : 0.05547487697777924\n    eval_frr       : 0.05547246770904147\n    eval_far       : 0.055477286246517016\n    eval_thr       : 0.15260523557662964\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.000580\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000143\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.001751\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.001120\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.10it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.003775\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 11\n    loss           : 0.03292938023690967\n    grad norm      : 2.9140637700699945\n    accuracy       : 0.9906881313131313\n    dev_loss       : 0.05251717373507271\n    dev_accuracy   : 0.9843951093951094\n    dev_eer        : 0.02308201371133864\n    dev_frr        : 0.02315541601255887\n    dev_far        : 0.023008611410118406\n    dev_thr        : 0.09152694046497345\n    eval_loss      : 0.2780532353384304\n    eval_accuracy  : 0.9102351818590031\n    eval_eer       : 0.0622629863256334\n    eval_frr       : 0.06227056424201224\n    eval_far       : 0.062255408409254566\n    eval_thr       : 0.9615458846092224\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.001155\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.001367\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.161946\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000360\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.10it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.001913\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.97it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 12\n    loss           : 0.01894445578323535\n    grad norm      : 1.8824787766489228\n    accuracy       : 0.9935290404040404\n    dev_loss       : 0.040960929502196826\n    dev_accuracy   : 0.9873847061602765\n    dev_eer        : 0.022353165825409405\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.022335844994617868\n    dev_thr        : 0.10282683372497559\n    eval_loss      : 0.23102644893384702\n    eval_accuracy  : 0.9240991243825775\n    eval_eer       : 0.05888849897896596\n    eval_frr       : 0.05887151597552685\n    eval_far       : 0.05890548198240506\n    eval_thr       : 0.8940058350563049\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.008589\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.000212\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.000494\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.003651\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.003649\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 13\n    loss           : 0.014533278812634326\n    grad norm      : 1.3929054807269512\n    accuracy       : 0.9963699494949495\n    dev_loss       : 0.16458826932996307\n    dev_accuracy   : 0.9486003861003861\n    dev_eer        : 0.031351619061137745\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03130606386795838\n    dev_thr        : 0.8814616799354553\n    eval_loss      : 0.3235900098123689\n    eval_accuracy  : 0.8785080826223619\n    eval_eer       : 0.06879772977927033\n    eval_frr       : 0.06879673691366417\n    eval_far       : 0.06879872264487649\n    eval_thr       : 0.9837188124656677\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.002549\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.001459\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.03it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000820\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.04it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000513\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.004608\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 14\n    loss           : 0.01124961503048344\n    grad norm      : 1.1603815985668329\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.04508657142319456\n    dev_accuracy   : 0.9883767696267697\n    dev_eer        : 0.023524927069444986\n    dev_frr        : 0.023547880690737835\n    dev_far        : 0.023501973448152136\n    dev_thr        : 0.0029558278620243073\n    eval_loss      : 0.1827331852554885\n    eval_accuracy  : 0.9547317018410417\n    eval_eer       : 0.04799465091260312\n    eval_frr       : 0.04799456152277362\n    eval_far       : 0.04799474030243261\n    eval_thr       : 0.40179216861724854\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.001081\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.003743\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.02it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.006321\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.032901\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000180\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 15\n    loss           : 0.01828749515272023\n    grad norm      : 1.3824983805893083\n    accuracy       : 0.9952651515151515\n    dev_loss       : 0.09840913790499463\n    dev_accuracy   : 0.9709888460399868\n    dev_eer        : 0.02047498224262794\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.020541801219949765\n    dev_thr        : 0.8053086400032043\n    eval_loss      : 0.29506476376987895\n    eval_accuracy  : 0.9018438482263135\n    eval_eer       : 0.04838644015028473\n    eval_frr       : 0.04840244731475187\n    eval_far       : 0.0483704329858176\n    eval_thr       : 0.9955756664276123\nSaving checkpoint: saved/models/exp5_hints_no_abs_no_weight_decay/1213_173613/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.000437\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000397\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000697\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000493\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.003252\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 16\n    loss           : 0.010456301332934263\n    grad norm      : 0.8645855901857504\n    accuracy       : 0.9970012626262627\n    dev_loss       : 0.04769407372655668\n    dev_accuracy   : 0.987733268983269\n    dev_eer        : 0.031396470155504445\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03139576605669178\n    dev_thr        : 0.1132175400853157\n    eval_loss      : 0.21774778148266757\n    eval_accuracy  : 0.9336551414458913\n    eval_eer       : 0.050846752609028406\n    eval_frr       : 0.05084976206662135\n    eval_far       : 0.05084374315143546\n    eval_thr       : 0.9143232107162476\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.004661\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.040309\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000661\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000630\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000193\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.97it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.85it/s]\n    epoch          : 17\n    loss           : 0.00774883672185678\n    grad norm      : 1.060883153965485\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.07185799613550907\n    dev_accuracy   : 0.9858429858429858\n    dev_eer        : 0.0254703872937765\n    dev_frr        : 0.025510204081632654\n    dev_far        : 0.025430570505920343\n    dev_thr        : 0.0007354238769039512\n    eval_loss      : 0.29261487400848923\n    eval_accuracy  : 0.9320414234396048\n    eval_eer       : 0.05561330032124363\n    eval_frr       : 0.05560842963970088\n    eval_far       : 0.05561817100278639\n    eval_thr       : 0.905593752861023\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000046\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.002069\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000063\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000393\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000323\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.97it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 18\n    loss           : 0.007516646639427875\n    grad norm      : 0.7659688420566398\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.034399553403015516\n    dev_accuracy   : 0.9917149292149292\n    dev_eer        : 0.01649435960523151\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016505202726946538\n    dev_thr        : 0.0025491865817457438\n    eval_loss      : 0.23108680522105784\n    eval_accuracy  : 0.9431550291872475\n    eval_eer       : 0.04802595863621853\n    eval_frr       : 0.04799456152277362\n    eval_far       : 0.048057355749663445\n    eval_thr       : 0.8541092276573181\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.000222\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.003071\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.92it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.042110\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.010945\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.002254\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 19\n    loss           : 0.02301595987707763\n    grad norm      : 1.9664282369265107\n    accuracy       : 0.9919507575757576\n    dev_loss       : 0.035288265723973034\n    dev_accuracy   : 0.9881220506731915\n    dev_eer        : 0.017268058585527445\n    dev_frr        : 0.01726844583987441\n    dev_far        : 0.01726767133118048\n    dev_thr        : 0.036966655403375626\n    eval_loss      : 0.1665773697118248\n    eval_accuracy  : 0.961761899416255\n    eval_eer       : 0.04285979475541783\n    eval_frr       : 0.04282800815771584\n    eval_far       : 0.042891581353119816\n    eval_thr       : 0.32063382863998413\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.001170\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000156\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.284178\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000435\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.10it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000203\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 20\n    loss           : 0.012192929310600962\n    grad norm      : 0.8802607301311013\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.051465195953860364\n    dev_accuracy   : 0.9882695195450899\n    dev_eer        : 0.024343477144107624\n    dev_frr        : 0.02433281004709576\n    dev_far        : 0.024354144241119483\n    dev_thr        : 0.0023689160589128733\n    eval_loss      : 0.2366037604480474\n    eval_accuracy  : 0.9426638976201167\n    eval_eer       : 0.051922831633128136\n    eval_frr       : 0.05193745751189667\n    eval_far       : 0.0519082057543596\n    eval_thr       : 0.6240811347961426\nSaving checkpoint: saved/models/exp5_hints_no_abs_no_weight_decay/1213_173613/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000877\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000339\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.001085\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.05it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000213\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.11it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.003721\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 21\n    loss           : 0.009499156570926042\n    grad norm      : 0.8734485753823655\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.0735618493054602\n    dev_accuracy   : 0.9783891034402442\n    dev_eer        : 0.028654885403693646\n    dev_frr        : 0.028649921507064365\n    dev_far        : 0.028659849300322927\n    dev_thr        : 0.2138717621564865\n    eval_loss      : 0.26021875081378076\n    eval_accuracy  : 0.9200858778625954\n    eval_eer       : 0.05059338671481118\n    eval_frr       : 0.05057783820530252\n    eval_far       : 0.05060893522431984\n    eval_thr       : 0.9450098872184753\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.007712\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.000270\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.004416\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.03it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000092\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000027\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 22\n    loss           : 0.009096083319454553\n    grad norm      : 1.1244726651906731\n    accuracy       : 0.9970012626262627\n    dev_loss       : 0.039903268763496584\n    dev_accuracy   : 0.9915138352638353\n    dev_eer        : 0.01649435960523151\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016505202726946538\n    dev_thr        : 0.014268996194005013\n    eval_loss      : 0.25695022713912785\n    eval_accuracy  : 0.941513246519982\n    eval_eer       : 0.04282848703180241\n    eval_frr       : 0.04282800815771584\n    eval_far       : 0.042828965905888985\n    eval_thr       : 0.9534593820571899\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000039\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.02it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000270\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000233\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000153\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000273\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.98it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 23\n    loss           : 0.01616398725110974\n    grad norm      : 1.2456886979605475\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.033680975840353435\n    dev_accuracy   : 0.990990990990991\n    dev_eer        : 0.016869996321787803\n    dev_frr        : 0.016875981161695447\n    dev_far        : 0.01686401148188016\n    dev_thr        : 0.0075703952461481094\n    eval_loss      : 0.1874801347721239\n    eval_accuracy  : 0.9514200718455321\n    eval_eer       : 0.04335087268204457\n    eval_frr       : 0.0433718558803535\n    eval_far       : 0.04332988948373564\n    eval_thr       : 0.7138946056365967\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.001268\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000088\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000729\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000102\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000102\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 24\n    loss           : 0.00687678324509008\n    grad norm      : 0.8579146177116946\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.03720503905514162\n    dev_accuracy   : 0.9901061776061776\n    dev_eer        : 0.018837882093302668\n    dev_frr        : 0.018838304552590265\n    dev_far        : 0.01883745963401507\n    dev_thr        : 0.00909728929400444\n    eval_loss      : 0.19979473362377606\n    eval_accuracy  : 0.9489363493488998\n    eval_eer       : 0.04541939590310662\n    eval_frr       : 0.04541128484024473\n    eval_far       : 0.045427506965968506\n    eval_thr       : 0.7248917818069458\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000120\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000031\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000244\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.000205\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.001733\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 25\n    loss           : 0.008025240657214527\n    grad norm      : 0.6293285227159622\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.04054959337183468\n    dev_accuracy   : 0.9869557057568465\n    dev_eer        : 0.017666120849267088\n    dev_frr        : 0.017660910518053376\n    dev_far        : 0.017671331180480802\n    dev_thr        : 0.28409290313720703\n    eval_loss      : 0.25778580656791417\n    eval_accuracy  : 0.9179613830318459\n    eval_eer       : 0.056012916489829104\n    eval_frr       : 0.05601631543167913\n    eval_far       : 0.05600951754797909\n    eval_thr       : 0.9587318301200867\nSaving checkpoint: saved/models/exp5_hints_no_abs_no_weight_decay/1213_173613/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp7.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:53:59.881730Z","iopub.execute_input":"2023-12-13T20:53:59.882829Z","iopub.status.idle":"2023-12-13T23:56:43.142051Z","shell.execute_reply.started":"2023-12-13T20:53:59.882794Z","shell.execute_reply":"2023-12-13T23:56:43.140752Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 1024, num_layers=3, batch_first=True, dropout=0.1)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_205406-hkm304nl\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mapricot-valley-10\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/hkm304nl\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.689638\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:34<01:39,  6.01it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.328977\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:05,  6.03it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.211241\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  6.02it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.041505\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.12it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.235501\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.90it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.93it/s]\n    epoch          : 1\n    loss           : 0.16243928871258642\n    grad norm      : 10.71845797185946\n    accuracy       : 0.9393939393939394\n    dev_loss       : 0.16785885508656453\n    dev_accuracy   : 0.9372452810464218\n    dev_eer        : 0.08202888466805121\n    dev_frr        : 0.08202511773940345\n    dev_far        : 0.08203265159669897\n    dev_thr        : 0.30730438232421875\n    eval_loss      : 0.2462053977310169\n    eval_accuracy  : 0.9072547148683974\n    eval_eer       : 0.09297529599260498\n    eval_frr       : 0.09299796057104011\n    eval_far       : 0.09295263141416987\n    eval_thr       : 0.4960412383079529\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.113494\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.07it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.033603\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:05,  6.05it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.038425\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:38<00:33,  6.06it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.242553\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.14it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.115364\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:11<00:00,  6.02it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.91it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.93it/s]\n    epoch          : 2\n    loss           : 0.13925336691964832\n    grad norm      : 7.312190815204322\n    accuracy       : 0.9559659090909091\n    dev_loss       : 0.16769202908278086\n    dev_accuracy   : 0.9440556628056628\n    dev_eer        : 0.09416698491933\n    dev_frr        : 0.09419152276295134\n    dev_far        : 0.09414244707570865\n    dev_thr        : 0.09751836210489273\n    eval_loss      : 0.2947357102929977\n    eval_accuracy  : 0.9196368432869331\n    eval_eer       : 0.09748847781060299\n    eval_frr       : 0.09748470428280082\n    eval_far       : 0.09749225133840518\n    eval_thr       : 0.2226763814687729\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.029529\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.06it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.034226\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:05<01:05,  6.05it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.097143\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:38<00:33,  6.05it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.003141\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.13it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.192565\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:11<00:00,  6.02it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.90it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.90it/s]\n    epoch          : 3\n    loss           : 0.06558481334870907\n    grad norm      : 5.118723420953058\n    accuracy       : 0.9807449494949495\n    dev_loss       : 0.23944348456731193\n    dev_accuracy   : 0.9273648648648649\n    dev_eer        : 0.04278329697367065\n    dev_frr        : 0.04277864992150707\n    dev_far        : 0.04278794402583423\n    dev_thr        : 0.880867063999176\n    eval_loss      : 0.3148231830240487\n    eval_accuracy  : 0.8785361472833408\n    eval_eer       : 0.06988163573427392\n    eval_frr       : 0.0698844323589395\n    eval_far       : 0.06987883910960833\n    eval_thr       : 0.9814945459365845\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.024325\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.020361\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.038333\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.002926\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.12it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.030720\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.89it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.91it/s]\n    epoch          : 4\n    loss           : 0.060777225762116485\n    grad norm      : 4.835644012411135\n    accuracy       : 0.9839015151515151\n    dev_loss       : 0.1108714254742891\n    dev_accuracy   : 0.9633204633204633\n    dev_eer        : 0.04355699595396659\n    dev_frr        : 0.04356357927786499\n    dev_far        : 0.043550412630068175\n    dev_thr        : 0.3211662471294403\n    eval_loss      : 0.22402515207294152\n    eval_accuracy  : 0.9194628423942168\n    eval_eer       : 0.06333906534973313\n    eval_frr       : 0.06335825968728756\n    eval_far       : 0.0633198710121787\n    eval_thr       : 0.8304075002670288\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.003179\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.04it/s]Train Epoch: 5 [198/794 (25%)] Loss: 1.298845\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.070676\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:38<00:33,  5.98it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.027639\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.13it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.006953\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.01it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.90it/s]\n    epoch          : 5\n    loss           : 0.044607458293974174\n    grad norm      : 3.678670001865336\n    accuracy       : 0.9878472222222222\n    dev_loss       : 0.06960131938289933\n    dev_accuracy   : 0.9771557271557272\n    dev_eer        : 0.0537720615280972\n    dev_frr        : 0.05376766091051805\n    dev_far        : 0.05377646214567636\n    dev_thr        : 0.027732927352190018\n    eval_loss      : 0.26193172064255194\n    eval_accuracy  : 0.9493236416757616\n    eval_eer       : 0.07886103778484682\n    eval_frr       : 0.07885791978246091\n    eval_far       : 0.07886415578723271\n    eval_thr       : 0.11656701564788818\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.494794\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.010029\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.03it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.047482\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.03it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.133501\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.13it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.070484\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.89it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.90it/s]\n    epoch          : 6\n    loss           : 0.07243948449049088\n    grad norm      : 5.085529402142974\n    accuracy       : 0.9761679292929293\n    dev_loss       : 0.12044406733403709\n    dev_accuracy   : 0.960505148005148\n    dev_eer        : 0.0368572141119427\n    dev_frr        : 0.036891679748822605\n    dev_far        : 0.03682274847506279\n    dev_thr        : 0.5468839406967163\n    eval_loss      : 0.2683415667178307\n    eval_accuracy  : 0.9060956443646161\n    eval_eer       : 0.06336254614244469\n    eval_frr       : 0.06335825968728756\n    eval_far       : 0.06336683259760183\n    eval_thr       : 0.9128729104995728\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.006407\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.042996\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.716963\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.197162\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.13it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.018181\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.89it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.90it/s]\n    epoch          : 7\n    loss           : 0.12551345083288698\n    grad norm      : 4.686998419313118\n    accuracy       : 0.9570707070707071\n    dev_loss       : 0.10261017025269789\n    dev_accuracy   : 0.965599528150669\n    dev_eer        : 0.04393263267052287\n    dev_frr        : 0.04395604395604396\n    dev_far        : 0.04390922138500179\n    dev_thr        : 0.28576362133026123\n    eval_loss      : 0.2138145500484588\n    eval_accuracy  : 0.9251038392509748\n    eval_eer       : 0.06934359622222405\n    eval_frr       : 0.06934058463630184\n    eval_far       : 0.06934660780814626\n    eval_thr       : 0.6257641911506653\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.025571\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.02it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.003320\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.022762\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.196156\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:11<00:00,  6.12it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.208840\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:44<00:00,  9.90it/s]\n    epoch          : 8\n    loss           : 0.18547633739959712\n    grad norm      : 13.848294025117701\n    accuracy       : 0.928030303030303\n    dev_loss       : 0.1774743411329214\n    dev_accuracy   : 0.9260510510766214\n    dev_eer        : 0.07614765290068996\n    dev_frr        : 0.076138147566719\n    dev_far        : 0.07615715823466093\n    dev_thr        : 0.48588064312934875\n    eval_loss      : 0.2309425247659163\n    eval_accuracy  : 0.9150566906205303\n    eval_eer       : 0.0815747161378077\n    eval_frr       : 0.08157715839564922\n    eval_far       : 0.08157227387996618\n    eval_thr       : 0.5358893871307373\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.113089\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.02it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.037188\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.711990\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.03it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.287564\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.10it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.117450\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 9\n    loss           : 0.19079571924727373\n    grad norm      : 7.198816391253712\n    accuracy       : 0.912405303030303\n    dev_loss       : 0.0913678774915209\n    dev_accuracy   : 0.9653984341995749\n    dev_eer        : 0.05932250767326886\n    dev_frr        : 0.05926216640502355\n    dev_far        : 0.059382848941514174\n    dev_thr        : 0.12128134816884995\n    eval_loss      : 0.23781032275787392\n    eval_accuracy  : 0.9483413785415002\n    eval_eer       : 0.0717569470955446\n    eval_frr       : 0.07178789938817132\n    eval_far       : 0.07172599480291789\n    eval_thr       : 0.20489345490932465\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.915578\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.121248\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.073142\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.05it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.128158\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.054345\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 10\n    loss           : 0.06002836039341572\n    grad norm      : 4.767360506221802\n    accuracy       : 0.9834280303030303\n    dev_loss       : 0.09520994630304226\n    dev_accuracy   : 0.9688036250791955\n    dev_eer        : 0.03413805490731525\n    dev_frr        : 0.03414442700156986\n    dev_far        : 0.034131682813060636\n    dev_thr        : 0.399296373128891\n    eval_loss      : 0.21495470458352675\n    eval_accuracy  : 0.9244162550569919\n    eval_eer       : 0.05519803029085046\n    eval_frr       : 0.05520054384772264\n    eval_far       : 0.055195516733978274\n    eval_thr       : 0.9167066216468811\nSaving checkpoint: saved/models/exp7_hints_no_abs_no_gru_bid/1213_205403/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.024022\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.174265\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.03it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.452412\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.031886\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.009304\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.97it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 11\n    loss           : 0.05802782107617311\n    grad norm      : 4.707567589263422\n    accuracy       : 0.985479797979798\n    dev_loss       : 0.08130339460874136\n    dev_accuracy   : 0.9738309738565443\n    dev_eer        : 0.044263418292712464\n    dev_frr        : 0.04434850863422292\n    dev_far        : 0.04417832795120201\n    dev_thr        : 0.11864752322435379\n    eval_loss      : 0.2285035144624254\n    eval_accuracy  : 0.925684777727885\n    eval_eer       : 0.06949767342749616\n    eval_frr       : 0.06947654656696126\n    eval_far       : 0.06951880028803106\n    eval_thr       : 0.6183016896247864\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.073826\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.117018\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:05,  6.04it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.015987\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.017286\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.001815\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 12\n    loss           : 0.04130650559649567\n    grad norm      : 4.262165319080455\n    accuracy       : 0.9891098484848485\n    dev_loss       : 0.07915171302997051\n    dev_accuracy   : 0.9740454740966149\n    dev_eer        : 0.0314188957026878\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03144061715105849\n    dev_thr        : 0.3444019854068756\n    eval_loss      : 0.2189242156728166\n    eval_accuracy  : 0.9238325101032779\n    eval_eer       : 0.052076908838400236\n    eval_frr       : 0.052073419442556085\n    eval_far       : 0.05208039823424439\n    eval_thr       : 0.9336285591125488\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.123361\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.002669\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.009179\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.96it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.002435\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.005730\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 13\n    loss           : 0.03827403326203689\n    grad norm      : 3.1614619878525234\n    accuracy       : 0.98989898989899\n    dev_loss       : 0.05022074098946309\n    dev_accuracy   : 0.9837650150405854\n    dev_eer        : 0.03453611717105489\n    dev_frr        : 0.03453689167974882\n    dev_far        : 0.03453534266236096\n    dev_thr        : 0.11583500355482101\n    eval_loss      : 0.2263252051788887\n    eval_accuracy  : 0.9320694881005838\n    eval_eer       : 0.07161852375208021\n    eval_frr       : 0.0716519374575119\n    eval_far       : 0.07158511004664851\n    eval_thr       : 0.4289429187774658\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.025305\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.030744\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.014159\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.03it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.001185\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.007516\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 14\n    loss           : 0.038870670046890154\n    grad norm      : 3.462555704111553\n    accuracy       : 0.9900568181818182\n    dev_loss       : 0.03890310507732176\n    dev_accuracy   : 0.9873712998712999\n    dev_eer        : 0.02511717612440356\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.025116612845353426\n    dev_thr        : 0.12868431210517883\n    eval_loss      : 0.16740106790912845\n    eval_accuracy  : 0.9451195554557701\n    eval_eer       : 0.056582263725494394\n    eval_frr       : 0.05656016315431679\n    eval_far       : 0.05660436429667199\n    eval_thr       : 0.46032002568244934\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.016990\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.011929\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.005324\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.03it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.009259\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.004616\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 15\n    loss           : 0.04302515474446776\n    grad norm      : 3.6373328762034878\n    accuracy       : 0.9850063131313131\n    dev_loss       : 0.058576847595635244\n    dev_accuracy   : 0.9822367010122715\n    dev_eer        : 0.03292144256891297\n    dev_frr        : 0.03296703296703297\n    dev_far        : 0.03287585217079297\n    dev_thr        : 0.009962256997823715\n    eval_loss      : 0.20933341497269853\n    eval_accuracy  : 0.957111585097405\n    eval_eer       : 0.05302239144993943\n    eval_frr       : 0.05302515295717199\n    eval_far       : 0.05301962994270686\n    eval_thr       : 0.15046383440494537\nSaving checkpoint: saved/models/exp7_hints_no_abs_no_gru_bid/1213_205403/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.016060\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000946\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.001476\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.016202\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.001357\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 16\n    loss           : 0.03111820448498063\n    grad norm      : 2.592805251573222\n    accuracy       : 0.9925820707070707\n    dev_loss       : 0.03983903604159863\n    dev_accuracy   : 0.9897442084942085\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.015404577367007732\n    eval_loss      : 0.2590192543808684\n    eval_accuracy  : 0.9362090255949708\n    eval_eer       : 0.05463650998608903\n    eval_frr       : 0.054656696125084975\n    eval_far       : 0.05461632384709308\n    eval_thr       : 0.8529213666915894\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.611289\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.008390\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.009001\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.002867\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.003148\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 17\n    loss           : 0.03240939673560206\n    grad norm      : 1.777639583430507\n    accuracy       : 0.9933712121212122\n    dev_loss       : 0.03550550192131564\n    dev_accuracy   : 0.989824646074646\n    dev_eer        : 0.02157946684511347\n    dev_frr        : 0.021585557299843013\n    dev_far        : 0.021573376390383925\n    dev_thr        : 0.048912163823843\n    eval_loss      : 0.26443223052658243\n    eval_accuracy  : 0.932265940727436\n    eval_eer       : 0.057804593023962375\n    eval_frr       : 0.05778382053025153\n    eval_far       : 0.05782536551767321\n    eval_thr       : 0.9015374779701233\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.001051\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000465\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:05,  6.04it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.004744\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.053173\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.030714\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 18\n    loss           : 0.02753868307436186\n    grad norm      : 1.840186502389384\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.04066674468279673\n    dev_accuracy   : 0.9883499571255275\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.007833242416381836\n    eval_loss      : 0.23507723038413716\n    eval_accuracy  : 0.9462702065559048\n    eval_eer       : 0.05696622603227215\n    eval_frr       : 0.056968048946295036\n    eval_far       : 0.056964403118249275\n    eval_thr       : 0.35944411158561707\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.002017\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.02it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.001014\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.002327\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.008471\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.066026\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.88it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 19\n    loss           : 0.027636709957144862\n    grad norm      : 2.112267221949731\n    accuracy       : 0.9930555555555556\n    dev_loss       : 0.044527957918142784\n    dev_accuracy   : 0.9836175461686869\n    dev_eer        : 0.0255152383881432\n    dev_frr        : 0.025510204081632654\n    dev_far        : 0.02552027269465375\n    dev_thr        : 0.18815071880817413\n    eval_loss      : 0.22023104516573738\n    eval_accuracy  : 0.9229765379434216\n    eval_eer       : 0.05505178001648221\n    eval_frr       : 0.055064581917063225\n    eval_far       : 0.055038978115901194\n    eval_thr       : 0.8909986615180969\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.014450\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.002133\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.003768\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.013369\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.12it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.004023\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 20\n    loss           : 0.021917587492983632\n    grad norm      : 1.8704725507590356\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.0316978243321655\n    dev_accuracy   : 0.9913529601029601\n    dev_eer        : 0.014548899380899996\n    dev_frr        : 0.014521193092621664\n    dev_far        : 0.014576605669178328\n    dev_thr        : 0.04893440753221512\n    eval_loss      : 0.21130692125252082\n    eval_accuracy  : 0.9403906600808262\n    eval_eer       : 0.05411412433584687\n    eval_frr       : 0.05411284840244732\n    eval_far       : 0.054115400269246425\n    eval_thr       : 0.7187508940696716\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.002843\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.030224\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.01it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.002788\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000931\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.002094\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 21\n    loss           : 0.02706397043228281\n    grad norm      : 1.615096868467376\n    accuracy       : 0.9943181818181818\n    dev_loss       : 0.032402382496580485\n    dev_accuracy   : 0.9903877091377091\n    dev_eer        : 0.020009643337338248\n    dev_frr        : 0.020015698587127158\n    dev_far        : 0.020003588087549335\n    dev_thr        : 0.011009515263140202\n    eval_loss      : 0.1700634403808417\n    eval_accuracy  : 0.9497782891782667\n    eval_eer       : 0.04948599996709603\n    eval_frr       : 0.049490142760027195\n    eval_far       : 0.04948185717416487\n    eval_thr       : 0.5335280299186707\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.004343\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.03it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.002368\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.001069\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.003716\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.002372\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  5.99it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.89it/s]\n    epoch          : 22\n    loss           : 0.012306334729091208\n    grad norm      : 1.4442983764186126\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.0401112990843913\n    dev_accuracy   : 0.991956241956242\n    dev_eer        : 0.020362854506711187\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.020317545748116252\n    dev_thr        : 0.0020014713518321514\n    eval_loss      : 0.30516451612468753\n    eval_accuracy  : 0.9333043331836551\n    eval_eer       : 0.051131426226861044\n    eval_frr       : 0.051121685927940176\n    eval_far       : 0.05114116652578191\n    eval_thr       : 0.9908373355865479\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000378\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:38,  6.04it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000481\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:05,  6.04it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000992\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.02it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.007965\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.08it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.080137\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.86it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 23\n    loss           : 0.018077829060135314\n    grad norm      : 2.3239772276802344\n    accuracy       : 0.99447601010101\n    dev_loss       : 0.0778176227103238\n    dev_accuracy   : 0.9782550407806112\n    dev_eer        : 0.05217981247313863\n    dev_frr        : 0.0521978021978022\n    dev_far        : 0.05216182274847506\n    dev_thr        : 0.1826472133398056\n    eval_loss      : 0.22401015224963172\n    eval_accuracy  : 0.9271441400987877\n    eval_eer       : 0.07585485888314941\n    eval_frr       : 0.07586675730795377\n    eval_far       : 0.07584296045834507\n    eval_thr       : 0.45688438415527344\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.022274\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.01it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.007965\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:05,  6.03it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.006726\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.04it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000591\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.001101\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 24\n    loss           : 0.01778082298742539\n    grad norm      : 1.1480729467531836\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.052216156034720185\n    dev_accuracy   : 0.9857625482625483\n    dev_eer        : 0.028654885403693646\n    dev_frr        : 0.028649921507064365\n    dev_far        : 0.028659849300322927\n    dev_thr        : 0.008694682270288467\n    eval_loss      : 0.21956267719570846\n    eval_accuracy  : 0.9436601930848675\n    eval_eer       : 0.05751209247522587\n    eval_frr       : 0.0575118966689327\n    eval_far       : 0.05751228828151905\n    eval_thr       : 0.4359704256057739\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.002213\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.001394\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.02it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000356\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.048841\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.11it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.001116\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:12<00:00,  6.00it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.87it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.88it/s]\n    epoch          : 25\n    loss           : 0.017012682054653373\n    grad norm      : 1.1260442329344875\n    accuracy       : 0.9958964646464646\n    dev_loss       : 0.0393876654134603\n    dev_accuracy   : 0.9899050836550837\n    dev_eer        : 0.032966293663279675\n    dev_frr        : 0.03296703296703297\n    dev_far        : 0.032965554359526375\n    dev_thr        : 0.015428724698722363\n    eval_loss      : 0.2665838274121373\n    eval_accuracy  : 0.940166142792995\n    eval_eer       : 0.05861947922294103\n    eval_frr       : 0.058599592114208024\n    eval_far       : 0.05863936633167403\n    eval_thr       : 0.5645572543144226\nSaving checkpoint: saved/models/exp7_hints_no_abs_no_gru_bid/1213_205403/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp9.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T23:58:50.438754Z","iopub.execute_input":"2023-12-13T23:58:50.439520Z","iopub.status.idle":"2023-12-14T03:02:48.755820Z","shell.execute_reply.started":"2023-12-13T23:58:50.439481Z","shell.execute_reply":"2023-12-14T03:02:48.754778Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_235856-fi7lo6up\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-wave-12\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/fi7lo6up\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.695309\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:34<01:39,  5.99it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.471461\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.131783\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.99it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.348792\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.194352\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 1\n    loss           : 0.2557142824310847\n    grad norm      : 12.717492366077924\n    accuracy       : 0.8977272727272727\n    dev_loss       : 0.2780227328062134\n    dev_accuracy   : 0.8934336121900048\n    dev_eer        : 0.11539324059507053\n    dev_frr        : 0.11538461538461539\n    dev_far        : 0.11540186580552565\n    dev_thr        : 0.41258126497268677\n    eval_loss      : 0.32911654267348034\n    eval_accuracy  : 0.9002722272114952\n    eval_eer       : 0.11053448392516531\n    eval_frr       : 0.1105370496261047\n    eval_far       : 0.11053191822422592\n    eval_thr       : 0.3067631125450134\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.321341\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.095960\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.076260\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.061863\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.199082\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 2\n    loss           : 0.16403544518739135\n    grad norm      : 8.914981113840835\n    accuracy       : 0.9397095959595959\n    dev_loss       : 0.17489588226550085\n    dev_accuracy   : 0.9324994638006046\n    dev_eer        : 0.07581686727850037\n    dev_frr        : 0.07574568288854003\n    dev_far        : 0.07588805166846072\n    dev_thr        : 0.40570834279060364\n    eval_loss      : 0.2296906306504949\n    eval_accuracy  : 0.9245341266277504\n    eval_eer       : 0.08075982993882905\n    eval_frr       : 0.08076138681169273\n    eval_far       : 0.08075827306596538\n    eval_thr       : 0.41365155577659607\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.073240\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.130094\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.032665\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.046512\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.040146\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 3\n    loss           : 0.11622202396628005\n    grad norm      : 7.751133446440552\n    accuracy       : 0.9627525252525253\n    dev_loss       : 0.1102715119202004\n    dev_accuracy   : 0.9605587730843435\n    dev_eer        : 0.052975937000617916\n    dev_frr        : 0.052982731554160126\n    dev_far        : 0.05296914244707571\n    dev_thr        : 0.2430371791124344\n    eval_loss      : 0.24875263927818486\n    eval_accuracy  : 0.9323361023798833\n    eval_eer       : 0.07447845237940934\n    eval_frr       : 0.07450713800135962\n    eval_far       : 0.07444976675745907\n    eval_thr       : 0.3267582058906555\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.303679\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.135597\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.019469\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.025667\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.215477\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 4\n    loss           : 0.08489781768399883\n    grad norm      : 6.708323786449101\n    accuracy       : 0.9685921717171717\n    dev_loss       : 0.09498085068010496\n    dev_accuracy   : 0.9650498712998713\n    dev_eer        : 0.04941580217414447\n    dev_frr        : 0.04945054945054945\n    dev_far        : 0.0493810548977395\n    dev_thr        : 0.26013824343681335\n    eval_loss      : 0.22717266197353567\n    eval_accuracy  : 0.937878872923215\n    eval_eer       : 0.06988163573427392\n    eval_frr       : 0.0698844323589395\n    eval_far       : 0.06987883910960833\n    eval_thr       : 0.34985804557800293\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.018548\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.022143\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.019738\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.002196\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.010281\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.85it/s]\n    epoch          : 5\n    loss           : 0.058432661519900925\n    grad norm      : 5.452658864387283\n    accuracy       : 0.9807449494949495\n    dev_loss       : 0.09318032653208527\n    dev_accuracy   : 0.9708279708791117\n    dev_eer        : 0.04709470523325667\n    dev_frr        : 0.04709576138147567\n    dev_far        : 0.04709364908503767\n    dev_thr        : 0.07842716574668884\n    eval_loss      : 0.27970879667671295\n    eval_accuracy  : 0.9331078805568028\n    eval_eer       : 0.07423291341609597\n    eval_frr       : 0.07423521414004079\n    eval_far       : 0.07423061269215116\n    eval_thr       : 0.28565627336502075\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.017852\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.029581\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.004604\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.003112\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.04it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.013224\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.84it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 6\n    loss           : 0.04842927449558052\n    grad norm      : 3.8141345062358964\n    accuracy       : 0.9837436868686869\n    dev_loss       : 0.07603889058420928\n    dev_accuracy   : 0.9762441012696716\n    dev_eer        : 0.0510304767762864\n    dev_frr        : 0.05102040816326531\n    dev_far        : 0.0510405453893075\n    dev_thr        : 0.050294432789087296\n    eval_loss      : 0.2766329908680144\n    eval_accuracy  : 0.9460316569375842\n    eval_eer       : 0.07068869500234871\n    eval_frr       : 0.07070020394289599\n    eval_far       : 0.07067718606180144\n    eval_thr       : 0.15650252997875214\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.043447\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.036459\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.195582\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.011722\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.017495\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 7\n    loss           : 0.04974887946107886\n    grad norm      : 3.482504604948741\n    accuracy       : 0.9870580808080808\n    dev_loss       : 0.05950020848957108\n    dev_accuracy   : 0.9814993564993565\n    dev_eer        : 0.035707878415090474\n    dev_frr        : 0.03571428571428571\n    dev_far        : 0.03570147111589523\n    dev_thr        : 0.017028795555233955\n    eval_loss      : 0.29629503219765013\n    eval_accuracy  : 0.9522339470139201\n    eval_eer       : 0.06415395154871179\n    eval_frr       : 0.06417403127124405\n    eval_far       : 0.06413387182617952\n    eval_thr       : 0.049721263349056244\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.009318\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.026274\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.054652\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.002611\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.010180\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.87it/s]\n    epoch          : 8\n    loss           : 0.031974925273309716\n    grad norm      : 3.507234411845642\n    accuracy       : 0.9895833333333334\n    dev_loss       : 0.06865392237782725\n    dev_accuracy   : 0.977665165216306\n    dev_eer        : 0.04072570901342237\n    dev_frr        : 0.04081632653061224\n    dev_far        : 0.040635091496232505\n    dev_thr        : 0.08171974122524261\n    eval_loss      : 0.2283911148919864\n    eval_accuracy  : 0.9438566457117198\n    eval_eer       : 0.062163697636688275\n    eval_frr       : 0.06213460231135282\n    eval_far       : 0.06219279296202373\n    eval_thr       : 0.3223157823085785\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.030872\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.001445\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000371\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.01it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.005569\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.09it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.158903\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:18<00:00,  9.85it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:45<00:00,  9.86it/s]\n    epoch          : 9\n    loss           : 0.022887613331091194\n    grad norm      : 2.5744137994126612\n    accuracy       : 0.9921085858585859\n    dev_loss       : 0.0642476066224594\n    dev_accuracy   : 0.9807486057741762\n    dev_eer        : 0.03413805490731525\n    dev_frr        : 0.03414442700156986\n    dev_far        : 0.034131682813060636\n    dev_thr        : 0.059744399040937424\n    eval_loss      : 0.25075326271577947\n    eval_accuracy  : 0.937121127076785\n    eval_eer       : 0.05751209247522587\n    eval_frr       : 0.0575118966689327\n    eval_far       : 0.05751228828151905\n    eval_thr       : 0.696983814239502\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.052817\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.000621\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.000414\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.001412\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.007074\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.85it/s]\n    epoch          : 10\n    loss           : 0.016375430552124263\n    grad norm      : 2.0957631340175116\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.10743895508317478\n    dev_accuracy   : 0.9779332904588609\n    dev_eer        : 0.08320064591208678\n    dev_frr        : 0.08320251177394035\n    dev_far        : 0.08319878005023322\n    dev_thr        : 0.0020632450468838215\n    eval_loss      : 0.4780538480810517\n    eval_accuracy  : 0.9600499550965425\n    eval_eer       : 0.08116727303831837\n    eval_frr       : 0.08116927260367097\n    eval_far       : 0.08116527347296577\n    eval_thr       : 0.002999505028128624\nSaving checkpoint: saved/models/exp9_hints_mel_inv_no_abs/1213_235854/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.001303\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.047363\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.040877\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.000787\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.003497\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 11\n    loss           : 0.02640265879848022\n    grad norm      : 2.5800046816167206\n    accuracy       : 0.9908459595959596\n    dev_loss       : 0.05607292216757799\n    dev_accuracy   : 0.9818077006088414\n    dev_eer        : 0.03847188871408462\n    dev_frr        : 0.038461538461538464\n    dev_far        : 0.038482238966630784\n    dev_thr        : 0.06603386253118515\n    eval_loss      : 0.20562501858719542\n    eval_accuracy  : 0.9475050516389762\n    eval_eer       : 0.059280288216647575\n    eval_frr       : 0.0592794017675051\n    eval_far       : 0.05928117466579005\n    eval_thr       : 0.32619214057922363\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.011891\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.002888\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.196192\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.98it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000241\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.020498\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 12\n    loss           : 0.02497992627468193\n    grad norm      : 2.5758710210023428\n    accuracy       : 0.992739898989899\n    dev_loss       : 0.06047568128129169\n    dev_accuracy   : 0.9820356070611774\n    dev_eer        : 0.03453611717105489\n    dev_frr        : 0.03453689167974882\n    dev_far        : 0.03453534266236096\n    dev_thr        : 0.0627501904964447\n    eval_loss      : 0.24063813160925826\n    eval_accuracy  : 0.9425937359676695\n    eval_eer       : 0.05549835777049081\n    eval_frr       : 0.05547246770904147\n    eval_far       : 0.05552424783194014\n    eval_thr       : 0.5744016766548157\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.018887\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.001052\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.052789\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000814\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.000182\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 13\n    loss           : 0.009582443082506118\n    grad norm      : 1.1502699598057355\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.08806101739499218\n    dev_accuracy   : 0.9817272630284039\n    dev_eer        : 0.029518286572722985\n    dev_frr        : 0.02943485086342229\n    dev_far        : 0.029601722282023683\n    dev_thr        : 0.045627694576978683\n    eval_loss      : 0.36877016702758303\n    eval_accuracy  : 0.9284912438257746\n    eval_eer       : 0.05642035958931843\n    eval_frr       : 0.05642420122365738\n    eval_far       : 0.05641651795497949\n    eval_thr       : 0.971416711807251\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.000209\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.003322\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000578\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.283112\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.020184\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 14\n    loss           : 0.02983100573578438\n    grad norm      : 3.225029452224121\n    accuracy       : 0.9903724747474747\n    dev_loss       : 0.07915951669164616\n    dev_accuracy   : 0.9722356285367694\n    dev_eer        : 0.0451268194617418\n    dev_frr        : 0.045133437990580845\n    dev_far        : 0.04512020093290276\n    dev_thr        : 0.09102951735258102\n    eval_loss      : 0.20898101904601374\n    eval_accuracy  : 0.938566457117198\n    eval_eer       : 0.06129402292138264\n    eval_frr       : 0.06131883072739633\n    eval_far       : 0.06126921511536896\n    eval_thr       : 0.5042366981506348\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.012179\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.002366\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.015061\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.001045\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.003215\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 15\n    loss           : 0.023408230554931\n    grad norm      : 1.7963673454365985\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.04405255452956375\n    dev_accuracy   : 0.9871299871299871\n    dev_eer        : 0.02668699963217878\n    dev_frr        : 0.026687598116169546\n    dev_far        : 0.026686401148188016\n    dev_thr        : 0.013978655450046062\n    eval_loss      : 0.24299382323940594\n    eval_accuracy  : 0.9479119892231702\n    eval_eer       : 0.061886850949759487\n    eval_frr       : 0.061862678450033994\n    eval_far       : 0.061911023449484986\n    eval_thr       : 0.21605108678340912\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.013080\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000181\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000198\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000639\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.001503\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 16\n    loss           : 0.013687063683814492\n    grad norm      : 1.7122957138038908\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.05100370062178741\n    dev_accuracy   : 0.9870227370483075\n    dev_eer        : 0.03148617234423785\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03157517043415859\n    dev_thr        : 0.005882903467863798\n    eval_loss      : 0.2883724910347515\n    eval_accuracy  : 0.9487679613830265\n    eval_eer       : 0.060103001346530086\n    eval_frr       : 0.06009517335146159\n    eval_far       : 0.06011082934159857\n    eval_thr       : 0.1267358809709549\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.000292\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000230\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.001197\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.001623\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000334\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 17\n    loss           : 0.009937225396013195\n    grad norm      : 1.045297685607261\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.04986184936295869\n    dev_accuracy   : 0.9888191763191764\n    dev_eer        : 0.025913300651882847\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.025923932543954073\n    dev_thr        : 0.0013200042303651571\n    eval_loss      : 0.2834888507814966\n    eval_accuracy  : 0.9477295689268074\n    eval_eer       : 0.05372233509816525\n    eval_frr       : 0.053704962610469066\n    eval_far       : 0.05373970758586143\n    eval_thr       : 0.388359010219574\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000949\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.007097\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.92it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000098\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000757\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.018500\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 18\n    loss           : 0.01909705621378956\n    grad norm      : 2.067600915719981\n    accuracy       : 0.9940025252525253\n    dev_loss       : 0.053506277847982356\n    dev_accuracy   : 0.9850788288288288\n    dev_eer        : 0.040372497844049435\n    dev_frr        : 0.04042386185243328\n    dev_far        : 0.04032113383566559\n    dev_thr        : 0.01847696490585804\n    eval_loss      : 0.23832496409208254\n    eval_accuracy  : 0.9426218006286484\n    eval_eer       : 0.06443862516654442\n    eval_frr       : 0.06444595513256288\n    eval_far       : 0.06443129520052597\n    eval_thr       : 0.2387254536151886\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.013723\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.016531\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000080\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.033812\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.001370\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.85it/s]\n    epoch          : 19\n    loss           : 0.01605275561787218\n    grad norm      : 1.8310320063263668\n    accuracy       : 0.9949494949494949\n    dev_loss       : 0.050168513638843\n    dev_accuracy   : 0.986003861003861\n    dev_eer        : 0.028256823139954004\n    dev_frr        : 0.0282574568288854\n    dev_far        : 0.028256189451022606\n    dev_thr        : 0.004935495089739561\n    eval_loss      : 0.25161644519019416\n    eval_accuracy  : 0.9384962954647508\n    eval_eer       : 0.06713664965769761\n    eval_frr       : 0.0671651937457512\n    eval_far       : 0.06710810556964403\n    eval_thr       : 0.3089151978492737\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.050103\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.003601\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000227\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.002462\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000103\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 20\n    loss           : 0.008785176219070575\n    grad norm      : 0.825525186604331\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.04417186457895875\n    dev_accuracy   : 0.9900659588159588\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.0019372826209291816\n    eval_loss      : 0.2788712039098789\n    eval_accuracy  : 0.9465508531656938\n    eval_eer       : 0.051800062151471454\n    eval_frr       : 0.051801495581237256\n    eval_far       : 0.051798628721705646\n    eval_thr       : 0.6314248442649841\nSaving checkpoint: saved/models/exp9_hints_mel_inv_no_abs/1213_235854/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000148\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000575\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.000764\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.99it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000232\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000177\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 21\n    loss           : 0.0077840217431499195\n    grad norm      : 1.236362526638932\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.05832314483960431\n    dev_accuracy   : 0.9865267052767053\n    dev_eer        : 0.02942858438398958\n    dev_frr        : 0.02943485086342229\n    dev_far        : 0.02942231790455687\n    dev_thr        : 0.0013706132303923368\n    eval_loss      : 0.2540188965279604\n    eval_accuracy  : 0.9533144364616075\n    eval_eer       : 0.053330545860483636\n    eval_frr       : 0.05329707681849082\n    eval_far       : 0.05336401490247644\n    eval_thr       : 0.18790751695632935\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000967\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.001093\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.000050\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000438\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.001405\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 22\n    loss           : 0.013273104514210541\n    grad norm      : 0.968267464652808\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.03149951128888691\n    dev_accuracy   : 0.9913127413127413\n    dev_eer        : 0.021977529108853117\n    dev_frr        : 0.02197802197802198\n    dev_far        : 0.02197703623968425\n    dev_thr        : 0.02872563898563385\n    eval_loss      : 0.22371933303440703\n    eval_accuracy  : 0.9463964975303099\n    eval_eer       : 0.05234592859442517\n    eval_frr       : 0.052345343303874914\n    eval_far       : 0.052346513884975424\n    eval_thr       : 0.5566708445549011\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000362\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000232\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000462\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000068\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.003910\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 23\n    loss           : 0.014536627245553348\n    grad norm      : 1.4517811022915248\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.051347554213143465\n    dev_accuracy   : 0.9869288931788932\n    dev_eer        : 0.03210289249425033\n    dev_frr        : 0.03218210361067504\n    dev_far        : 0.032023681377825616\n    dev_thr        : 0.006774199660867453\n    eval_loss      : 0.2724565535833141\n    eval_accuracy  : 0.9454703637180063\n    eval_eer       : 0.05628976317675789\n    eval_frr       : 0.05628823929299796\n    eval_far       : 0.05629128706051783\n    eval_thr       : 0.41470038890838623\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.000601\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000815\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000532\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.018989\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000326\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 24\n    loss           : 0.012441215061846029\n    grad norm      : 0.9323224582805797\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.04108071063873183\n    dev_accuracy   : 0.9904279279279279\n    dev_eer        : 0.027858760876214358\n    dev_frr        : 0.027864992150706435\n    dev_far        : 0.02785252960172228\n    dev_thr        : 0.004709715489298105\n    eval_loss      : 0.2841397097798685\n    eval_accuracy  : 0.9460176246070947\n    eval_eer       : 0.05696622603227215\n    eval_frr       : 0.056968048946295036\n    eval_far       : 0.056964403118249275\n    eval_thr       : 0.2925657331943512\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.002156\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000525\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.002132\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.033040\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.025573\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 25\n    loss           : 0.014409127132717234\n    grad norm      : 1.3878037087017236\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.031528064989352775\n    dev_accuracy   : 0.9918355855855856\n    dev_eer        : 0.020805767864817533\n    dev_frr        : 0.020800627943485087\n    dev_far        : 0.020810907786149982\n    dev_thr        : 0.010938756167888641\n    eval_loss      : 0.22343528846996882\n    eval_accuracy  : 0.9367843511450382\n    eval_eer       : 0.053860758441629644\n    eval_frr       : 0.05384092454112848\n    eval_far       : 0.0538805923421308\n    eval_thr       : 0.8274410367012024\nSaving checkpoint: saved/models/exp9_hints_mel_inv_no_abs/1213_235854/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp11.json","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:23:06.684735Z","iopub.execute_input":"2023-12-14T08:23:06.685271Z","iopub.status.idle":"2023-12-14T11:27:42.920031Z","shell.execute_reply.started":"2023-12-14T08:23:06.685237Z","shell.execute_reply":"2023-12-14T11:27:42.919014Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231214_082317-n4a042nm\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdulcet-snow-14\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/n4a042nm\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.693097\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:37<01:40,  5.94it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.273667\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:11<01:06,  5.96it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.121190\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:44<00:33,  5.95it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.055662\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:17<00:00,  6.07it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.074919\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:17<00:00,  5.77it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:51<00:00,  9.61it/s]\n    epoch          : 1\n    loss           : 0.1601601862054638\n    grad norm      : 11.077937241305005\n    accuracy       : 0.9411300505050505\n    dev_loss       : 0.275678086928868\n    dev_accuracy   : 0.9040245603257011\n    dev_eer        : 0.08048148670745933\n    dev_frr        : 0.0804552590266876\n    dev_far        : 0.08050771438823107\n    dev_thr        : 0.7216417789459229\n    eval_loss      : 0.32549420887977387\n    eval_accuracy  : 0.8827879434216435\n    eval_eer       : 0.09668141854252821\n    eval_frr       : 0.09666893269884433\n    eval_far       : 0.09669390438621207\n    eval_thr       : 0.8471658229827881\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.007041\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.043560\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.135785\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.94it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.024688\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.130100\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 2\n    loss           : 0.11427749908703257\n    grad norm      : 7.956046359406577\n    accuracy       : 0.9589646464646465\n    dev_loss       : 0.09566802307744625\n    dev_accuracy   : 0.9657335907335908\n    dev_eer        : 0.0541476982446535\n    dev_frr        : 0.05416012558869702\n    dev_far        : 0.054135270900609975\n    dev_thr        : 0.2490224987268448\n    eval_loss      : 0.20791225535456354\n    eval_accuracy  : 0.9408481140601351\n    eval_eer       : 0.07152706199403894\n    eval_frr       : 0.07151597552685249\n    eval_far       : 0.07153814846122539\n    eval_thr       : 0.33286136388778687\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.018160\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.010754\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.109409\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.93it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.155575\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.015535\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.83it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.84it/s]\n    epoch          : 3\n    loss           : 0.08821884931695431\n    grad norm      : 6.546640651846173\n    accuracy       : 0.9701704545454546\n    dev_loss       : 0.08653747737163467\n    dev_accuracy   : 0.9696884384640089\n    dev_eer        : 0.04393263267052287\n    dev_frr        : 0.04395604395604396\n    dev_far        : 0.04390922138500179\n    dev_thr        : 0.18662849068641663\n    eval_loss      : 0.22197885178828292\n    eval_accuracy  : 0.9293893129770993\n    eval_eer       : 0.07355645056058172\n    eval_frr       : 0.0735554044867437\n    eval_far       : 0.07355749663441971\n    eval_thr       : 0.42427846789360046\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.014220\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.026007\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.088755\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.066506\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.015128\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 4\n    loss           : 0.08047087235150463\n    grad norm      : 6.598191931881387\n    accuracy       : 0.9726957070707071\n    dev_loss       : 0.11281220989087248\n    dev_accuracy   : 0.9592181467181468\n    dev_eer        : 0.04081541120215578\n    dev_frr        : 0.04081632653061224\n    dev_far        : 0.04081449587369932\n    dev_thr        : 0.4934063255786896\n    eval_loss      : 0.23707770182856505\n    eval_accuracy  : 0.911890996856758\n    eval_eer       : 0.06580720473938065\n    eval_frr       : 0.06580557443915704\n    eval_far       : 0.06580883503960427\n    eval_thr       : 0.8783798813819885\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.024129\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.004209\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.076441\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.049020\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.003815\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 5\n    loss           : 0.05826203189578585\n    grad norm      : 5.013416215739768\n    accuracy       : 0.9790088383838383\n    dev_loss       : 0.06266907626811155\n    dev_accuracy   : 0.9782550407806112\n    dev_eer        : 0.03413805490731525\n    dev_frr        : 0.03414442700156986\n    dev_far        : 0.034131682813060636\n    dev_thr        : 0.03184985741972923\n    eval_loss      : 0.2055457173867049\n    eval_accuracy  : 0.9568505837449484\n    eval_eer       : 0.05631324396946946\n    eval_frr       : 0.05628823929299796\n    eval_far       : 0.056338248645940954\n    eval_thr       : 0.1590183526277542\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.194261\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.001463\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.011810\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.007955\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.040438\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.82it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 6\n    loss           : 0.05339624707568249\n    grad norm      : 5.197038898075169\n    accuracy       : 0.9827967171717171\n    dev_loss       : 0.10107491449815517\n    dev_accuracy   : 0.9597275847787256\n    dev_eer        : 0.031816957966427445\n    dev_frr        : 0.031789638932496075\n    dev_far        : 0.03184427700035881\n    dev_thr        : 0.6072142124176025\n    eval_loss      : 0.18886178075496926\n    eval_accuracy  : 0.9001880332285586\n    eval_eer       : 0.056835629619711614\n    eval_frr       : 0.05683208701563562\n    eval_far       : 0.05683917222378761\n    eval_thr       : 0.8962446451187134\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.084486\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.061148\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.170262\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.014675\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.000460\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 7\n    loss           : 0.03243034041628966\n    grad norm      : 2.8837170985884812\n    accuracy       : 0.9906881313131313\n    dev_loss       : 0.06555819375828867\n    dev_accuracy   : 0.984475546975547\n    dev_eer        : 0.04004171222185984\n    dev_frr        : 0.040031397174254316\n    dev_far        : 0.04005202726946538\n    dev_thr        : 0.0030478190165013075\n    eval_loss      : 0.20923021958091903\n    eval_accuracy  : 0.9594886618769646\n    eval_eer       : 0.048647632975405815\n    eval_frr       : 0.0486743711760707\n    eval_far       : 0.04862089477474093\n    eval_thr       : 0.1927463710308075\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.002349\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.012702\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.117571\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.006600\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.002541\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.83it/s]\n    epoch          : 8\n    loss           : 0.02416917503800542\n    grad norm      : 2.5010540242485626\n    accuracy       : 0.9911616161616161\n    dev_loss       : 0.05156335134415479\n    dev_accuracy   : 0.9853603603603603\n    dev_eer        : 0.03453611717105489\n    dev_frr        : 0.03453689167974882\n    dev_far        : 0.03453534266236096\n    dev_thr        : 0.020987944677472115\n    eval_loss      : 0.1994375090079644\n    eval_accuracy  : 0.9487679613830265\n    eval_eer       : 0.05901126846062264\n    eval_frr       : 0.05900747790618627\n    eval_far       : 0.05901505901505902\n    eval_thr       : 0.32432106137275696\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.041983\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.003038\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000940\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.96it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.016668\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.000116\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 9\n    loss           : 0.0154877347096147\n    grad norm      : 2.1987685606264593\n    accuracy       : 0.9949494949494949\n    dev_loss       : 0.06437358942510323\n    dev_accuracy   : 0.9820490133501542\n    dev_eer        : 0.02345765042789493\n    dev_frr        : 0.023547880690737835\n    dev_far        : 0.023367420165052027\n    dev_thr        : 0.1469188928604126\n    eval_loss      : 0.22697413308644954\n    eval_accuracy  : 0.9336551414458913\n    eval_eer       : 0.05001621254824204\n    eval_frr       : 0.05003399048266485\n    eval_far       : 0.049998434613819226\n    eval_thr       : 0.9465956091880798\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.048081\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.000921\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.007785\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.99it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.000652\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.001643\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 10\n    loss           : 0.04459156119470447\n    grad norm      : 3.5397279447772436\n    accuracy       : 0.9835858585858586\n    dev_loss       : 0.04940996326569365\n    dev_accuracy   : 0.9845157657657657\n    dev_eer        : 0.025913300651882847\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.025923932543954073\n    dev_thr        : 0.01692785881459713\n    eval_loss      : 0.225063315847943\n    eval_accuracy  : 0.938869555461123\n    eval_eer       : 0.06294727611205152\n    eval_frr       : 0.06295037389530932\n    eval_far       : 0.06294417832879372\n    eval_thr       : 0.42996856570243835\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.001550\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.89it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000360\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.000163\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.003376\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.051489\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 11\n    loss           : 0.01818306893755557\n    grad norm      : 1.8844763101595972\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.042980841427359445\n    dev_accuracy   : 0.9888593951093951\n    dev_eer        : 0.01735776077426085\n    dev_frr        : 0.01726844583987441\n    dev_far        : 0.01744707570864729\n    dev_thr        : 0.04915788769721985\n    eval_loss      : 0.21948220965419402\n    eval_accuracy  : 0.9398714638527167\n    eval_eer       : 0.045435049764914325\n    eval_frr       : 0.04541128484024473\n    eval_far       : 0.04545881468958392\n    eval_thr       : 0.925189197063446\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.000409\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.003747\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.169043\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.002350\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.006556\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 12\n    loss           : 0.03793628378230326\n    grad norm      : 3.459351913909418\n    accuracy       : 0.9884785353535354\n    dev_loss       : 0.041646525226236006\n    dev_accuracy   : 0.9838052338308042\n    dev_eer        : 0.02511717612440356\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.025116612845353426\n    dev_thr        : 0.18577609956264496\n    eval_loss      : 0.19690434655579636\n    eval_accuracy  : 0.922611697350696\n    eval_eer       : 0.053730162029069106\n    eval_frr       : 0.053704962610469066\n    eval_far       : 0.05375536144766914\n    eval_thr       : 0.8497675657272339\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.008545\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.000514\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.001460\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000598\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.010855\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 13\n    loss           : 0.017232757569493544\n    grad norm      : 1.1797572690617255\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.08445379323423963\n    dev_accuracy   : 0.973509223534794\n    dev_eer        : 0.03022470891146887\n    dev_frr        : 0.03021978021978022\n    dev_far        : 0.030229637603157517\n    dev_thr        : 0.3835113048553467\n    eval_loss      : 0.2839833871070908\n    eval_accuracy  : 0.8924702514593623\n    eval_eer       : 0.06430802875398389\n    eval_frr       : 0.06430999320190346\n    eval_far       : 0.06430606430606431\n    eval_thr       : 0.9709907174110413\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.010021\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.003256\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.077935\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.006960\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.000539\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.81it/s]\n    epoch          : 14\n    loss           : 0.022118486322987605\n    grad norm      : 2.6033262420031758\n    accuracy       : 0.9925820707070707\n    dev_loss       : 0.08811482160325838\n    dev_accuracy   : 0.9770752895752896\n    dev_eer        : 0.019566729979231902\n    dev_frr        : 0.019623233908948195\n    dev_far        : 0.01951022604951561\n    dev_thr        : 0.7311227917671204\n    eval_loss      : 0.29464993662227057\n    eval_accuracy  : 0.9108806690615178\n    eval_eer       : 0.05356825789289315\n    eval_frr       : 0.05356900067980965\n    eval_far       : 0.05356751510597665\n    eval_thr       : 0.9940124154090881\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.000357\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.001162\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.000736\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:34,  5.88it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.001812\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000165\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 15\n    loss           : 0.021462816503833783\n    grad norm      : 1.8195238408698426\n    accuracy       : 0.9952651515151515\n    dev_loss       : 0.08394134695883582\n    dev_accuracy   : 0.9813787001287001\n    dev_eer        : 0.035707878415090474\n    dev_frr        : 0.03571428571428571\n    dev_far        : 0.03570147111589523\n    dev_thr        : 0.0016583848046138883\n    eval_loss      : 0.25202931257255684\n    eval_accuracy  : 0.9504237763807813\n    eval_eer       : 0.05504395308557836\n    eval_frr       : 0.055064581917063225\n    eval_far       : 0.05502332425409349\n    eval_thr       : 0.2060757279396057\nSaving checkpoint: saved/models/exp11_hints_lin_no_abs/1214_082312/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.000480\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000845\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.001233\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000569\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.000304\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 16\n    loss           : 0.015730697247349643\n    grad norm      : 1.5382681908603344\n    accuracy       : 0.9957386363636364\n    dev_loss       : 0.0499060107135806\n    dev_accuracy   : 0.98869851994852\n    dev_eer        : 0.0314637467970545\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03153031933979189\n    dev_thr        : 0.013876456767320633\n    eval_loss      : 0.2750048514185206\n    eval_accuracy  : 0.9321536820835205\n    eval_eer       : 0.048101766532452093\n    eval_frr       : 0.048130523453433036\n    eval_far       : 0.04807300961147115\n    eval_thr       : 0.9754289388656616\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.000699\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.99it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.050357\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000214\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  6.00it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000209\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.001287\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 17\n    loss           : 0.0073113746252005\n    grad norm      : 0.893218445263549\n    accuracy       : 0.9977904040404041\n    dev_loss       : 0.05980863888364003\n    dev_accuracy   : 0.9871702059202059\n    dev_eer        : 0.02122625567574053\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.021259418729817008\n    dev_thr        : 0.00037962949136272073\n    eval_loss      : 0.2257323317286103\n    eval_accuracy  : 0.9574118769645262\n    eval_eer       : 0.047179764713624464\n    eval_frr       : 0.047178789938817134\n    eval_far       : 0.047180739488431794\n    eval_thr       : 0.216955304145813\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000116\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.003152\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000672\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000650\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.002084\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.81it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 18\n    loss           : 0.015145723112355982\n    grad norm      : 1.0955009066389234\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.03411694055214432\n    dev_accuracy   : 0.9906290218790219\n    dev_eer        : 0.0173353352270775\n    dev_frr        : 0.01726844583987441\n    dev_far        : 0.01740222461428059\n    dev_thr        : 0.1871272474527359\n    eval_loss      : 0.22453787800455827\n    eval_accuracy  : 0.9244078356533453\n    eval_eer       : 0.0501937705462257\n    eval_frr       : 0.05016995241332427\n    eval_far       : 0.050217588679127144\n    eval_thr       : 0.9676306843757629\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.002395\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.001514\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000453\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.002606\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.001151\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 19\n    loss           : 0.014582204279834357\n    grad norm      : 1.3613830331214374\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.037165338230910984\n    dev_accuracy   : 0.9875723938223938\n    dev_eer        : 0.018109034207373434\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018164693218514532\n    dev_thr        : 0.12530827522277832\n    eval_loss      : 0.17459589531520503\n    eval_accuracy  : 0.9381314548720251\n    eval_eer       : 0.04299039116797837\n    eval_frr       : 0.042963970088375256\n    eval_far       : 0.04301681224758148\n    eval_thr       : 0.9063245058059692\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000516\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000059\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000260\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000259\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.002657\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 20\n    loss           : 0.02032991670362529\n    grad norm      : 1.6282056477532318\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.03224316595629831\n    dev_accuracy   : 0.9906022093777798\n    dev_eer        : 0.013730349306237358\n    dev_frr        : 0.013736263736263736\n    dev_far        : 0.01372443487621098\n    dev_thr        : 0.21293115615844727\n    eval_loss      : 0.19386243633314304\n    eval_accuracy  : 0.9258110687022901\n    eval_eer       : 0.0394148650306157\n    eval_frr       : 0.03942895989123046\n    eval_far       : 0.03940077017000094\n    eval_thr       : 0.9809795022010803\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.001603\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000324\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.000625\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.003260\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000320\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.81it/s]\n    epoch          : 21\n    loss           : 0.011228807063786797\n    grad norm      : 1.193495582210634\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.08056533108217878\n    dev_accuracy   : 0.9845559845559846\n    dev_eer        : 0.04004171222185984\n    dev_frr        : 0.040031397174254316\n    dev_far        : 0.04005202726946538\n    dev_thr        : 0.00019001451437361538\n    eval_loss      : 0.2546689305308549\n    eval_accuracy  : 0.9613128648405928\n    eval_eer       : 0.04839426708118859\n    eval_frr       : 0.04840244731475187\n    eval_far       : 0.04838608684762531\n    eval_thr       : 0.08180465549230576\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000518\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.001763\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.001751\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.001314\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.001033\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 22\n    loss           : 0.01584059864229986\n    grad norm      : 1.231516911121405\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.052693221297116136\n    dev_accuracy   : 0.983510296010296\n    dev_eer        : 0.022683951447598993\n    dev_frr        : 0.022762951334379906\n    dev_far        : 0.022604951560818085\n    dev_thr        : 0.1466418355703354\n    eval_loss      : 0.22439835955322246\n    eval_accuracy  : 0.9239447687471936\n    eval_eer       : 0.058057958918179595\n    eval_frr       : 0.05805574439157036\n    eval_far       : 0.05806017344478883\n    eval_thr       : 0.9124867916107178\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.001464\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.001178\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000322\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.001077\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000217\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 23\n    loss           : 0.008707551103615322\n    grad norm      : 0.7881779117460335\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.05972567171757268\n    dev_accuracy   : 0.9872104247104247\n    dev_eer        : 0.02699535970718502\n    dev_frr        : 0.02708006279434851\n    dev_far        : 0.02691065662002153\n    dev_thr        : 0.0008236202993430197\n    eval_loss      : 0.22950740011635495\n    eval_accuracy  : 0.9572294566681635\n    eval_eer       : 0.050700502334660155\n    eval_frr       : 0.05071380013596193\n    eval_far       : 0.05068720453335838\n    eval_thr       : 0.2083522379398346\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.048720\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000768\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.94it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000383\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000980\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000132\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 24\n    loss           : 0.004923321550137703\n    grad norm      : 0.30142071747927773\n    accuracy       : 0.9985795454545454\n    dev_loss       : 0.047333338497711444\n    dev_accuracy   : 0.9914736164736164\n    dev_eer        : 0.02511717612440356\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.025116612845353426\n    dev_thr        : 0.0003422301379032433\n    eval_loss      : 0.25639359251332816\n    eval_accuracy  : 0.9482627974854064\n    eval_eer       : 0.049624423310560425\n    eval_frr       : 0.04962610469068661\n    eval_far       : 0.04962274193043424\n    eval_thr       : 0.6112122535705566\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000101\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  6.00it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000175\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000175\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.002643\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.001347\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.80it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:46<00:00,  9.82it/s]\n    epoch          : 25\n    loss           : 0.0060202319842629195\n    grad norm      : 0.8277840514998351\n    accuracy       : 0.998895202020202\n    dev_loss       : 0.04904515810750376\n    dev_accuracy   : 0.9878539253539254\n    dev_eer        : 0.021646743486663525\n    dev_frr        : 0.021585557299843013\n    dev_far        : 0.021707929673484033\n    dev_thr        : 0.0013978732749819756\n    eval_loss      : 0.22933147984790678\n    eval_accuracy  : 0.951448136506511\n    eval_eer       : 0.0509851759524928\n    eval_frr       : 0.05098572399728076\n    eval_far       : 0.05098462790770483\n    eval_thr       : 0.37912049889564514\nSaving checkpoint: saved/models/exp11_hints_lin_no_abs/1214_082312/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/exp13/exp13.json","metadata":{"execution":{"iopub.status.busy":"2023-12-14T11:59:59.459598Z","iopub.execute_input":"2023-12-14T11:59:59.460020Z","iopub.status.idle":"2023-12-14T15:23:18.395343Z","shell.execute_reply.started":"2023-12-14T11:59:59.459986Z","shell.execute_reply":"2023-12-14T15:23:18.394075Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv_fast()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231214_120005-taaocqa6\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwandering-lake-16\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/taaocqa6\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.688962\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:45<02:11,  4.54it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.706955\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.52it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.504851\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:12<00:44,  4.54it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.708080\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:56<00:00,  4.59it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.319415\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.50it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 1\n    loss           : 0.5034079491490066\n    grad norm      : 7.367345237370693\n    accuracy       : 0.7814078282828283\n    dev_loss       : 0.6933611975635188\n    dev_accuracy   : 0.7015765765765766\n    dev_eer        : 0.2409791212170883\n    dev_frr        : 0.24097331240188383\n    dev_far        : 0.2409849300322928\n    dev_thr        : 0.6491252779960632\n    eval_loss      : 0.49218176422723486\n    eval_accuracy  : 0.8061012572968118\n    eval_eer       : 0.19127866000218666\n    eval_frr       : 0.19129843643779743\n    eval_far       : 0.1912588835665759\n    eval_thr       : 0.5156989097595215\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.786304\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.249866\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.258448\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.53it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.206101\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.154930\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.53it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.73it/s]\n    epoch          : 2\n    loss           : 0.2481013476999119\n    grad norm      : 6.730387601587507\n    accuracy       : 0.9010416666666666\n    dev_loss       : 0.2383084664806877\n    dev_accuracy   : 0.9017454954954955\n    dev_eer        : 0.18139310456317992\n    dev_frr        : 0.1813186813186813\n    dev_far        : 0.1814675278076785\n    dev_thr        : 0.19129574298858643\n    eval_loss      : 0.46207519940995134\n    eval_accuracy  : 0.8785501796138303\n    eval_eer       : 0.15212498779669203\n    eval_frr       : 0.1521414004078858\n    eval_far       : 0.15210857518549825\n    eval_thr       : 0.18878033757209778\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.277124\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.54it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.129542\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.111339\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.51it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.075066\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.075050\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.72it/s]\n    epoch          : 3\n    loss           : 0.20537090335379948\n    grad norm      : 6.609595009172805\n    accuracy       : 0.9299242424242424\n    dev_loss       : 0.22184676606270415\n    dev_accuracy   : 0.9147093522349227\n    dev_eer        : 0.14081877679448032\n    dev_frr        : 0.14089481946624804\n    dev_far        : 0.1407427341227126\n    dev_thr        : 0.13551433384418488\n    eval_loss      : 0.4522598444408481\n    eval_accuracy  : 0.8874326448136507\n    eval_eer       : 0.13525008965054983\n    eval_frr       : 0.13528212100611828\n    eval_far       : 0.13521805829498137\n    eval_thr       : 0.16776065528392792\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.073392\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.187173\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.51it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.022292\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.52it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.071739\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.082564\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.73it/s]\n    epoch          : 4\n    loss           : 0.13189918357841293\n    grad norm      : 6.336209247810672\n    accuracy       : 0.952020202020202\n    dev_loss       : 0.16763920628696743\n    dev_accuracy   : 0.9346846846846847\n    dev_eer        : 0.10871588430022999\n    dev_frr        : 0.108712715855573\n    dev_far        : 0.10871905274488698\n    dev_thr        : 0.12349345535039902\n    eval_loss      : 0.4284399188720409\n    eval_accuracy  : 0.8958885271719448\n    eval_eer       : 0.12003627162598035\n    eval_frr       : 0.12005438477226377\n    eval_far       : 0.12001815847969693\n    eval_thr       : 0.2088288813829422\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.032567\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.53it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.009442\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.52it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.024139\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.128394\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.029415\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 5\n    loss           : 0.09600351485682444\n    grad norm      : 5.507286753994648\n    accuracy       : 0.9644886363636364\n    dev_loss       : 0.26329999656564507\n    dev_accuracy   : 0.8990240240495945\n    dev_eer        : 0.09732905748206379\n    dev_frr        : 0.09733124018838304\n    dev_far        : 0.09732687477574453\n    dev_thr        : 0.5299577116966248\n    eval_loss      : 0.410768449688301\n    eval_accuracy  : 0.8735406376290974\n    eval_eer       : 0.11978290573176313\n    eval_frr       : 0.11978246091094494\n    eval_far       : 0.11978335055258132\n    eval_thr       : 0.6255894899368286\nSaving checkpoint: saved/models/exp13_hints_no_abs_no_base_sinc_no_zero/1214_120003/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.225780\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.005753\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.107896\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.52it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.069906\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.59it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.005287\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 6\n    loss           : 0.07308154687287775\n    grad norm      : 4.435353993127744\n    accuracy       : 0.9739583333333334\n    dev_loss       : 0.143572944999724\n    dev_accuracy   : 0.956188331239472\n    dev_eer        : 0.07031127222769543\n    dev_frr        : 0.07025117739403454\n    dev_far        : 0.0703713670613563\n    dev_thr        : 0.10336942225694656\n    eval_loss      : 0.4317146832813736\n    eval_accuracy  : 0.8997951279748541\n    eval_eer       : 0.10170133214896065\n    eval_frr       : 0.1016995241332427\n    eval_far       : 0.10170314016467863\n    eval_thr       : 0.45357024669647217\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.014889\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.52it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.021865\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.50it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.107997\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.51it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.053582\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.002591\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 7\n    loss           : 0.07116451583957921\n    grad norm      : 4.2265830931413655\n    accuracy       : 0.9744318181818182\n    dev_loss       : 0.1159084339013642\n    dev_accuracy   : 0.9646074646074646\n    dev_eer        : 0.07294072924358946\n    dev_frr        : 0.07299843014128729\n    dev_far        : 0.07288302834589164\n    dev_thr        : 0.009835544042289257\n    eval_loss      : 0.4881529364794795\n    eval_accuracy  : 0.9230551189995154\n    eval_eer       : 0.10060959926305321\n    eval_frr       : 0.10061182868796736\n    eval_far       : 0.10060736983813907\n    eval_thr       : 0.035890862345695496\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.027987\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.002448\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.52it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.027744\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.53it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.111914\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.56it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.057122\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 8\n    loss           : 0.05160253585552599\n    grad norm      : 3.7981954329656533\n    accuracy       : 0.9826388888888888\n    dev_loss       : 0.11623284829126616\n    dev_accuracy   : 0.9611084298584298\n    dev_eer        : 0.07024399558614536\n    dev_frr        : 0.07025117739403454\n    dev_far        : 0.07023681377825619\n    dev_thr        : 0.057108886539936066\n    eval_loss      : 0.41892365920612507\n    eval_accuracy  : 0.9148518185900314\n    eval_eer       : 0.0992253658284093\n    eval_frr       : 0.09925220938137322\n    eval_far       : 0.09919852227544536\n    eval_thr       : 0.14865323901176453\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.021145\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.54it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.210837\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.087633\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.020083\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.001544\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 9\n    loss           : 0.029439710769855246\n    grad norm      : 2.7661467517933085\n    accuracy       : 0.9881628787878788\n    dev_loss       : 0.09240866978934262\n    dev_accuracy   : 0.9722892535392536\n    dev_eer        : 0.052975937000617916\n    dev_frr        : 0.052982731554160126\n    dev_far        : 0.05296914244707571\n    dev_thr        : 0.016653260216116905\n    eval_loss      : 0.41714316450226063\n    eval_accuracy  : 0.930259317467445\n    eval_eer       : 0.08592599381962976\n    eval_frr       : 0.08592794017675051\n    eval_far       : 0.085924047462509\n    eval_thr       : 0.08507944643497467\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.017754\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.027242\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.51it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.001942\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.52it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.003137\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.59it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.003877\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 10\n    loss           : 0.03422115798045956\n    grad norm      : 2.9445879486285977\n    accuracy       : 0.9875315656565656\n    dev_loss       : 0.10790700321434847\n    dev_accuracy   : 0.9633204633204633\n    dev_eer        : 0.06672871185403863\n    dev_frr        : 0.06671899529042387\n    dev_far        : 0.06673842841765339\n    dev_thr        : 0.0586509145796299\n    eval_loss      : 0.3773575167917719\n    eval_accuracy  : 0.9199539739613475\n    eval_eer       : 0.09791940170280389\n    eval_frr       : 0.09789259007477906\n    eval_far       : 0.09794621333082872\n    eval_thr       : 0.1762790083885193\nSaving checkpoint: saved/models/exp13_hints_no_abs_no_base_sinc_no_zero/1214_120003/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.007831\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.53it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.021649\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.005561\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.50it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.059154\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.058884\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 11\n    loss           : 0.03383224743337258\n    grad norm      : 2.7630935328485764\n    accuracy       : 0.9883207070707071\n    dev_loss       : 0.07870656684040236\n    dev_accuracy   : 0.9743538181293885\n    dev_eer        : 0.04749276749699631\n    dev_frr        : 0.04748822605965463\n    dev_far        : 0.047497308934338\n    dev_thr        : 0.03762180358171463\n    eval_loss      : 0.33048200070119155\n    eval_accuracy  : 0.9138779748594167\n    eval_eer       : 0.08662593746785557\n    eval_frr       : 0.08660774983004758\n    eval_far       : 0.08664412510566356\n    eval_thr       : 0.481789231300354\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.001458\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.062131\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.52it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.019489\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.51it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.005987\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.000712\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 12\n    loss           : 0.030834451897511956\n    grad norm      : 2.1747563856870236\n    accuracy       : 0.9886363636363636\n    dev_loss       : 0.07303795307756214\n    dev_accuracy   : 0.9780271343282751\n    dev_eer        : 0.03807382645034498\n    dev_frr        : 0.0380690737833595\n    dev_far        : 0.038078579117330466\n    dev_thr        : 0.014973479323089123\n    eval_loss      : 0.37988126512042797\n    eval_accuracy  : 0.922914795694621\n    eval_eer       : 0.08549506992742886\n    eval_frr       : 0.08552005438477227\n    eval_far       : 0.08547008547008547\n    eval_thr       : 0.20671656727790833\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.005012\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.54it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.001130\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.52it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.001784\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.53it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.002060\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.001220\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 13\n    loss           : 0.032902698731049895\n    grad norm      : 2.444758839557192\n    accuracy       : 0.9881628787878788\n    dev_loss       : 0.07067560625304023\n    dev_accuracy   : 0.9763111325611326\n    dev_eer        : 0.04282814806803735\n    dev_frr        : 0.04277864992150707\n    dev_far        : 0.04287764621456763\n    dev_thr        : 0.06438691169023514\n    eval_loss      : 0.32290450466168835\n    eval_accuracy  : 0.9117506735518635\n    eval_eer       : 0.08604093637038258\n    eval_frr       : 0.08606390210740993\n    eval_far       : 0.08601797063335524\n    eval_thr       : 0.5602397918701172\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.001669\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.000956\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.54it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000282\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.51it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.004326\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.008273\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 14\n    loss           : 0.0276939476170075\n    grad norm      : 2.3337053055827965\n    accuracy       : 0.9903724747474747\n    dev_loss       : 0.08078414467750891\n    dev_accuracy   : 0.9743806306306306\n    dev_eer        : 0.03884752543064092\n    dev_frr        : 0.03885400313971742\n    dev_far        : 0.03884104772156441\n    dev_thr        : 0.009664802812039852\n    eval_loss      : 0.39482996288565086\n    eval_accuracy  : 0.9346738886447782\n    eval_eer       : 0.08484208786462616\n    eval_frr       : 0.08484024473147518\n    eval_far       : 0.08484393099777715\n    eval_thr       : 0.05935729667544365\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.001077\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.53it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.000372\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.50it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.070180\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.000578\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.001576\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 15\n    loss           : 0.028797211021718786\n    grad norm      : 2.6537929134951397\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.09800168397680042\n    dev_accuracy   : 0.9701308451564156\n    dev_eer        : 0.05761813088239354\n    dev_frr        : 0.057692307692307696\n    dev_far        : 0.05754395407247937\n    dev_thr        : 0.033960700035095215\n    eval_loss      : 0.3284092287243489\n    eval_accuracy  : 0.9255304220925011\n    eval_eer       : 0.08292764184883622\n    eval_frr       : 0.08293677770224338\n    eval_far       : 0.08291850599542908\n    eval_thr       : 0.2760563790798187\nSaving checkpoint: saved/models/exp13_hints_no_abs_no_base_sinc_no_zero/1214_120003/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.001892\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.52it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.009345\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.51it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000584\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.52it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.009625\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.56it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.000755\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 16\n    loss           : 0.03580461229498127\n    grad norm      : 2.5518566500442574\n    accuracy       : 0.9884785353535354\n    dev_loss       : 0.08143576308966155\n    dev_accuracy   : 0.9769144144144144\n    dev_eer        : 0.051406113492842694\n    dev_frr        : 0.05141287284144427\n    dev_far        : 0.05139935414424112\n    dev_thr        : 0.027649488300085068\n    eval_loss      : 0.38061951282373\n    eval_accuracy  : 0.9142905253704535\n    eval_eer       : 0.08864749910349451\n    eval_frr       : 0.08864717878993882\n    eval_far       : 0.08864781941705019\n    eval_thr       : 0.41524726152420044\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.004235\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.55it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000212\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.52it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000125\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.52it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.003142\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.019408\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 17\n    loss           : 0.019468301230076715\n    grad norm      : 1.8441375609948252\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.08746112670313225\n    dev_accuracy   : 0.9722892535392536\n    dev_eer        : 0.03301114475764637\n    dev_frr        : 0.03296703296703297\n    dev_far        : 0.033055256548259776\n    dev_thr        : 0.28582003712654114\n    eval_loss      : 0.39275223093485706\n    eval_accuracy  : 0.8933542882801976\n    eval_eer       : 0.08933178888991261\n    eval_frr       : 0.08932698844323589\n    eval_far       : 0.08933658933658933\n    eval_thr       : 0.8858963847160339\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.146093\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.50it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.161892\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:27,  4.53it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.001580\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.51it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.016481\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.001150\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 18\n    loss           : 0.013963231768748944\n    grad norm      : 1.2368523988830433\n    accuracy       : 0.9963699494949495\n    dev_loss       : 0.06521455523472335\n    dev_accuracy   : 0.9789655727155727\n    dev_eer        : 0.02668699963217878\n    dev_frr        : 0.026687598116169546\n    dev_far        : 0.026686401148188016\n    dev_thr        : 0.008632360026240349\n    eval_loss      : 0.3106991455925367\n    eval_accuracy  : 0.9352548271216884\n    eval_eer       : 0.07382547031660665\n    eval_frr       : 0.07382732834806255\n    eval_far       : 0.07382361228515075\n    eval_thr       : 0.17959707975387573\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.002843\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.023573\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.51it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000870\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:12<00:44,  4.49it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.000317\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.56it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.000391\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 19\n    loss           : 0.015644974816854246\n    grad norm      : 1.394940614519227\n    accuracy       : 0.9949494949494949\n    dev_loss       : 0.0690763357561503\n    dev_accuracy   : 0.9816602316602316\n    dev_eer        : 0.03329707928546926\n    dev_frr        : 0.033359497645211934\n    dev_far        : 0.033234660925726585\n    dev_thr        : 0.0033888283651322126\n    eval_loss      : 0.4088332254216994\n    eval_accuracy  : 0.9310310956443646\n    eval_eer       : 0.08210492871895372\n    eval_frr       : 0.08212100611828688\n    eval_far       : 0.08208885131962056\n    eval_thr       : 0.09050637483596802\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000374\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.53it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000815\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:27,  4.53it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000104\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.53it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.001522\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.001240\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 20\n    loss           : 0.020465663438745202\n    grad norm      : 1.2857953909163673\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.06487571035013692\n    dev_accuracy   : 0.9825316388327796\n    dev_eer        : 0.03413805490731525\n    dev_frr        : 0.03414442700156986\n    dev_far        : 0.034131682813060636\n    dev_thr        : 0.05701546370983124\n    eval_loss      : 0.4229868719723382\n    eval_accuracy  : 0.9014088459811406\n    eval_eer       : 0.08608007102490187\n    eval_frr       : 0.08606390210740993\n    eval_far       : 0.08609623994239379\n    eval_thr       : 0.849511444568634\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.001071\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.53it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.003274\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.001159\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.002155\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000175\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 21\n    loss           : 0.010443163160725633\n    grad norm      : 0.78481544258374\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.05264507768745504\n    dev_accuracy   : 0.9863658301158301\n    dev_eer        : 0.025027473935670154\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.024937208467886617\n    dev_thr        : 0.006597448606044054\n    eval_loss      : 0.37531103960941853\n    eval_accuracy  : 0.9261197799730579\n    eval_eer       : 0.07490937627161023\n    eval_frr       : 0.07491502379333786\n    eval_far       : 0.07490372874988259\n    eval_thr       : 0.45274367928504944\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000433\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.55it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.005298\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:28,  4.50it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.000091\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.065865\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.58it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.002323\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 22\n    loss           : 0.017536277936405803\n    grad norm      : 1.3972594376848635\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.09561518598726963\n    dev_accuracy   : 0.9759089446589446\n    dev_eer        : 0.031396470155504445\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03139576605669178\n    dev_thr        : 0.0009957117727026343\n    eval_loss      : 0.44841411944434934\n    eval_accuracy  : 0.9395767849124382\n    eval_eer       : 0.07940690422780053\n    eval_frr       : 0.07940176750509857\n    eval_far       : 0.07941204095050249\n    eval_thr       : 0.024208256974816322\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000637\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.50it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000520\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.51it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000434\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000563\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.046985\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 23\n    loss           : 0.029385733860750645\n    grad norm      : 2.0194632171375697\n    accuracy       : 0.9913194444444444\n    dev_loss       : 0.06910775141752716\n    dev_accuracy   : 0.981016731016731\n    dev_eer        : 0.03093113125021475\n    dev_frr        : 0.031004709576138146\n    dev_far        : 0.03085755292429135\n    dev_thr        : 0.00485222227871418\n    eval_loss      : 0.3558244652304604\n    eval_accuracy  : 0.9343707903008531\n    eval_eer       : 0.07657045639318295\n    eval_frr       : 0.07654656696125085\n    eval_far       : 0.07659434582511505\n    eval_thr       : 0.12422796338796616\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.001403\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:11,  4.52it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000215\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:28,  4.52it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000220\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:12<00:44,  4.53it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.002215\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000199\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:56<00:00,  4.51it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 24\n    loss           : 0.012458198166911247\n    grad norm      : 1.1557395783819804\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.060092284555326766\n    dev_accuracy   : 0.9842342342342343\n    dev_eer        : 0.02668699963217878\n    dev_frr        : 0.026687598116169546\n    dev_far        : 0.026686401148188016\n    dev_thr        : 0.0051654125563800335\n    eval_loss      : 0.35343514858507136\n    eval_accuracy  : 0.9343006286484059\n    eval_eer       : 0.07083494527671697\n    eval_frr       : 0.0708361658735554\n    eval_far       : 0.07083372467987853\n    eval_thr       : 0.2464912235736847\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.001799\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:44<02:12,  4.51it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000599\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.54it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000175\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.54it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.001187\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.57it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.003836\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.66it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 25\n    loss           : 0.016006803072796727\n    grad norm      : 1.0592134389779388\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.052698583958596786\n    dev_accuracy   : 0.9835907335907336\n    dev_eer        : 0.030998407891764803\n    dev_frr        : 0.031004709576138146\n    dev_far        : 0.03099210620739146\n    dev_thr        : 0.02155601605772972\n    eval_loss      : 0.28451165153524904\n    eval_accuracy  : 0.9319291647956892\n    eval_eer       : 0.07274156436160306\n    eval_frr       : 0.07273963290278722\n    eval_far       : 0.07274349582041889\n    eval_thr       : 0.36509770154953003\nSaving checkpoint: saved/models/exp13_hints_no_abs_no_base_sinc_no_zero/1214_120003/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}