{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778},{"sourceId":7190267,"sourceType":"datasetVersion","datasetId":4157431},{"sourceId":7191816,"sourceType":"datasetVersion","datasetId":4158628},{"sourceId":7198883,"sourceType":"datasetVersion","datasetId":4163688}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/cm-project-exp/cm_project/. .\n!pip install -r requirements.txt\n!pip install .\nimport wandb\nwandb.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T08:20:22.478457Z","iopub.execute_input":"2023-12-14T08:20:22.478717Z","iopub.status.idle":"2023-12-14T08:21:12.839324Z","shell.execute_reply.started":"2023-12-14T08:20:22.478693Z","shell.execute_reply":"2023-12-14T08:21:12.838324Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.0.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.24.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.0.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.4)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.5.16)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.16.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.9)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (2023.11.17)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (2.31.0)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->-r requirements.txt (line 8)) (6.0.0)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (3.1.32)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.38.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (3.20.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->-r requirements.txt (line 8)) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->-r requirements.txt (line 8)) (3.4)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->-r requirements.txt (line 8)) (0.5.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->-r requirements.txt (line 8)) (1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (5.0.0)\nProcessing /kaggle/working\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: hw-cm\n  Building wheel for hw-cm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hw-cm: filename=hw_cm-0.0-py3-none-any.whl size=18053 sha256=2cd8b807460dfdf4e40f40aa7d4b21314e3191fed2cf6948550e4ab5941bfe0b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-cy2jjxsq/wheels/f5/8c/ca/4f95231da13b8fb9207b24da4e2d5b53ed7cee9f9f88bb6cc5\nSuccessfully built hw-cm\nInstalling collected packages: hw-cm\nSuccessfully installed hw-cm-0.0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!python3 train.py -c ./hw_cm/configs/exp0.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T08:28:06.836727Z","iopub.execute_input":"2023-12-13T08:28:06.837780Z","iopub.status.idle":"2023-12-13T11:43:24.504234Z","shell.execute_reply.started":"2023-12-13T08:28:06.837746Z","shell.execute_reply":"2023-12-13T11:43:24.503058Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_082817-loy8hy2q\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33melated-gorge-3\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/loy8hy2q\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.690658\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:38<01:40,  5.93it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.367685\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:11<01:07,  5.86it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.100091\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:45<00:33,  5.88it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.090267\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:18<00:00,  6.02it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.088347\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:18<00:00,  5.72it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:29<00:00,  8.65it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:50<00:00,  9.65it/s]\n    epoch          : 1\n    loss           : 0.19817968449470671\n    grad norm      : 10.00324720084065\n    accuracy       : 0.9223484848484849\n    dev_loss       : 0.15621653989366732\n    dev_accuracy   : 0.9418436293436293\n    dev_eer        : 0.06986835886958907\n    dev_frr        : 0.06985871271585557\n    dev_far        : 0.06987800502332257\n    dev_thr        : 0.32339832186698914\n    eval_loss      : 0.3603859362278182\n    eval_accuracy  : 0.880767287831163\n    eval_eer       : 0.12155110147318483\n    eval_frr       : 0.12154996600951734\n    eval_far       : 0.12155223693685233\n    eval_thr       : 0.4526156187057495\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.023474\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.145162\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  6.00it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.111653\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.95it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.054920\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.070859\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 2\n    loss           : 0.11531156772333714\n    grad norm      : 8.074499373935689\n    accuracy       : 0.9577020202020202\n    dev_loss       : 0.08926084441174195\n    dev_accuracy   : 0.9678115616127024\n    dev_eer        : 0.04915229319350495\n    dev_frr        : 0.04905808477237049\n    dev_far        : 0.0492465016146394\n    dev_thr        : 0.18406885862350464\n    eval_loss      : 0.3272555964234857\n    eval_accuracy  : 0.8932785137009075\n    eval_eer       : 0.10985802106965104\n    eval_frr       : 0.10985723997280761\n    eval_far       : 0.10985880216649448\n    eval_thr       : 0.437151163816452\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.262138\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.318472\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.006202\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.066800\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.031288\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 3\n    loss           : 0.10391718630074533\n    grad norm      : 6.784493712237989\n    accuracy       : 0.9654356060606061\n    dev_loss       : 0.1301161474842315\n    dev_accuracy   : 0.9582797083308491\n    dev_eer        : 0.04983628998506747\n    dev_frr        : 0.049843014128728415\n    dev_far        : 0.04982956584140653\n    dev_thr        : 0.32699334621429443\n    eval_loss      : 0.4083815713737789\n    eval_accuracy  : 0.8766558149977548\n    eval_eer       : 0.10376202843911886\n    eval_frr       : 0.10373895309313393\n    eval_far       : 0.10378510378510379\n    eval_thr       : 0.8979259133338928\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.032294\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.086127\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.118865\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.043042\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.060264\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 4\n    loss           : 0.07360794088354033\n    grad norm      : 5.035807350913834\n    accuracy       : 0.9756944444444444\n    dev_loss       : 0.15157813518894675\n    dev_accuracy   : 0.9548611111622519\n    dev_eer        : 0.037675764186605336\n    dev_frr        : 0.03767660910518053\n    dev_far        : 0.03767491926803014\n    dev_thr        : 0.6855043172836304\n    eval_loss      : 0.4503636201566826\n    eval_accuracy  : 0.866945442299057\n    eval_eer       : 0.09857238376560659\n    eval_frr       : 0.09857239972807613\n    eval_far       : 0.09857236780313704\n    eval_thr       : 0.9819164872169495\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.054939\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.004625\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.047005\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.98it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.008318\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.07it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.001637\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.77it/s]\n    epoch          : 5\n    loss           : 0.048938792462300776\n    grad norm      : 4.291570383528567\n    accuracy       : 0.9846906565656566\n    dev_loss       : 0.41983090993799804\n    dev_accuracy   : 0.8994262119517823\n    dev_eer        : 0.04638828289451079\n    dev_frr        : 0.04631083202511774\n    dev_far        : 0.04646573376390384\n    dev_thr        : 0.9900941252708435\n    eval_loss      : 0.5515080792229283\n    eval_accuracy  : 0.8480158284687921\n    eval_eer       : 0.10237779500447491\n    eval_frr       : 0.10237933378653977\n    eval_far       : 0.10237625622241008\n    eval_thr       : 0.9970113039016724\nSaving checkpoint: saved/models/exp1_hints/1213_082812/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.199688\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.010356\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.005714\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.052864\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.037316\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 6\n    loss           : 0.046942103416611904\n    grad norm      : 4.492424907332117\n    accuracy       : 0.9826388888888888\n    dev_loss       : 0.09753998284530571\n    dev_accuracy   : 0.96789199919314\n    dev_eer        : 0.04669664296951703\n    dev_frr        : 0.046703296703296704\n    dev_far        : 0.046689989235737354\n    dev_thr        : 0.1587359607219696\n    eval_loss      : 0.3724079412714711\n    eval_accuracy  : 0.8791956668163449\n    eval_eer       : 0.10044769512687726\n    eval_frr       : 0.10047586675730795\n    eval_far       : 0.10041952349644657\n    eval_thr       : 0.8781758546829224\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.183796\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.114073\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.92it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.131590\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.012005\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.000999\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 7\n    loss           : 0.03729456414382157\n    grad norm      : 3.1668363128591217\n    accuracy       : 0.9873737373737373\n    dev_loss       : 0.07877691337425846\n    dev_accuracy   : 0.9789119477130885\n    dev_eer        : 0.048244040930108895\n    dev_frr        : 0.048273155416012556\n    dev_far        : 0.04821492644420524\n    dev_thr        : 0.00502852164208889\n    eval_loss      : 0.4069340434369201\n    eval_accuracy  : 0.9095981140601351\n    eval_eer       : 0.09639674492469556\n    eval_frr       : 0.0963970088375255\n    eval_far       : 0.09639648101186563\n    eval_thr       : 0.2735038995742798\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.005432\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.052731\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.270107\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.002654\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.001024\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 8\n    loss           : 0.028451099911542384\n    grad norm      : 3.222101322191796\n    accuracy       : 0.98989898989899\n    dev_loss       : 0.06811159959399032\n    dev_accuracy   : 0.9811105748861453\n    dev_eer        : 0.03526496505698413\n    dev_frr        : 0.03532182103610675\n    dev_far        : 0.0352081090778615\n    dev_thr        : 0.011071826331317425\n    eval_loss      : 0.3753318639569253\n    eval_accuracy  : 0.8978025370453525\n    eval_eer       : 0.09303008450893197\n    eval_frr       : 0.09299796057104011\n    eval_far       : 0.09306220844682384\n    eval_thr       : 0.7963656783103943\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.019612\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.004621\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000491\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.000384\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.001588\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 9\n    loss           : 0.035631876942734564\n    grad norm      : 3.993070319708851\n    accuracy       : 0.9870580808080808\n    dev_loss       : 0.055865786545876976\n    dev_accuracy   : 0.9805072930328634\n    dev_eer        : 0.035242539509800774\n    dev_frr        : 0.03532182103610675\n    dev_far        : 0.035163257983494796\n    dev_thr        : 0.0508899912238121\n    eval_loss      : 0.32707643712274637\n    eval_accuracy  : 0.8968286933147377\n    eval_eer       : 0.09030075229416337\n    eval_frr       : 0.0902787219578518\n    eval_far       : 0.09032278263047494\n    eval_thr       : 0.8440494537353516\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.031386\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.011881\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.000929\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.004024\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.000649\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 10\n    loss           : 0.013417311760551658\n    grad norm      : 1.7219520483937378\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.0728837178483883\n    dev_accuracy   : 0.977665165216306\n    dev_eer        : 0.02942858438398958\n    dev_frr        : 0.02943485086342229\n    dev_far        : 0.02942231790455687\n    dev_thr        : 0.1516314148902893\n    eval_loss      : 0.42045761030886636\n    eval_accuracy  : 0.8780450157162102\n    eval_eer       : 0.09488191507749108\n    eval_frr       : 0.09490142760027193\n    eval_far       : 0.09486240255471025\n    eval_thr       : 0.9671216607093811\nSaving checkpoint: saved/models/exp1_hints/1213_082812/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.113348\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.012890\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.018640\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.99it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.002209\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.017174\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 11\n    loss           : 0.01782661999746007\n    grad norm      : 1.5248703218683732\n    accuracy       : 0.9952651515151515\n    dev_loss       : 0.04577917413343466\n    dev_accuracy   : 0.9854542042297746\n    dev_eer        : 0.021136553487007124\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.0210800143523502\n    dev_thr        : 0.23679602146148682\n    eval_loss      : 0.4006890959265196\n    eval_accuracy  : 0.8726846654692412\n    eval_eer       : 0.08963211636955297\n    eval_frr       : 0.08959891230455473\n    eval_far       : 0.08966532043455121\n    eval_thr       : 0.9852358102798462\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.002768\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.006164\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.010770\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.98it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000657\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.000642\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 12\n    loss           : 0.02490220621040513\n    grad norm      : 2.4737232893592482\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.0411220482146301\n    dev_accuracy   : 0.9876930501930502\n    dev_eer        : 0.021955103561669763\n    dev_frr        : 0.02197802197802198\n    dev_far        : 0.021932185145317546\n    dev_thr        : 0.010668936185538769\n    eval_loss      : 0.3502718696323308\n    eval_accuracy  : 0.9048467669510553\n    eval_eer       : 0.09162237028157647\n    eval_frr       : 0.09163834126444595\n    eval_far       : 0.091606399298707\n    eval_thr       : 0.6015149354934692\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.003832\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.011942\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.020227\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.98it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.001114\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.000854\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 13\n    loss           : 0.024460961517461605\n    grad norm      : 2.1073807864097143\n    accuracy       : 0.9930555555555556\n    dev_loss       : 0.05050323570712265\n    dev_accuracy   : 0.9850117975373679\n    dev_eer        : 0.032966293663279675\n    dev_frr        : 0.03296703296703297\n    dev_far        : 0.032965554359526375\n    dev_thr        : 0.024958431720733643\n    eval_loss      : 0.4149050467392669\n    eval_accuracy  : 0.9014790076335878\n    eval_eer       : 0.08753228542487551\n    eval_frr       : 0.0875594833446635\n    eval_far       : 0.08750508750508751\n    eval_thr       : 0.8623510599136353\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.001968\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.002622\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.99it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.001109\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.001336\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.053390\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 14\n    loss           : 0.014159875920196293\n    grad norm      : 2.2839524675180636\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.04505111709839364\n    dev_accuracy   : 0.9859636422136422\n    dev_eer        : 0.025094750577220208\n    dev_frr        : 0.02511773940345369\n    dev_far        : 0.025071761750986726\n    dev_thr        : 0.03579096123576164\n    eval_loss      : 0.34368371827404304\n    eval_accuracy  : 0.8997109339919174\n    eval_eer       : 0.09287600730365987\n    eval_frr       : 0.0928619986403807\n    eval_far       : 0.09289001596693905\n    eval_thr       : 0.7618436217308044\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.099127\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.033943\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.000331\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.009009\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000783\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 15\n    loss           : 0.023121358640705098\n    grad norm      : 2.126646337974252\n    accuracy       : 0.99447601010101\n    dev_loss       : 0.10504753589007597\n    dev_accuracy   : 0.9683746246757655\n    dev_eer        : 0.02628893736843914\n    dev_frr        : 0.02629513343799058\n    dev_far        : 0.026282741298887694\n    dev_thr        : 0.6928263902664185\n    eval_loss      : 0.4741880845616299\n    eval_accuracy  : 0.868573192635833\n    eval_eer       : 0.0893004811662972\n    eval_frr       : 0.08932698844323589\n    eval_far       : 0.08927397388935851\n    eval_thr       : 0.9965152740478516\nSaving checkpoint: saved/models/exp1_hints/1213_082812/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.001192\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.022828\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000573\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000555\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.008168\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 16\n    loss           : 0.015663316806148023\n    grad norm      : 1.789524285083359\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.06755259526338989\n    dev_accuracy   : 0.981780888030888\n    dev_eer        : 0.04552488172548145\n    dev_frr        : 0.04552590266875981\n    dev_far        : 0.045523860782203086\n    dev_thr        : 0.01052163727581501\n    eval_loss      : 0.3525015129302626\n    eval_accuracy  : 0.8990935114503816\n    eval_eer       : 0.10154725494368856\n    eval_frr       : 0.10156356220258328\n    eval_far       : 0.10153094768479384\n    eval_thr       : 0.479882150888443\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.003287\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.007357\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:12<01:26,  4.62it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000626\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:45<00:33,  5.98it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000245\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:18<00:00,  6.05it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000290\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:19<00:00,  5.71it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 17\n    loss           : 0.011415562765269172\n    grad norm      : 1.2313300104337894\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.04661272567294641\n    dev_accuracy   : 0.9864864864864865\n    dev_eer        : 0.018064183113006733\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018074991029781128\n    dev_thr        : 0.15060149133205414\n    eval_loss      : 0.49854033457402125\n    eval_accuracy  : 0.8743264481365065\n    eval_eer       : 0.08867097989620606\n    eval_frr       : 0.08864717878993882\n    eval_far       : 0.08869478100247331\n    eval_thr       : 0.9965456128120422\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000847\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.027614\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000555\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.010532\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.002745\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 18\n    loss           : 0.01915083008329149\n    grad norm      : 1.282993287132639\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.07803554634298882\n    dev_accuracy   : 0.9822635135135135\n    dev_eer        : 0.05848153205142287\n    dev_frr        : 0.05847723704866562\n    dev_far        : 0.05848582705418012\n    dev_thr        : 0.0025792771484702826\n    eval_loss      : 0.3983863948239923\n    eval_accuracy  : 0.9146693982936687\n    eval_eer       : 0.0923223139298023\n    eval_frr       : 0.09231815091774304\n    eval_far       : 0.09232647694186155\n    eval_thr       : 0.25766053795814514\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.002342\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.004188\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.004061\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.000967\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.002119\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 19\n    loss           : 0.01692904769813388\n    grad norm      : 1.3321042922137287\n    accuracy       : 0.9954229797979798\n    dev_loss       : 0.02565364269216088\n    dev_accuracy   : 0.9913127413127413\n    dev_eer        : 0.01609629734149187\n    dev_frr        : 0.01609105180533752\n    dev_far        : 0.016101542877646216\n    dev_thr        : 0.14281287789344788\n    eval_loss      : 0.2982033357365754\n    eval_accuracy  : 0.88948136506511\n    eval_eer       : 0.08903146141027227\n    eval_frr       : 0.08905506458191706\n    eval_far       : 0.08900785823862747\n    eval_thr       : 0.8865413069725037\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.005792\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.044567\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.91it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.002440\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.001973\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000164\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 20\n    loss           : 0.01293872774803818\n    grad norm      : 0.8142971292542613\n    accuracy       : 0.9970012626262627\n    dev_loss       : 0.04160152100490845\n    dev_accuracy   : 0.9898648648648649\n    dev_eer        : 0.022375591372592755\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.02238069608898457\n    dev_thr        : 0.006680467166006565\n    eval_loss      : 0.4337488461085383\n    eval_accuracy  : 0.9012544903457567\n    eval_eer       : 0.0876707087683399\n    eval_frr       : 0.08769544527532291\n    eval_far       : 0.08764597226135688\n    eval_thr       : 0.9131529331207275\nSaving checkpoint: saved/models/exp1_hints/1213_082812/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000371\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.002434\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.001899\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.98it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.005432\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:12<00:00,  6.07it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000674\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.96it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 21\n    loss           : 0.011502377187799088\n    grad norm      : 1.0391826879966892\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.03644573714042226\n    dev_accuracy   : 0.9898648648648649\n    dev_eer        : 0.019634006620781956\n    dev_frr        : 0.019623233908948195\n    dev_far        : 0.019644779332615717\n    dev_thr        : 0.0030599224846810102\n    eval_loss      : 0.35530080989802304\n    eval_accuracy  : 0.9083829142343961\n    eval_eer       : 0.0799449437398504\n    eval_frr       : 0.07994561522773623\n    eval_far       : 0.07994427225196456\n    eval_thr       : 0.8534127473831177\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000886\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.003471\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.045059\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.94it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000764\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000270\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 22\n    loss           : 0.009484364628250008\n    grad norm      : 1.0486970112207488\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.03280527172141674\n    dev_accuracy   : 0.9904279279279279\n    dev_eer        : 0.01530017281401258\n    dev_frr        : 0.015306122448979591\n    dev_far        : 0.01529422317904557\n    dev_thr        : 0.06588923931121826\n    eval_loss      : 0.45202121896204733\n    eval_accuracy  : 0.8861837674000899\n    eval_eer       : 0.08484208786462616\n    eval_frr       : 0.08484024473147518\n    eval_far       : 0.08484393099777715\n    eval_thr       : 0.9889515042304993\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000178\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000591\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000202\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000142\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000615\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 23\n    loss           : 0.011024281114856935\n    grad norm      : 1.238508985513666\n    accuracy       : 0.9958964646464646\n    dev_loss       : 0.02426461524169128\n    dev_accuracy   : 0.9924120549376253\n    dev_eer        : 0.013046352514674828\n    dev_frr        : 0.012951334379905808\n    dev_far        : 0.013141370649443847\n    dev_thr        : 0.0341290682554245\n    eval_loss      : 0.34553288747718036\n    eval_accuracy  : 0.8939296138302649\n    eval_eer       : 0.08075982993882905\n    eval_frr       : 0.08076138681169273\n    eval_far       : 0.08075827306596538\n    eval_thr       : 0.94316565990448\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.001001\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000501\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.003596\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.96it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000685\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000577\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 24\n    loss           : 0.021386618595392468\n    grad norm      : 1.7455084047990503\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.03335937580862427\n    dev_accuracy   : 0.9896771772027476\n    dev_eer        : 0.021999954656036463\n    dev_frr        : 0.02197802197802198\n    dev_far        : 0.02202188733405095\n    dev_thr        : 0.025769900530576706\n    eval_loss      : 0.41248953108640024\n    eval_accuracy  : 0.8897900763358778\n    eval_eer       : 0.08562566633998941\n    eval_frr       : 0.08565601631543168\n    eval_far       : 0.08559531636454713\n    eval_thr       : 0.9754512906074524\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.016118\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000690\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:12<01:06,  5.99it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000402\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:45<00:33,  5.96it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.012906\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:18<00:00,  6.06it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.000597\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:18<00:00,  5.71it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 25\n    loss           : 0.013018107041532839\n    grad norm      : 1.3754227431408703\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.04882366437269579\n    dev_accuracy   : 0.9878137065637066\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.03206368908286095\n    eval_loss      : 0.4478889765336707\n    eval_accuracy  : 0.8903233048944769\n    eval_eer       : 0.08321231546666887\n    eval_frr       : 0.0832087015635622\n    eval_far       : 0.08321592936977552\n    eval_thr       : 0.9945409893989563\nSaving checkpoint: saved/models/exp1_hints/1213_082812/checkpoint-epoch25.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 26 [0/794 (0%)] Loss: 0.001111\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 26 [198/794 (25%)] Loss: 0.000326\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 26 [396/794 (50%)] Loss: 0.000125\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:39<00:33,  5.97it/s]Train Epoch: 26 [594/794 (75%)] Loss: 0.004968\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 26 [792/794 (100%)] Loss: 0.009776\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.95it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 26\n    loss           : 0.009934285637501315\n    grad norm      : 1.0698747638556543\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.03323451111000009\n    dev_accuracy   : 0.9892213642213642\n    dev_eer        : 0.020009643337338248\n    dev_frr        : 0.020015698587127158\n    dev_far        : 0.020003588087549335\n    dev_thr        : 0.047670431435108185\n    eval_loss      : 0.2950273802232952\n    eval_accuracy  : 0.8908705657835654\n    eval_eer       : 0.0843040483525763\n    eval_frr       : 0.08429639700883752\n    eval_far       : 0.08431169969631508\n    eval_thr       : 0.9216902256011963\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 27 [0/794 (0%)] Loss: 0.001087\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 27 [198/794 (25%)] Loss: 0.000294\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 27 [396/794 (50%)] Loss: 0.000088\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 27 [594/794 (75%)] Loss: 0.000777\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 27 [792/794 (100%)] Loss: 0.000674\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 268/777 [00:27<00:52,  9.77it/s]^C\ndev:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 268/777 [00:27<00:52,  9.70it/s]\nSaving model on keyboard interrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp2.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T11:46:00.800949Z","iopub.execute_input":"2023-12-13T11:46:00.801492Z","iopub.status.idle":"2023-12-13T14:35:51.771840Z","shell.execute_reply.started":"2023-12-13T11:46:00.801450Z","shell.execute_reply":"2023-12-13T14:35:51.770677Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (gru): GRU(128, 512, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_114606-ehak00sr\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-bee-5\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/ehak00sr\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.706587\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:31<01:28,  6.72it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.426248\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:00<00:59,  6.74it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.560249\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:30<00:29,  6.70it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.281989\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:59<00:00,  6.85it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.115597\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:59<00:00,  6.63it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.52it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 1\n    loss           : 0.15859549533989695\n    grad norm      : 8.720639587652803\n    accuracy       : 0.9460227272727273\n    dev_loss       : 0.10618870789134226\n    dev_accuracy   : 0.9579713642213642\n    dev_eer        : 0.06279294031100889\n    dev_frr        : 0.06279434850863422\n    dev_far        : 0.06279153211338356\n    dev_thr        : 0.2209756225347519\n    eval_loss      : 0.250322810426684\n    eval_accuracy  : 0.942096991473696\n    eval_eer       : 0.07831517134189309\n    eval_frr       : 0.07831407205982326\n    eval_far       : 0.07831627062396293\n    eval_thr       : 0.2302105873823166\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.177839\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.68it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.178315\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.74it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.107040\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.74it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.065863\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.157111\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 2\n    loss           : 0.08642217158245845\n    grad norm      : 7.077587201664544\n    accuracy       : 0.9715909090909091\n    dev_loss       : 1.3654495614203042\n    dev_accuracy   : 0.6794294294358221\n    dev_eer        : 0.06429548717723407\n    dev_frr        : 0.06436420722135008\n    dev_far        : 0.06422676713311805\n    dev_thr        : 0.9986763596534729\n    eval_loss      : 0.7195002917216219\n    eval_accuracy  : 0.7771385271665918\n    eval_eer       : 0.07015065549029885\n    eval_frr       : 0.07015635622025833\n    eval_far       : 0.07014495476033937\n    eval_thr       : 0.9991987347602844\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.141139\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.162981\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:58,  6.75it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.038545\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.74it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.021338\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.115663\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 3\n    loss           : 0.07123287058096718\n    grad norm      : 5.031354376914526\n    accuracy       : 0.9791666666666666\n    dev_loss       : 0.09041027131414298\n    dev_accuracy   : 0.9670742170997875\n    dev_eer        : 0.053284297075624154\n    dev_frr        : 0.05337519623233909\n    dev_far        : 0.05319339791890922\n    dev_thr        : 0.12163754552602768\n    eval_loss      : 0.21756996441930265\n    eval_accuracy  : 0.9370649977548271\n    eval_eer       : 0.0728878146359713\n    eval_frr       : 0.07287559483344663\n    eval_far       : 0.07290003443849598\n    eval_thr       : 0.32161155343055725\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.021935\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.75it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.004103\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.68it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.004547\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.70it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.087882\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.004560\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.52it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 4\n    loss           : 0.03984724110723802\n    grad norm      : 3.4840527283912053\n    accuracy       : 0.9873737373737373\n    dev_loss       : 0.0763006110804409\n    dev_accuracy   : 0.9747828185328186\n    dev_eer        : 0.045922943989221095\n    dev_frr        : 0.04591836734693878\n    dev_far        : 0.04592752063150341\n    dev_thr        : 0.01641828753054142\n    eval_loss      : 0.2607910626321269\n    eval_accuracy  : 0.9529720476030179\n    eval_eer       : 0.06580720473938065\n    eval_frr       : 0.06580557443915704\n    eval_far       : 0.06580883503960427\n    eval_thr       : 0.09977662563323975\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.005545\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.71it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.030891\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.087518\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.70it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.001484\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.006512\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.52it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 5\n    loss           : 0.04954922495829059\n    grad norm      : 4.113221610959789\n    accuracy       : 0.9865845959595959\n    dev_loss       : 0.06824445503552899\n    dev_accuracy   : 0.9766999142510551\n    dev_eer        : 0.03650400294256976\n    dev_frr        : 0.036499215070643645\n    dev_far        : 0.03650879081449587\n    dev_thr        : 0.023729581385850906\n    eval_loss      : 0.22240196398143008\n    eval_accuracy  : 0.9449371351594072\n    eval_eer       : 0.06526133829642694\n    eval_frr       : 0.06526172671651938\n    eval_far       : 0.06526094987633449\n    eval_thr       : 0.23647679388523102\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.009701\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.002143\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.73it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.019363\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.75it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.055908\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.82it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.010897\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:37<00:00, 10.23it/s]\n    epoch          : 6\n    loss           : 0.046254361389355375\n    grad norm      : 3.7023056433206856\n    accuracy       : 0.9848484848484849\n    dev_loss       : 0.0787363648820642\n    dev_accuracy   : 0.9691387816899225\n    dev_eer        : 0.044353120481445865\n    dev_frr        : 0.04434850863422292\n    dev_far        : 0.04435773232866882\n    dev_thr        : 0.1808512955904007\n    eval_loss      : 0.19741214596033665\n    eval_accuracy  : 0.9301470588235294\n    eval_eer       : 0.07014282855939499\n    eval_frr       : 0.07015635622025833\n    eval_far       : 0.07012930089853167\n    eval_thr       : 0.49468252062797546\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.066220\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.69it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.003791\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:58,  6.76it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.028597\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.68it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.017326\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.012363\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 7\n    loss           : 0.03310538953592921\n    grad norm      : 2.376497411771179\n    accuracy       : 0.9906881313131313\n    dev_loss       : 0.07383519039694114\n    dev_accuracy   : 0.9808692621448325\n    dev_eer        : 0.03811867754471168\n    dev_frr        : 0.0380690737833595\n    dev_far        : 0.03816828130606387\n    dev_thr        : 0.002712337300181389\n    eval_loss      : 0.25159324834307756\n    eval_accuracy  : 0.9588936910695649\n    eval_eer       : 0.05494466439663323\n    eval_frr       : 0.054928619986403804\n    eval_far       : 0.05496070880686265\n    eval_thr       : 0.06682704389095306\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.007203\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.73it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.005609\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.68it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.000814\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.70it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.004993\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.80it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.012401\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.52it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 8\n    loss           : 0.02176310503434959\n    grad norm      : 1.977295047462438\n    accuracy       : 0.9919507575757576\n    dev_loss       : 0.07108329394561676\n    dev_accuracy   : 0.980788824564395\n    dev_eer        : 0.03376241819075895\n    dev_frr        : 0.033751962323390894\n    dev_far        : 0.03377287405812702\n    dev_thr        : 0.030392762273550034\n    eval_loss      : 0.22766819938627825\n    eval_accuracy  : 0.9383279074988774\n    eval_eer       : 0.0526149483504501\n    eval_frr       : 0.05261726716519374\n    eval_far       : 0.05261262953570646\n    eval_thr       : 0.7858771085739136\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.000859\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.73it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.025123\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.71it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.010211\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:30,  6.62it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.024182\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.002378\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 9\n    loss           : 0.030830591676931363\n    grad norm      : 2.4004829450642142\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.08083201572596783\n    dev_accuracy   : 0.9755201630457334\n    dev_eer        : 0.045922943989221095\n    dev_frr        : 0.04591836734693878\n    dev_far        : 0.04592752063150341\n    dev_thr        : 0.01092679426074028\n    eval_loss      : 0.2879058845541626\n    eval_accuracy  : 0.9420885720700494\n    eval_eer       : 0.07410231700353544\n    eval_frr       : 0.07409925220938138\n    eval_far       : 0.0741053817976895\n    eval_thr       : 0.1226649358868599\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.006741\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.001038\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.73it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.006136\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.67it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.000860\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.005041\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 10\n    loss           : 0.017266029859970927\n    grad norm      : 2.268434693798131\n    accuracy       : 0.9940025252525253\n    dev_loss       : 0.07343925560740418\n    dev_accuracy   : 0.9782014157014157\n    dev_eer        : 0.04081541120215578\n    dev_frr        : 0.04081632653061224\n    dev_far        : 0.04081449587369932\n    dev_thr        : 0.014813662506639957\n    eval_loss      : 0.22581580011390498\n    eval_accuracy  : 0.9503059048100229\n    eval_eer       : 0.058303497881492965\n    eval_frr       : 0.05832766825288919\n    eval_far       : 0.05827932751009674\n    eval_thr       : 0.21251113712787628\nSaving checkpoint: saved/models/exp2_hints_no_abs_no_gru_feats/1213_114604/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.034152\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.68it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.004837\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.71it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.002154\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.71it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.000292\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.001048\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 11\n    loss           : 0.010875525297623508\n    grad norm      : 1.225756972143897\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.07735492983271564\n    dev_accuracy   : 0.9784695410206818\n    dev_eer        : 0.03137404460832109\n    dev_frr        : 0.03139717425431711\n    dev_far        : 0.03135091496232508\n    dev_thr        : 0.05979584902524948\n    eval_loss      : 0.24986361527926831\n    eval_accuracy  : 0.9264004265828468\n    eval_eer       : 0.04881736404248563\n    eval_frr       : 0.048810333106730115\n    eval_far       : 0.048824394978241134\n    eval_thr       : 0.9695472121238708\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.000226\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.67it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.000352\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.67it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.022747\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.69it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.148761\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.025163\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:34<00:00, 10.38it/s]\n    epoch          : 12\n    loss           : 0.020361072799432528\n    grad norm      : 1.7664772429200115\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.04680667014501542\n    dev_accuracy   : 0.9873847061602765\n    dev_eer        : 0.024343477144107624\n    dev_frr        : 0.02433281004709576\n    dev_far        : 0.024354144241119483\n    dev_thr        : 0.006206993479281664\n    eval_loss      : 0.18885385176760677\n    eval_accuracy  : 0.9576728783169829\n    eval_eer       : 0.044458259429759714\n    eval_frr       : 0.04445955132562882\n    eval_far       : 0.04445696753389061\n    eval_thr       : 0.40630659461021423\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.014882\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.75it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.000383\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.055939\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.70it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.001552\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.051203\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.50it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 13\n    loss           : 0.015340955087484679\n    grad norm      : 1.538103286310974\n    accuracy       : 0.9963699494949495\n    dev_loss       : 0.08332318700398493\n    dev_accuracy   : 0.9816736379492084\n    dev_eer        : 0.04552488172548145\n    dev_frr        : 0.04552590266875981\n    dev_far        : 0.045523860782203086\n    dev_thr        : 0.001808683155104518\n    eval_loss      : 0.34793907842785815\n    eval_accuracy  : 0.9508952626905797\n    eval_eer       : 0.06429237489217618\n    eval_frr       : 0.06430999320190346\n    eval_far       : 0.0642747565824489\n    eval_thr       : 0.056612659245729446\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.004402\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.71it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.001906\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.71it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000416\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.71it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000236\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.000906\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.50it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 14\n    loss           : 0.015450622296129674\n    grad norm      : 1.854773749272231\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.060728636646740275\n    dev_accuracy   : 0.985440797940798\n    dev_eer        : 0.03573030396227382\n    dev_frr        : 0.03571428571428571\n    dev_far        : 0.03574632221026193\n    dev_thr        : 0.0018050444778054953\n    eval_loss      : 0.21264312383365153\n    eval_accuracy  : 0.9565699371351594\n    eval_eer       : 0.05016246282261029\n    eval_frr       : 0.05016995241332427\n    eval_far       : 0.050154973231896306\n    eval_thr       : 0.22793127596378326\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.000279\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.74it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.000338\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.000493\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.73it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.000078\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000527\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 15\n    loss           : 0.014894721016885755\n    grad norm      : 1.3112530316757696\n    accuracy       : 0.9955808080808081\n    dev_loss       : 0.058464149742684976\n    dev_accuracy   : 0.9869288931788932\n    dev_eer        : 0.02940615883680623\n    dev_frr        : 0.02943485086342229\n    dev_far        : 0.02937746681019017\n    dev_thr        : 0.0016644321149215102\n    eval_loss      : 0.25899334910926236\n    eval_accuracy  : 0.9426498652896274\n    eval_eer       : 0.053429834549428755\n    eval_frr       : 0.05343303874915024\n    eval_far       : 0.05342663034970727\n    eval_thr       : 0.6772432923316956\nSaving checkpoint: saved/models/exp2_hints_no_abs_no_gru_feats/1213_114604/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.000201\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.75it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.000055\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.059594\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.74it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000790\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.015306\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 16\n    loss           : 0.014118238607779582\n    grad norm      : 1.55319112252016\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.04792853490608969\n    dev_accuracy   : 0.9859368297124002\n    dev_eer        : 0.028256823139954004\n    dev_frr        : 0.0282574568288854\n    dev_far        : 0.028256189451022606\n    dev_thr        : 0.011120319366455078\n    eval_loss      : 0.17372536701235447\n    eval_accuracy  : 0.9538280197628742\n    eval_eer       : 0.048947960455046166\n    eval_frr       : 0.04894629503738953\n    eval_far       : 0.048949625872702796\n    eval_thr       : 0.39311036467552185\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.002427\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000076\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:58,  6.76it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000171\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.71it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.001418\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.85it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000641\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 17\n    loss           : 0.007739818884441077\n    grad norm      : 1.008757337784357\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.07578934672301271\n    dev_accuracy   : 0.9796626984382688\n    dev_eer        : 0.021977529108853117\n    dev_frr        : 0.02197802197802198\n    dev_far        : 0.02197703623968425\n    dev_thr        : 0.37628090381622314\n    eval_loss      : 0.2756502921127352\n    eval_accuracy  : 0.9224713740458015\n    eval_eer       : 0.04486570252924904\n    eval_frr       : 0.04486743711760707\n    eval_far       : 0.044863967940891016\n    eval_thr       : 0.9931396842002869\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000107\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000351\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.006598\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.72it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000113\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.82it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000185\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 18\n    loss           : 0.013423376534223225\n    grad norm      : 1.7390528817995066\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.04148823405952946\n    dev_accuracy   : 0.9867412055167759\n    dev_eer        : 0.02228588918385935\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.02220129171151776\n    dev_thr        : 0.029792506247758865\n    eval_loss      : 0.183752276098814\n    eval_accuracy  : 0.9440110013471037\n    eval_eer       : 0.04755590008949838\n    eval_frr       : 0.04758667573079538\n    eval_far       : 0.047525124448201374\n    eval_thr       : 0.7736498117446899\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.001575\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.68it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.007404\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.72it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.002679\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.73it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.004220\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.83it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.010298\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 19\n    loss           : 0.0077751557120350435\n    grad norm      : 1.186434706769451\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.05290746877956453\n    dev_accuracy   : 0.9860708923720332\n    dev_eer        : 0.023149290352888693\n    dev_frr        : 0.02315541601255887\n    dev_far        : 0.023143164693218515\n    dev_thr        : 0.009009326808154583\n    eval_loss      : 0.23964079680203776\n    eval_accuracy  : 0.9435058374494836\n    eval_eer       : 0.052207505250960774\n    eval_frr       : 0.0522093813732155\n    eval_far       : 0.05220562912870605\n    eval_thr       : 0.7133453488349915\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000168\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.70it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000359\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:58,  6.76it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.075957\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:30,  6.66it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000288\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.85it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000196\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.69it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 20\n    loss           : 0.0065181743948322934\n    grad norm      : 0.7365507816136203\n    accuracy       : 0.9981060606060606\n    dev_loss       : 0.04332968603697902\n    dev_accuracy   : 0.9863524239035647\n    dev_eer        : 0.022706376994782347\n    dev_frr        : 0.022762951334379906\n    dev_far        : 0.022649802655184785\n    dev_thr        : 0.07956167310476303\n    eval_loss      : 0.19649743290549412\n    eval_accuracy  : 0.9371351594072743\n    eval_eer       : 0.04677232161413514\n    eval_frr       : 0.04677090414683888\n    eval_far       : 0.04677373908143139\n    eval_thr       : 0.9141412377357483\nSaving checkpoint: saved/models/exp2_hints_no_abs_no_gru_feats/1213_114604/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.001704\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.72it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000334\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.73it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.002275\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.75it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000212\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.85it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000525\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:14<00:00, 10.37it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.54it/s]\n    epoch          : 21\n    loss           : 0.018223360060544265\n    grad norm      : 2.206897092466901\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.05107405763689924\n    dev_accuracy   : 0.9842476405232109\n    dev_eer        : 0.02942858438398958\n    dev_frr        : 0.02943485086342229\n    dev_far        : 0.02942231790455687\n    dev_thr        : 0.010150720365345478\n    eval_loss      : 0.16422521357643222\n    eval_accuracy  : 0.9571873596766951\n    eval_eer       : 0.04784057370733101\n    eval_frr       : 0.04785859959211421\n    eval_far       : 0.04782254782254782\n    eval_thr       : 0.34197813272476196\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000435\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.71it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.001452\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.71it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.000204\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.74it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000438\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000167\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:13<00:00, 10.51it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:31<00:00, 10.53it/s]\n    epoch          : 22\n    loss           : 0.0034468129373213152\n    grad norm      : 0.3284324362481276\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.04128580058518702\n    dev_accuracy   : 0.9896101459112867\n    dev_eer        : 0.021557041297930117\n    dev_frr        : 0.021585557299843013\n    dev_far        : 0.021528525296017224\n    dev_thr        : 0.007939944043755531\n    eval_loss      : 0.20364917172768174\n    eval_accuracy  : 0.9466771441400987\n    eval_eer       : 0.04308967985692349\n    eval_frr       : 0.04309993201903467\n    eval_far       : 0.04307942769481231\n    eval_thr       : 0.8611809611320496\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000128\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:28,  6.73it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000524\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.73it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000890\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:28<00:29,  6.73it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000313\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:58<00:00,  6.84it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.001036\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:58<00:00,  6.70it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:14<00:00, 10.48it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:32<00:00, 10.47it/s]\n    epoch          : 23\n    loss           : 0.011247918096219707\n    grad norm      : 0.9002050464094448\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.07603547000556575\n    dev_accuracy   : 0.974300193050193\n    dev_eer        : 0.02120383012855718\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.021214567635450304\n    dev_thr        : 0.6492248177528381\n    eval_loss      : 0.2136887767131487\n    eval_accuracy  : 0.918977323753929\n    eval_eer       : 0.045680588728227695\n    eval_frr       : 0.04568320870156356\n    eval_far       : 0.04567796875489183\n    eval_thr       : 0.9724991917610168\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.002538\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:30<01:29,  6.67it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000397\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.67it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000067\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:29<00:29,  6.67it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000096\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:59<00:00,  6.78it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000073\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:59<00:00,  6.65it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:14<00:00, 10.47it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:32<00:00, 10.49it/s]\n    epoch          : 24\n    loss           : 0.005974096924840735\n    grad norm      : 0.7694411149796456\n    accuracy       : 0.9977904040404041\n    dev_loss       : 0.05944218298376382\n    dev_accuracy   : 0.9872238309994014\n    dev_eer        : 0.027858760876214358\n    dev_frr        : 0.027864992150706435\n    dev_far        : 0.02785252960172228\n    dev_thr        : 0.001322852331213653\n    eval_loss      : 0.25718564561247076\n    eval_accuracy  : 0.9544089582397844\n    eval_eer       : 0.051562350119061934\n    eval_frr       : 0.05152957171991842\n    eval_far       : 0.05159512851820544\n    eval_thr       : 0.1807425171136856\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.007793\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:29<01:29,  6.68it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.001036\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [00:59<00:59,  6.65it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000546\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:29<00:29,  6.67it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.070622\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [01:59<00:00,  6.79it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.108285\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [01:59<00:00,  6.65it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:14<00:00, 10.46it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:32<00:00, 10.48it/s]\n    epoch          : 25\n    loss           : 0.006709977573502163\n    grad norm      : 0.7623766691563886\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.17660617544925877\n    dev_accuracy   : 0.9536277348777349\n    dev_eer        : 0.018793030998935964\n    dev_frr        : 0.018838304552590265\n    dev_far        : 0.018747757445281666\n    dev_thr        : 0.9834007620811462\n    eval_loss      : 0.3384051327267497\n    eval_accuracy  : 0.9018017512348451\n    eval_eer       : 0.051408272913789826\n    eval_frr       : 0.051393609789259005\n    eval_far       : 0.051422936038320655\n    eval_thr       : 0.9974786639213562\nSaving checkpoint: saved/models/exp2_hints_no_abs_no_gru_feats/1213_114604/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp4.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T15:01:02.020818Z","iopub.execute_input":"2023-12-13T15:01:02.021551Z","iopub.status.idle":"2023-12-13T18:06:34.524679Z","shell.execute_reply.started":"2023-12-13T15:01:02.021513Z","shell.execute_reply":"2023-12-13T18:06:34.523351Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_150111-kga9e5fg\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meternal-oath-7\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/kga9e5fg\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.667279\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:34<01:39,  5.98it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.134181\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:08<01:07,  5.92it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.019010\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:41<00:33,  5.97it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.061773\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.05it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.118635\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:15<00:00,  5.88it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.81it/s]\n    epoch          : 1\n    loss           : 0.07779719777795664\n    grad norm      : 5.144575554162565\n    accuracy       : 0.9747474747474747\n    dev_loss       : 0.12086039184911945\n    dev_accuracy   : 0.9604515230026638\n    dev_eer        : 0.07409006494044168\n    dev_frr        : 0.07417582417582418\n    dev_far        : 0.0740043057050592\n    dev_thr        : 0.029140857979655266\n    eval_loss      : 0.20097480347040467\n    eval_accuracy  : 0.9364616075437808\n    eval_eer       : 0.09096156128786992\n    eval_frr       : 0.09095853161114888\n    eval_far       : 0.09096459096459096\n    eval_thr       : 0.05016964673995972\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.004308\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.023235\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.018517\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.010688\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.161621\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 2\n    loss           : 0.04728570440784097\n    grad norm      : 3.431503398663769\n    accuracy       : 0.9856376262626263\n    dev_loss       : 0.07455100275750214\n    dev_accuracy   : 0.9741661304672713\n    dev_eer        : 0.04552488172548145\n    dev_frr        : 0.04552590266875981\n    dev_far        : 0.045523860782203086\n    dev_thr        : 0.036483969539403915\n    eval_loss      : 0.1346182047285317\n    eval_accuracy  : 0.9534968567579704\n    eval_eer       : 0.06553035805245186\n    eval_frr       : 0.0655336505778382\n    eval_far       : 0.06552706552706553\n    eval_thr       : 0.09810197353363037\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.004516\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.029637\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.005288\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.006246\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.012974\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 3\n    loss           : 0.03714136831812805\n    grad norm      : 3.044584058413301\n    accuracy       : 0.9884785353535354\n    dev_loss       : 0.06243544807127213\n    dev_accuracy   : 0.9780003217503217\n    dev_eer        : 0.03805140090316163\n    dev_frr        : 0.0380690737833595\n    dev_far        : 0.03803372802296376\n    dev_thr        : 0.0707164853811264\n    eval_loss      : 0.11704723012236753\n    eval_accuracy  : 0.9538897620116749\n    eval_eer       : 0.061455927057558604\n    eval_frr       : 0.06145479265805574\n    eval_far       : 0.06145706145706146\n    eval_thr       : 0.20923157036304474\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.100421\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.88it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.000620\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.006216\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.013118\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.001095\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 4\n    loss           : 0.02932655001870554\n    grad norm      : 2.2577692353721672\n    accuracy       : 0.9914772727272727\n    dev_loss       : 0.0598185362983032\n    dev_accuracy   : 0.9813116688372392\n    dev_eer        : 0.03610594067883011\n    dev_frr        : 0.03610675039246468\n    dev_far        : 0.03610513096519555\n    dev_thr        : 0.016003573313355446\n    eval_loss      : 0.15732109793893648\n    eval_accuracy  : 0.9530197575213292\n    eval_eer       : 0.060502617515115556\n    eval_frr       : 0.060503059143439834\n    eval_far       : 0.06050217588679127\n    eval_thr       : 0.15771697461605072\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.047161\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.001570\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.000525\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.000858\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.001014\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 5\n    loss           : 0.018438220733624996\n    grad norm      : 2.1506838994735684\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.06270880859577317\n    dev_accuracy   : 0.980815637065637\n    dev_eer        : 0.03530981615135083\n    dev_frr        : 0.03532182103610675\n    dev_far        : 0.035297811266594904\n    dev_thr        : 0.021417543292045593\n    eval_loss      : 0.1771759425491604\n    eval_accuracy  : 0.9477856982487651\n    eval_eer       : 0.06224733246382569\n    eval_frr       : 0.06227056424201224\n    eval_far       : 0.06222410068563915\n    eval_thr       : 0.2157740741968155\nSaving checkpoint: saved/models/exp4_hints_no_abs_no_weights/1213_150105/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.029427\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.002233\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.000862\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.015093\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.002317\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 6\n    loss           : 0.016088183078064696\n    grad norm      : 2.035054109651934\n    accuracy       : 0.9947916666666666\n    dev_loss       : 0.07376874705643957\n    dev_accuracy   : 0.9766462891718596\n    dev_eer        : 0.029736944458995822\n    dev_frr        : 0.029827315541601257\n    dev_far        : 0.029646573376390383\n    dev_thr        : 0.28530964255332947\n    eval_loss      : 0.2699645513590872\n    eval_accuracy  : 0.9315081948810059\n    eval_eer       : 0.05233810166352132\n    eval_frr       : 0.052345343303874914\n    eval_far       : 0.05233086002316772\n    eval_thr       : 0.8693031668663025\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.003882\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.006802\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.123620\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.007136\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.000588\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 7\n    loss           : 0.013328041981201915\n    grad norm      : 1.1913894814464987\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.10561094165558393\n    dev_accuracy   : 0.9737773487773488\n    dev_eer        : 0.035332241698534175\n    dev_frr        : 0.03532182103610675\n    dev_far        : 0.035342662360961605\n    dev_thr        : 0.0013552228920161724\n    eval_loss      : 0.14758150601368225\n    eval_accuracy  : 0.9588993039964078\n    eval_eer       : 0.06674486042001598\n    eval_frr       : 0.06675730795377294\n    eval_far       : 0.06673241288625904\n    eval_thr       : 0.012870023027062416\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.059268\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.078387\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.073406\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.151675\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.001463\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.79it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 8\n    loss           : 0.012334921641417572\n    grad norm      : 1.1624495722306423\n    accuracy       : 0.9949494949494949\n    dev_loss       : 0.048657711397993866\n    dev_accuracy   : 0.9870093307593307\n    dev_eer        : 0.028654885403693646\n    dev_frr        : 0.028649921507064365\n    dev_far        : 0.028659849300322927\n    dev_thr        : 0.006978947203606367\n    eval_loss      : 0.13221894216556043\n    eval_accuracy  : 0.9609059272563988\n    eval_eer       : 0.04677232161413514\n    eval_frr       : 0.04677090414683888\n    eval_far       : 0.04677373908143139\n    eval_thr       : 0.2217879444360733\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.012539\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.000896\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000474\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.000860\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.000126\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 9\n    loss           : 0.010229895048733034\n    grad norm      : 1.083914610223299\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.16053636118397369\n    dev_accuracy   : 0.9728255041010745\n    dev_eer        : 0.07260994362139987\n    dev_frr        : 0.07260596546310832\n    dev_far        : 0.07261392177969142\n    dev_thr        : 0.00017803382070269436\n    eval_loss      : 0.1783911759833514\n    eval_accuracy  : 0.9562612258643916\n    eval_eer       : 0.07192667816262441\n    eval_frr       : 0.07192386131883073\n    eval_far       : 0.07192949500641808\n    eval_thr       : 0.002851213561370969\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.003988\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.89it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.007484\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.003475\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.013348\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.001500\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 10\n    loss           : 0.00916227581976934\n    grad norm      : 0.97699089922279\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.0426702218818077\n    dev_accuracy   : 0.9882158944658944\n    dev_eer        : 0.02124868122292388\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.02130426982418371\n    dev_thr        : 0.004729066975414753\n    eval_loss      : 0.14338414173505534\n    eval_accuracy  : 0.9568365514144589\n    eval_eer       : 0.049901269997489214\n    eval_frr       : 0.04989802855200544\n    eval_far       : 0.04990451144297298\n    eval_thr       : 0.24115422368049622\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.000188\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.89it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000040\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.000234\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.000131\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.004614\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 11\n    loss           : 0.01253702432487361\n    grad norm      : 1.2754475096466416\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.0711039673097874\n    dev_accuracy   : 0.9824646074646075\n    dev_eer        : 0.03219259468298374\n    dev_frr        : 0.03218210361067504\n    dev_far        : 0.03220308575529243\n    dev_thr        : 0.001563290716148913\n    eval_loss      : 0.1263548488025793\n    eval_accuracy  : 0.9634738437359677\n    eval_eer       : 0.053184295586115385\n    eval_frr       : 0.05316111488783141\n    eval_far       : 0.05320747628439936\n    eval_thr       : 0.028775222599506378\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.003465\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.000662\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.011417\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000148\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.00it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.000510\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 12\n    loss           : 0.007336299117565487\n    grad norm      : 0.8301155329270363\n    accuracy       : 0.9981060606060606\n    dev_loss       : 0.04853515051666058\n    dev_accuracy   : 0.9880148005148005\n    dev_eer        : 0.02628893736843914\n    dev_frr        : 0.02629513343799058\n    dev_far        : 0.026282741298887694\n    dev_thr        : 0.0025129930581897497\n    eval_loss      : 0.16464372877085198\n    eval_accuracy  : 0.9563875168387966\n    eval_eer       : 0.04991692385929691\n    eval_frr       : 0.04989802855200544\n    eval_far       : 0.049935819166588395\n    eval_thr       : 0.23117300868034363\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.000168\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.000298\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.015053\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000896\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.000209\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.80it/s]\n    epoch          : 13\n    loss           : 0.007789477042924681\n    grad norm      : 0.5713179315119332\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.03500828764414926\n    dev_accuracy   : 0.9915138352638353\n    dev_eer        : 0.017666120849267088\n    dev_frr        : 0.017660910518053376\n    dev_far        : 0.017671331180480802\n    dev_thr        : 0.006390094757080078\n    eval_loss      : 0.2905157541440104\n    eval_accuracy  : 0.9410642119443197\n    eval_eer       : 0.04761068860582535\n    eval_frr       : 0.04758667573079538\n    eval_far       : 0.04763470148085533\n    eval_thr       : 0.9049614667892456\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.000325\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.013961\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000425\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000211\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.000538\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 14\n    loss           : 0.01126124119573341\n    grad norm      : 1.0917834059601048\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.06075306790456124\n    dev_accuracy   : 0.9856821106821106\n    dev_eer        : 0.028256823139954004\n    dev_frr        : 0.0282574568288854\n    dev_far        : 0.028256189451022606\n    dev_thr        : 0.00176902930252254\n    eval_loss      : 0.15044346520914587\n    eval_accuracy  : 0.958029299506062\n    eval_eer       : 0.04869459456082894\n    eval_frr       : 0.0486743711760707\n    eval_far       : 0.04871481794558718\n    eval_thr       : 0.22531026601791382\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.000356\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.012209\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.000356\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.88it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.032381\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000236\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 15\n    loss           : 0.007014624611996385\n    grad norm      : 0.8465732249426609\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.06002617838702963\n    dev_accuracy   : 0.9859234234234234\n    dev_eer        : 0.027085061895918423\n    dev_frr        : 0.02708006279434851\n    dev_far        : 0.027090060997488338\n    dev_thr        : 0.0016040082555264235\n    eval_loss      : 0.1412428440793708\n    eval_accuracy  : 0.9655590480520525\n    eval_eer       : 0.0432594109240033\n    eval_frr       : 0.043235893949694085\n    eval_far       : 0.043282927898312513\n    eval_thr       : 0.08477988094091415\nSaving checkpoint: saved/models/exp4_hints_no_abs_no_weights/1213_150105/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.107226\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.87it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.006285\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000265\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.001735\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  5.99it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.000425\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 16\n    loss           : 0.00766008748145065\n    grad norm      : 0.7100555278546637\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.07171836030975194\n    dev_accuracy   : 0.9839527027027027\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.0005355709581635892\n    eval_loss      : 0.1113333188441877\n    eval_accuracy  : 0.9689604849573417\n    eval_eer       : 0.04527314562873837\n    eval_frr       : 0.04527532290958532\n    eval_far       : 0.045270968347891426\n    eval_thr       : 0.043379221111536026\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.000150\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000329\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.96it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000578\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000190\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000197\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 17\n    loss           : 0.0030456326408837948\n    grad norm      : 0.42972620425544766\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.04436441621238927\n    dev_accuracy   : 0.9906290218790219\n    dev_eer        : 0.0227736536363324\n    dev_frr        : 0.022762951334379906\n    dev_far        : 0.022784355938284893\n    dev_thr        : 0.0017380177741870284\n    eval_loss      : 0.23706631315642393\n    eval_accuracy  : 0.9512797485406377\n    eval_eer       : 0.05041582871682751\n    eval_frr       : 0.0504418762746431\n    eval_far       : 0.05038978115901193\n    eval_thr       : 0.4117819368839264\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000102\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000287\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.97it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000629\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000226\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000244\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 18\n    loss           : 0.005662933375825018\n    grad norm      : 0.8823854532386788\n    accuracy       : 0.9976325757575758\n    dev_loss       : 0.09473349063839188\n    dev_accuracy   : 0.9759089446589446\n    dev_eer        : 0.02628893736843914\n    dev_frr        : 0.02629513343799058\n    dev_far        : 0.026282741298887694\n    dev_thr        : 0.2710680663585663\n    eval_loss      : 0.35486808692456634\n    eval_accuracy  : 0.9284351145038168\n    eval_eer       : 0.045241837905122956\n    eval_frr       : 0.04527532290958532\n    eval_far       : 0.045208352900660595\n    eval_thr       : 0.9873682856559753\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.001254\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.001220\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000227\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.012821\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.000234\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 19\n    loss           : 0.004319209397723134\n    grad norm      : 0.5403235565113713\n    accuracy       : 0.9984217171717171\n    dev_loss       : 0.04469763496950852\n    dev_accuracy   : 0.9903474903474904\n    dev_eer        : 0.024343477144107624\n    dev_frr        : 0.02433281004709576\n    dev_far        : 0.024354144241119483\n    dev_thr        : 0.0014401006046682596\n    eval_loss      : 0.17063873098617377\n    eval_accuracy  : 0.9590536596317917\n    eval_eer       : 0.043382180405659984\n    eval_frr       : 0.0433718558803535\n    eval_far       : 0.04339250493096647\n    eval_thr       : 0.3528521656990051\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000213\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.002802\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000123\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000159\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000169\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 20\n    loss           : 0.006097868991756431\n    grad norm      : 0.5850067247878854\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.052284863727139294\n    dev_accuracy   : 0.9880952380952381\n    dev_eer        : 0.02905294766743329\n    dev_frr        : 0.029042386185243328\n    dev_far        : 0.02906350914962325\n    dev_thr        : 0.005899927578866482\n    eval_loss      : 0.32457784305435805\n    eval_accuracy  : 0.9368545127974854\n    eval_eer       : 0.05558199259762822\n    eval_frr       : 0.05560842963970088\n    eval_far       : 0.05555555555555555\n    eval_thr       : 0.8328270316123962\nSaving checkpoint: saved/models/exp4_hints_no_abs_no_weights/1213_150105/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000366\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000050\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.91it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.002908\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.001195\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000156\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 21\n    loss           : 0.005605380000439125\n    grad norm      : 0.6501284120980688\n    accuracy       : 0.9984217171717171\n    dev_loss       : 0.08120117628457685\n    dev_accuracy   : 0.9813384813384813\n    dev_eer        : 0.022375591372592755\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.02238069608898457\n    dev_thr        : 0.00042142902384512126\n    eval_loss      : 0.10548518435901624\n    eval_accuracy  : 0.97197182308573\n    eval_eer       : 0.04225131286523327\n    eval_frr       : 0.042284160435078176\n    eval_far       : 0.04221846529538837\n    eval_thr       : 0.03047824092209339\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000815\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.000908\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.000094\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000285\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000348\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 22\n    loss           : 0.006987349245195439\n    grad norm      : 0.5884417695418998\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.055987217973577856\n    dev_accuracy   : 0.9864060489060489\n    dev_eer        : 0.017666120849267088\n    dev_frr        : 0.017660910518053376\n    dev_far        : 0.017671331180480802\n    dev_thr        : 0.0006137625314295292\n    eval_loss      : 0.13919798466779898\n    eval_accuracy  : 0.9632633587786259\n    eval_eer       : 0.04556564617747487\n    eval_frr       : 0.045547246770904146\n    eval_far       : 0.045584045584045586\n    eval_thr       : 0.1110617145895958\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.001820\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000420\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.008807\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.002307\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000213\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.78it/s]\n    epoch          : 23\n    loss           : 0.005592172363432121\n    grad norm      : 0.6874753575262877\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.04895626001350557\n    dev_accuracy   : 0.9899453024453024\n    dev_eer        : 0.03022470891146887\n    dev_frr        : 0.03021978021978022\n    dev_far        : 0.030229637603157517\n    dev_thr        : 0.0019707116298377514\n    eval_loss      : 0.250992958972396\n    eval_accuracy  : 0.9515323304894477\n    eval_eer       : 0.0527533716939145\n    eval_frr       : 0.052753229095853164\n    eval_far       : 0.052753514291975834\n    eval_thr       : 0.24460841715335846\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.000472\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000514\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000039\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000063\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000088\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.78it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 24\n    loss           : 0.0042276097016052845\n    grad norm      : 0.32453178902340535\n    accuracy       : 0.9990530303030303\n    dev_loss       : 0.0790837469962592\n    dev_accuracy   : 0.986003861003861\n    dev_eer        : 0.0451268194617418\n    dev_frr        : 0.045133437990580845\n    dev_far        : 0.04512020093290276\n    dev_thr        : 0.0004972328897565603\n    eval_loss      : 0.15890405465160864\n    eval_accuracy  : 0.9634598114054782\n    eval_eer       : 0.049078556867606704\n    eval_frr       : 0.049082256968048944\n    eval_far       : 0.04907485676716446\n    eval_thr       : 0.038095347583293915\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000219\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000131\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000056\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.130951\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.003367\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.77it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.79it/s]\n    epoch          : 25\n    loss           : 0.009174883606491024\n    grad norm      : 0.8124123480432017\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.061192116429731866\n    dev_accuracy   : 0.9847168597168597\n    dev_eer        : 0.02157946684511347\n    dev_frr        : 0.021585557299843013\n    dev_far        : 0.021573376390383925\n    dev_thr        : 0.0016525231767445803\n    eval_loss      : 0.1520871763346979\n    eval_accuracy  : 0.9620565783565335\n    eval_eer       : 0.05142392677559754\n    eval_frr       : 0.051393609789259005\n    eval_far       : 0.051454243761936067\n    eval_thr       : 0.051552824676036835\nSaving checkpoint: saved/models/exp4_hints_no_abs_no_weights/1213_150105/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp6.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:07:30.158516Z","iopub.execute_input":"2023-12-13T18:07:30.159441Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv_fast()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_180736-ap8xr862\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbrisk-dew-9\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/ap8xr862\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.684695\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:45<02:10,  4.55it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.635652\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:28<01:27,  4.54it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.507793\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:12<00:43,  4.57it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.664045\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:55<00:00,  4.62it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.275580\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.52it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.72it/s]\n    epoch          : 1\n    loss           : 0.46343754525437497\n    grad norm      : 7.61634364874676\n    accuracy       : 0.8172348484848485\n    dev_loss       : 0.6708289695186888\n    dev_accuracy   : 0.7255201630457334\n    dev_eer        : 0.2142921215849095\n    dev_frr        : 0.21428571428571427\n    dev_far        : 0.21429852888410478\n    dev_thr        : 0.6808484792709351\n    eval_loss      : 0.4574594640034595\n    eval_accuracy  : 0.8219437584193983\n    eval_eer       : 0.17607266890852102\n    eval_frr       : 0.1760707002039429\n    eval_far       : 0.17607463761309916\n    eval_thr       : 0.5225902199745178\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.577781\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.58it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.147612\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.919423\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.56it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.191546\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.62it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.213548\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.72it/s]\n    epoch          : 2\n    loss           : 0.23378650924999905\n    grad norm      : 6.875827430173604\n    accuracy       : 0.9070391414141414\n    dev_loss       : 0.27319724927206873\n    dev_accuracy   : 0.8739006864518273\n    dev_eer        : 0.18961785881861232\n    dev_frr        : 0.18956043956043955\n    dev_far        : 0.18967527807678508\n    dev_thr        : 0.1763787865638733\n    eval_loss      : 0.6414831751705782\n    eval_accuracy  : 0.8736472833461701\n    eval_eer       : 0.15460878104814726\n    eval_frr       : 0.15458871515975528\n    eval_far       : 0.15462884693653925\n    eval_thr       : 0.08146288245916367\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.220418\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.457573\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.087843\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.039668\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.61it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.365100\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.72it/s]\n    epoch          : 3\n    loss           : 0.19839842162668855\n    grad norm      : 6.846272455622452\n    accuracy       : 0.9278724747474747\n    dev_loss       : 0.19603922817870456\n    dev_accuracy   : 0.9263996138996139\n    dev_eer        : 0.12804153084600572\n    dev_frr        : 0.12794348508634223\n    dev_far        : 0.1281395766056692\n    dev_thr        : 0.14890062808990479\n    eval_loss      : 0.4675615943795163\n    eval_accuracy  : 0.8861697350696004\n    eval_eer       : 0.13432026090081833\n    eval_frr       : 0.1343303874915024\n    eval_far       : 0.1343101343101343\n    eval_thr       : 0.1801561862230301\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.064392\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.54it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.256602\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.052449\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.53it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.067687\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.012936\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.54it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 4\n    loss           : 0.12689262834810322\n    grad norm      : 6.080766565044119\n    accuracy       : 0.9524936868686869\n    dev_loss       : 0.15390315070805863\n    dev_accuracy   : 0.9450745388501093\n    dev_eer        : 0.09843354208454932\n    dev_frr        : 0.09850863422291994\n    dev_far        : 0.09835844994617869\n    dev_thr        : 0.13028647005558014\n    eval_loss      : 0.46909040357557064\n    eval_accuracy  : 0.8836803996461252\n    eval_eer       : 0.1285089418881188\n    eval_frr       : 0.12848402447314752\n    eval_far       : 0.12853385930309008\n    eval_thr       : 0.26641789078712463\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.146154\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.54it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.186387\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:26,  4.58it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.042216\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.56it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.009042\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:53<00:00,  4.60it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.052225\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 5\n    loss           : 0.08376201949519754\n    grad norm      : 5.39770207648175\n    accuracy       : 0.9730113636363636\n    dev_loss       : 0.27209308458656367\n    dev_accuracy   : 0.8965572715572716\n    dev_eer        : 0.09065170118722325\n    dev_frr        : 0.09065934065934066\n    dev_far        : 0.09064406171510585\n    dev_thr        : 0.5645740032196045\n    eval_loss      : 0.3943558075295056\n    eval_accuracy  : 0.8547794117647058\n    eval_eer       : 0.12426477982614573\n    eval_frr       : 0.12426920462270565\n    eval_far       : 0.1242603550295858\n    eval_thr       : 0.8019043803215027\nSaving checkpoint: saved/models/exp6_hints_no_abs_no_base_sinc/1213_180733/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.220692\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.57it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.015203\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.165119\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.095797\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:53<00:00,  4.61it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.151995\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 6\n    loss           : 0.07315001566541579\n    grad norm      : 4.962852249580501\n    accuracy       : 0.9761679292929293\n    dev_loss       : 0.23036271098271813\n    dev_accuracy   : 0.9221096096351801\n    dev_eer        : 0.08830817869915208\n    dev_frr        : 0.08830455259026687\n    dev_far        : 0.08831180480803731\n    dev_thr        : 0.37458211183547974\n    eval_loss      : 0.44274464875253083\n    eval_accuracy  : 0.8686152896273013\n    eval_eer       : 0.12141267812972044\n    eval_frr       : 0.12141400407885793\n    eval_far       : 0.12141135218058295\n    eval_thr       : 0.6794961094856262\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.039879\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.57it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.017622\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.119572\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.016730\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.053413\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.54it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 7\n    loss           : 0.06801823796022383\n    grad norm      : 4.77220198854503\n    accuracy       : 0.9801136363636364\n    dev_loss       : 0.14288072293572443\n    dev_accuracy   : 0.9591243029254437\n    dev_eer        : 0.08631786738045388\n    dev_frr        : 0.08634222919937205\n    dev_far        : 0.0862935055615357\n    dev_thr        : 0.015162383206188679\n    eval_loss      : 0.5621982415962724\n    eval_accuracy  : 0.898476088908846\n    eval_eer       : 0.1176072668908521\n    eval_frr       : 0.11760707002039429\n    eval_far       : 0.11760746376130991\n    eval_thr       : 0.07807748019695282\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.082733\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.028487\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.241437\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.206760\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.061193\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.54it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 8\n    loss           : 0.049550876922722004\n    grad norm      : 3.9419304307531378\n    accuracy       : 0.9824810606060606\n    dev_loss       : 0.11156430161017067\n    dev_accuracy   : 0.959740990990991\n    dev_eer        : 0.0651588883462634\n    dev_frr        : 0.065149136577708\n    dev_far        : 0.06516864011481881\n    dev_thr        : 0.09064663201570511\n    eval_loss      : 0.3789117378363579\n    eval_accuracy  : 0.8921615401885945\n    eval_eer       : 0.10689097682247292\n    eval_frr       : 0.10686607749830047\n    eval_far       : 0.10691587614664538\n    eval_thr       : 0.5290923714637756\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.432082\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.57it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.001732\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.001473\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.57it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.079032\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.61it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.003484\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 9\n    loss           : 0.040540849877582545\n    grad norm      : 3.0702323258638082\n    accuracy       : 0.9846906565656566\n    dev_loss       : 0.12704369760475162\n    dev_accuracy   : 0.9643661518661518\n    dev_eer        : 0.07565988844821692\n    dev_frr        : 0.07574568288854003\n    dev_far        : 0.07557409400789379\n    dev_thr        : 0.024072356522083282\n    eval_loss      : 0.5180639317700912\n    eval_accuracy  : 0.8934525145936237\n    eval_eer       : 0.115700647805966\n    eval_frr       : 0.11570360299116247\n    eval_far       : 0.11569769262076954\n    eval_thr       : 0.2072417438030243\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.035395\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.58it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.001995\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.003744\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.57it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.000594\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.62it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.013436\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.70it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.71it/s]\n    epoch          : 10\n    loss           : 0.02765849141503691\n    grad norm      : 2.251383693479566\n    accuracy       : 0.9906881313131313\n    dev_loss       : 0.10770348071378212\n    dev_accuracy   : 0.9707475332986741\n    dev_eer        : 0.06082505453949403\n    dev_frr        : 0.060832025117739406\n    dev_far        : 0.06081808396124865\n    dev_thr        : 0.011892111040651798\n    eval_loss      : 0.5084763931107992\n    eval_accuracy  : 0.9060956443646161\n    eval_eer       : 0.10469185718885034\n    eval_frr       : 0.10469068660774983\n    eval_far       : 0.10469302776995085\n    eval_thr       : 0.1976523995399475\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.030511\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.008352\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.014821\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.53it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.045882\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.61it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.025275\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.67it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 11\n    loss           : 0.030399041407185398\n    grad norm      : 2.362996869310125\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.06252138300176603\n    dev_accuracy   : 0.9812982625482626\n    dev_eer        : 0.0372777019228657\n    dev_frr        : 0.03728414442700157\n    dev_far        : 0.037271259418729816\n    dev_thr        : 0.026089094579219818\n    eval_loss      : 0.44598894092959734\n    eval_accuracy  : 0.9016473955994612\n    eval_eer       : 0.09610424437595906\n    eval_frr       : 0.09612508497620666\n    eval_far       : 0.09608340377571147\n    eval_thr       : 0.5816200971603394\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.005283\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.004092\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.038064\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.57it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.007310\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.61it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.001493\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 12\n    loss           : 0.037144491068370325\n    grad norm      : 2.5674867636119627\n    accuracy       : 0.9892676767676768\n    dev_loss       : 0.10700668932615624\n    dev_accuracy   : 0.9660687473443177\n    dev_eer        : 0.04983628998506747\n    dev_frr        : 0.049843014128728415\n    dev_far        : 0.04982956584140653\n    dev_thr        : 0.1741616129875183\n    eval_loss      : 0.4032573104517904\n    eval_accuracy  : 0.8906741131567131\n    eval_eer       : 0.0973344006053309\n    eval_frr       : 0.0973487423521414\n    eval_far       : 0.0973200588585204\n    eval_thr       : 0.8141358494758606\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.016661\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.55it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.003509\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.57it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.018363\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000475\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.62it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.002427\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 13\n    loss           : 0.02587341950474909\n    grad norm      : 2.448759015656613\n    accuracy       : 0.9908459595959596\n    dev_loss       : 0.10591461527586771\n    dev_accuracy   : 0.9709754397510102\n    dev_eer        : 0.04826646647729225\n    dev_frr        : 0.048273155416012556\n    dev_far        : 0.04825977753857194\n    dev_thr        : 0.034927502274513245\n    eval_loss      : 0.49167829254184414\n    eval_accuracy  : 0.8869415132465199\n    eval_eer       : 0.10523772363180406\n    eval_frr       : 0.10523453433038749\n    eval_far       : 0.10524091293322063\n    eval_thr       : 0.8245208859443665\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.002699\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.55it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.016939\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.012524\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.001662\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.009348\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.68it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.69it/s]\n    epoch          : 14\n    loss           : 0.033116988459405916\n    grad norm      : 3.3804494485075613\n    accuracy       : 0.9873737373737373\n    dev_loss       : 0.0968184059555013\n    dev_accuracy   : 0.9708413770913771\n    dev_eer        : 0.04625372961141068\n    dev_frr        : 0.04631083202511774\n    dev_far        : 0.04619662719770362\n    dev_thr        : 0.047788169234991074\n    eval_loss      : 0.47535778517129346\n    eval_accuracy  : 0.8897058823529411\n    eval_eer       : 0.1018475824233289\n    eval_frr       : 0.10183548606390211\n    eval_far       : 0.1018596787827557\n    eval_thr       : 0.8092224597930908\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.035219\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.54it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.018112\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.55it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.002888\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:11<00:44,  4.50it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.049253\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.001513\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:55<00:00,  4.54it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:50<00:00,  9.68it/s]\n    epoch          : 15\n    loss           : 0.02501652652691436\n    grad norm      : 2.70863739608533\n    accuracy       : 0.9903724747474747\n    dev_loss       : 0.06613610345409389\n    dev_accuracy   : 0.9791800729556434\n    dev_eer        : 0.0369020652063094\n    dev_frr        : 0.036891679748822605\n    dev_far        : 0.0369124506637962\n    dev_thr        : 0.05125659331679344\n    eval_loss      : 0.38018198533362235\n    eval_accuracy  : 0.9012264256847777\n    eval_eer       : 0.0907081953936527\n    eval_frr       : 0.09068660774983005\n    eval_far       : 0.09072978303747535\n    eval_thr       : 0.7524875402450562\nSaving checkpoint: saved/models/exp6_hints_no_abs_no_base_sinc/1213_180733/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.015230\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:11,  4.53it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.001593\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.54it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.002454\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:44,  4.54it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000324\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.60it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.000218\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.54it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.65it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:50<00:00,  9.68it/s]\n    epoch          : 16\n    loss           : 0.013589015548253277\n    grad norm      : 1.674646585217837\n    accuracy       : 0.9957386363636364\n    dev_loss       : 0.07628265426865957\n    dev_accuracy   : 0.9794079794079794\n    dev_eer        : 0.04437554602862922\n    dev_frr        : 0.04434850863422292\n    dev_far        : 0.04440258342303552\n    dev_thr        : 0.025554340332746506\n    eval_loss      : 0.43494297906114054\n    eval_accuracy  : 0.9055343511450382\n    eval_eer       : 0.08852472962183781\n    eval_frr       : 0.0885112168592794\n    eval_far       : 0.08853824238439623\n    eval_thr       : 0.7131577134132385\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.001709\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.55it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.001004\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.56it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000704\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [02:10<00:43,  4.57it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.005423\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:54<00:00,  4.62it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.007500\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:54<00:00,  4.55it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.69it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:49<00:00,  9.70it/s]\n    epoch          : 17\n    loss           : 0.034107516546477326\n    grad norm      : 3.211858263286301\n    accuracy       : 0.9881628787878788\n    dev_loss       : 0.11681203046238685\n    dev_accuracy   : 0.96921921927036\n    dev_eer        : 0.06005135555919809\n    dev_frr        : 0.060047095761381473\n    dev_far        : 0.06005561535701471\n    dev_thr        : 0.006370228249579668\n    eval_loss      : 0.49443363949106456\n    eval_accuracy  : 0.9021244948361024\n    eval_eer       : 0.10819694094807833\n    eval_frr       : 0.10822569680489463\n    eval_far       : 0.10816818509126201\n    eval_thr       : 0.183912992477417\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.050696\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:43<02:10,  4.57it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.091436\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:27<01:27,  4.53it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.001492\ntrain:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 456/794 [01:40<01:14,  4.54it/s]","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp8.json","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:55:13.789009Z","iopub.execute_input":"2023-12-13T20:55:13.789513Z","iopub.status.idle":"2023-12-14T00:00:42.936877Z","shell.execute_reply.started":"2023-12-13T20:55:13.789481Z","shell.execute_reply":"2023-12-14T00:00:42.935582Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231213_205524-ubh8sn5r\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msparkling-disco-11\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/ubh8sn5r\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.690704\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:38<01:40,  5.93it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.346683\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:11<01:06,  5.95it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.132292\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:44<00:33,  5.95it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.085739\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:18<00:00,  6.03it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.208981\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:18<00:00,  5.73it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 1\n    loss           : 0.18610544974040805\n    grad norm      : 11.626867225073804\n    accuracy       : 0.931344696969697\n    dev_loss       : 0.22345702004519458\n    dev_accuracy   : 0.9188652939164347\n    dev_eer        : 0.07212217916892683\n    dev_frr        : 0.07221350078492936\n    dev_far        : 0.0720308575529243\n    dev_thr        : 0.6192474365234375\n    eval_loss      : 0.33993183315004344\n    eval_accuracy  : 0.8696677144140099\n    eval_eer       : 0.11816096026470968\n    eval_frr       : 0.11815091774303195\n    eval_far       : 0.1181710027863874\n    eval_thr       : 0.7341552972793579\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.053505\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.037209\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.079205\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.028877\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.060598\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.77it/s]\n    epoch          : 2\n    loss           : 0.11722152293989002\n    grad norm      : 7.60403751077676\n    accuracy       : 0.9591224747474747\n    dev_loss       : 0.09956631916928725\n    dev_accuracy   : 0.9653179966191374\n    dev_eer        : 0.05965329329545845\n    dev_frr        : 0.059654631083202514\n    dev_far        : 0.05965195550771439\n    dev_thr        : 0.10747470706701279\n    eval_loss      : 0.3482940376351065\n    eval_accuracy  : 0.9006791647956892\n    eval_eer       : 0.10728276606015455\n    eval_frr       : 0.10727396329027872\n    eval_far       : 0.10729156883003037\n    eval_thr       : 0.33062469959259033\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.062267\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.127296\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.006489\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.055265\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.038970\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.77it/s]\n    epoch          : 3\n    loss           : 0.08295589109360607\n    grad norm      : 6.067448378587612\n    accuracy       : 0.9726957070707071\n    dev_loss       : 0.1510209030870899\n    dev_accuracy   : 0.9499544187555595\n    dev_eer        : 0.03891480207219097\n    dev_frr        : 0.03885400313971742\n    dev_far        : 0.03897560100466451\n    dev_thr        : 0.7413708567619324\n    eval_loss      : 0.4205494449561948\n    eval_accuracy  : 0.8723198248765155\n    eval_eer       : 0.10004025202738794\n    eval_frr       : 0.1000679809653297\n    eval_far       : 0.10001252308944616\n    eval_thr       : 0.9621631503105164\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.037989\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.073672\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.037933\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.016212\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.057259\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 4\n    loss           : 0.06631250829245387\n    grad norm      : 5.4441012903069605\n    accuracy       : 0.9764835858585859\n    dev_loss       : 0.36094103774872094\n    dev_accuracy   : 0.8625187688199096\n    dev_eer        : 0.04514924500892516\n    dev_frr        : 0.045133437990580845\n    dev_far        : 0.04516505202726947\n    dev_thr        : 0.9395140409469604\n    eval_loss      : 0.4380207114447733\n    eval_accuracy  : 0.8409856308935788\n    eval_eer       : 0.09928015434473626\n    eval_frr       : 0.09925220938137322\n    eval_far       : 0.0993080993080993\n    eval_thr       : 0.9844993948936462\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.025554\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.001635\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.070220\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.061660\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.05it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.001510\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 5\n    loss           : 0.045084467251794505\n    grad norm      : 3.4941375370965235\n    accuracy       : 0.9859532828282829\n    dev_loss       : 0.12823272128551247\n    dev_accuracy   : 0.9700504075759779\n    dev_eer        : 0.07457782939291474\n    dev_frr        : 0.07456828885400314\n    dev_far        : 0.07458736993182634\n    dev_thr        : 0.0029633163940161467\n    eval_loss      : 0.47758349866467664\n    eval_accuracy  : 0.9158621463852716\n    eval_eer       : 0.09625832158123115\n    eval_frr       : 0.09626104690686607\n    eval_far       : 0.09625559625559625\n    eval_thr       : 0.084367536008358\nSaving checkpoint: saved/models/exp8_hints_mel_inv/1213_205519/checkpoint-epoch5.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.115594\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.008618\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.023079\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.098424\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.016048\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 6\n    loss           : 0.0273847062237128\n    grad norm      : 3.1730446894606104\n    accuracy       : 0.9917929292929293\n    dev_loss       : 0.09557779327993392\n    dev_accuracy   : 0.9726244101499806\n    dev_eer        : 0.035618176226357066\n    dev_frr        : 0.03571428571428571\n    dev_far        : 0.03552206673842842\n    dev_thr        : 0.2777317464351654\n    eval_loss      : 0.4470534852070656\n    eval_accuracy  : 0.8767400089806915\n    eval_eer       : 0.0913768313182631\n    eval_frr       : 0.09136641740312712\n    eval_far       : 0.09138724523339908\n    eval_thr       : 0.9855445027351379\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.155057\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.114085\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.146035\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.008659\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.001407\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 7\n    loss           : 0.04196368703957309\n    grad norm      : 3.8163457424520995\n    accuracy       : 0.9865845959595959\n    dev_loss       : 0.07760099052171412\n    dev_accuracy   : 0.9754263191763192\n    dev_eer        : 0.032147743588617037\n    dev_frr        : 0.03218210361067504\n    dev_far        : 0.032113383566559024\n    dev_thr        : 0.1973354071378708\n    eval_loss      : 0.4298329976304127\n    eval_accuracy  : 0.8814548720251459\n    eval_eer       : 0.09547474310586793\n    eval_frr       : 0.09544527532290958\n    eval_far       : 0.09550421088882627\n    eval_thr       : 0.9720582365989685\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.025319\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.045750\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.593976\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.139680\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.00it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.000595\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 8\n    loss           : 0.018025582014657135\n    grad norm      : 2.007241905208282\n    accuracy       : 0.9946338383838383\n    dev_loss       : 0.0692959382042875\n    dev_accuracy   : 0.9830276705276705\n    dev_eer        : 0.035332241698534175\n    dev_frr        : 0.03532182103610675\n    dev_far        : 0.035342662360961605\n    dev_thr        : 0.0022670167963951826\n    eval_loss      : 0.4469466091692312\n    eval_accuracy  : 0.9077935563538393\n    eval_eer       : 0.09096156128786992\n    eval_frr       : 0.09095853161114888\n    eval_far       : 0.09096459096459096\n    eval_thr       : 0.5614990592002869\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.019633\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.002504\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.001502\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.89it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.002963\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.027256\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 9\n    loss           : 0.027592580413593994\n    grad norm      : 3.3310750549038253\n    accuracy       : 0.98989898989899\n    dev_loss       : 0.09071559553269119\n    dev_accuracy   : 0.9718066280566281\n    dev_eer        : 0.03800654980879493\n    dev_frr        : 0.0380690737833595\n    dev_far        : 0.03794402583423036\n    dev_thr        : 0.202729731798172\n    eval_loss      : 0.4565817957440967\n    eval_accuracy  : 0.8736107992815447\n    eval_eer       : 0.09340621988480588\n    eval_frr       : 0.09340584636301835\n    eval_far       : 0.09340659340659341\n    eval_thr       : 0.9861637949943542\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.002851\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.86it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.000772\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.98it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.003270\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.001812\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.001052\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 10\n    loss           : 0.02226915525200023\n    grad norm      : 2.8278521948853848\n    accuracy       : 0.9903724747474747\n    dev_loss       : 0.04616284188853042\n    dev_accuracy   : 0.9853603603603603\n    dev_eer        : 0.024719113860663916\n    dev_frr        : 0.024725274725274724\n    dev_far        : 0.024712952996053104\n    dev_thr        : 0.0728517696261406\n    eval_loss      : 0.4129970320868577\n    eval_accuracy  : 0.8795184104176021\n    eval_eer       : 0.09531283896969198\n    eval_frr       : 0.09530931339225017\n    eval_far       : 0.09531636454713378\n    eval_thr       : 0.9630118012428284\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.003015\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000627\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.000327\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.000920\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.006267\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 11\n    loss           : 0.03211122455376417\n    grad norm      : 2.260788193489942\n    accuracy       : 0.992739898989899\n    dev_loss       : 0.05931501140617382\n    dev_accuracy   : 0.9822232947232947\n    dev_eer        : 0.03769818973378869\n    dev_frr        : 0.03767660910518053\n    dev_far        : 0.03771977036239684\n    dev_thr        : 0.021711263805627823\n    eval_loss      : 0.3509394655980213\n    eval_accuracy  : 0.9029664346654692\n    eval_eer       : 0.08920901940825593\n    eval_frr       : 0.08919102651257647\n    eval_far       : 0.08922701230393539\n    eval_thr       : 0.7212889790534973\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.011279\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.015727\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.023337\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000618\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.056818\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 12\n    loss           : 0.0231086240437251\n    grad norm      : 2.0559740560411504\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.10135467151520615\n    dev_accuracy   : 0.9687902187902188\n    dev_eer        : 0.019544304432048548\n    dev_frr        : 0.019623233908948195\n    dev_far        : 0.019465374955148905\n    dev_thr        : 0.8636741638183594\n    eval_loss      : 0.5041105852419983\n    eval_accuracy  : 0.8613325101032779\n    eval_eer       : 0.08608007102490187\n    eval_frr       : 0.08606390210740993\n    eval_far       : 0.08609623994239379\n    eval_thr       : 0.99790358543396\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.026545\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.000345\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.000611\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.019456\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.013967\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 13\n    loss           : 0.022774190952160014\n    grad norm      : 2.241094904497849\n    accuracy       : 0.9936868686868687\n    dev_loss       : 0.07910478761381598\n    dev_accuracy   : 0.9698359073359073\n    dev_eer        : 0.0455921583670315\n    dev_frr        : 0.04552590266875981\n    dev_far        : 0.045658414065303195\n    dev_thr        : 0.11324778944253922\n    eval_loss      : 0.2504044598977148\n    eval_accuracy  : 0.9095560170686667\n    eval_eer       : 0.09262264140944265\n    eval_frr       : 0.09259007477906187\n    eval_far       : 0.09265520803982343\n    eval_thr       : 0.461995005607605\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.012392\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.035415\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.050937\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.010857\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.000705\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 14\n    loss           : 0.02121390545601966\n    grad norm      : 2.1045375970013516\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.04645727000962925\n    dev_accuracy   : 0.9874517374517374\n    dev_eer        : 0.02073849122326748\n    dev_frr        : 0.020800627943485087\n    dev_far        : 0.020676354503049874\n    dev_thr        : 0.07065394520759583\n    eval_loss      : 0.3855047274697209\n    eval_accuracy  : 0.8915721823080377\n    eval_eer       : 0.08389660525308698\n    eval_frr       : 0.08388851121685928\n    eval_far       : 0.08390469928931467\n    eval_thr       : 0.9797393679618835\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.000936\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.035734\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.051412\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.043969\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.001295\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 15\n    loss           : 0.020648089816647987\n    grad norm      : 2.3632963484416556\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.03669207417323363\n    dev_accuracy   : 0.9890202702702703\n    dev_eer        : 0.020009643337338248\n    dev_frr        : 0.020015698587127158\n    dev_far        : 0.020003588087549335\n    dev_thr        : 0.015882300212979317\n    eval_loss      : 0.36623636684574934\n    eval_accuracy  : 0.9010720700493938\n    eval_eer       : 0.08796320931707638\n    eval_frr       : 0.08796736913664174\n    eval_far       : 0.08795904949751103\n    eval_thr       : 0.8410849571228027\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.001684\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.018308\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000619\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000580\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.000979\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 16\n    loss           : 0.011381386548861764\n    grad norm      : 1.582868315518194\n    accuracy       : 0.9960542929292929\n    dev_loss       : 0.07048241567840173\n    dev_accuracy   : 0.9851994851994852\n    dev_eer        : 0.038449463166901274\n    dev_frr        : 0.038461538461538464\n    dev_far        : 0.038437387872264084\n    dev_thr        : 0.0010159284574910998\n    eval_loss      : 0.4607206361601567\n    eval_accuracy  : 0.8981112483161203\n    eval_eer       : 0.08644837946987191\n    eval_frr       : 0.08647178789938817\n    eval_far       : 0.08642497104035565\n    eval_thr       : 0.9508253335952759\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.000346\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.003829\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000396\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000542\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.09it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000371\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 17\n    loss           : 0.011865072057440152\n    grad norm      : 1.3190428650787458\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.03679364463617251\n    dev_accuracy   : 0.9891409266409267\n    dev_eer        : 0.02242044246695946\n    dev_frr        : 0.022370486656200943\n    dev_far        : 0.022470398277717976\n    dev_thr        : 0.030333027243614197\n    eval_loss      : 0.3693404074850399\n    eval_accuracy  : 0.8956275258194881\n    eval_eer       : 0.08755576621758707\n    eval_frr       : 0.0875594833446635\n    eval_far       : 0.08755204909051063\n    eval_thr       : 0.9024470448493958\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.001357\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000206\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000189\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.006033\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000217\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 18\n    loss           : 0.016254053628793858\n    grad norm      : 1.5798382523817698\n    accuracy       : 0.9930555555555556\n    dev_loss       : 0.08083646345167886\n    dev_accuracy   : 0.9830678893178894\n    dev_eer        : 0.03847188871408462\n    dev_frr        : 0.038461538461538464\n    dev_far        : 0.038482238966630784\n    dev_thr        : 0.0005003921105526388\n    eval_loss      : 0.4194538671363392\n    eval_accuracy  : 0.9098422766052986\n    eval_eer       : 0.08269775674733056\n    eval_frr       : 0.08266485384092453\n    eval_far       : 0.08273065965373658\n    eval_thr       : 0.8099633455276489\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.001064\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.89it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.003857\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.055317\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.002167\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  5.99it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.004660\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 19\n    loss           : 0.023397953351083533\n    grad norm      : 2.0641570866009165\n    accuracy       : 0.9933712121212122\n    dev_loss       : 0.03642383764386765\n    dev_accuracy   : 0.9867277992277992\n    dev_eer        : 0.021136553487007124\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.0210800143523502\n    dev_thr        : 0.19773583114147186\n    eval_loss      : 0.31471447656900287\n    eval_accuracy  : 0.8806129321957791\n    eval_eer       : 0.08920901940825593\n    eval_frr       : 0.08919102651257647\n    eval_far       : 0.08922701230393539\n    eval_thr       : 0.9398767948150635\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.004440\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.010709\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.95it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000740\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000113\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000214\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 20\n    loss           : 0.012742883274878488\n    grad norm      : 1.0368081877570166\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.042004084775440764\n    dev_accuracy   : 0.9897844272844273\n    dev_eer        : 0.020828193412000887\n    dev_frr        : 0.020800627943485087\n    dev_far        : 0.020855758880516686\n    dev_thr        : 0.003202664665877819\n    eval_loss      : 0.4307076490364218\n    eval_accuracy  : 0.9041170857656039\n    eval_eer       : 0.07902294192102277\n    eval_frr       : 0.07899388171312033\n    eval_far       : 0.0790520021289252\n    eval_thr       : 0.9617369174957275\nSaving checkpoint: saved/models/exp8_hints_mel_inv/1213_205519/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000148\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000080\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.92it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.000424\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000184\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.004346\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 21\n    loss           : 0.011764250954222392\n    grad norm      : 1.043604138003006\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.14562141631204084\n    dev_accuracy   : 0.9533998284253988\n    dev_eer        : 0.03022470891146887\n    dev_frr        : 0.03021978021978022\n    dev_far        : 0.030229637603157517\n    dev_thr        : 0.8343847393989563\n    eval_loss      : 0.42304895402614584\n    eval_accuracy  : 0.8573613605747643\n    eval_eer       : 0.08375035497871873\n    eval_frr       : 0.08375254928619986\n    eval_far       : 0.0837481606712376\n    eval_thr       : 0.9921694397926331\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.007497\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.88it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.003701\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.056174\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000627\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.00it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000452\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 22\n    loss           : 0.013506841381104554\n    grad norm      : 1.5376735855425434\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.023608230820203482\n    dev_accuracy   : 0.9932834620334621\n    dev_eer        : 0.014526473833716644\n    dev_frr        : 0.014521193092621664\n    dev_far        : 0.014531754574811625\n    dev_thr        : 0.018389182165265083\n    eval_loss      : 0.35886213409749007\n    eval_accuracy  : 0.8965817242927705\n    eval_eer       : 0.07956880836397648\n    eval_frr       : 0.07953772943575799\n    eval_far       : 0.07959988729219498\n    eval_thr       : 0.9751999974250793\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000583\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000157\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.001979\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:34,  5.87it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000794\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.00it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000391\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 23\n    loss           : 0.010484855434274644\n    grad norm      : 1.0841867399567766\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.037527851880684186\n    dev_accuracy   : 0.9895163020418725\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.013812229037284851\n    eval_loss      : 0.35955973468172303\n    eval_accuracy  : 0.8987286708576561\n    eval_eer       : 0.08089825328229344\n    eval_frr       : 0.08089734874235215\n    eval_far       : 0.08089915782223475\n    eval_thr       : 0.9583730697631836\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.003640\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000311\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000216\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.005514\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000968\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 24\n    loss           : 0.02179199400959969\n    grad norm      : 1.5425685087425842\n    accuracy       : 0.9932133838383839\n    dev_loss       : 0.04775100509381998\n    dev_accuracy   : 0.9856150793906497\n    dev_eer        : 0.02363705480536174\n    dev_frr        : 0.023547880690737835\n    dev_far        : 0.02372622891998565\n    dev_thr        : 0.05289912596344948\n    eval_loss      : 0.3927654414740903\n    eval_accuracy  : 0.8920492815446789\n    eval_eer       : 0.08212058258076142\n    eval_frr       : 0.08212100611828688\n    eval_far       : 0.08212015904323597\n    eval_thr       : 0.9857132434844971\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000485\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.97it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000301\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.94it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000341\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.001683\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.080076\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 25\n    loss           : 0.013833698311322628\n    grad norm      : 1.2992832353091657\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.05441505791030189\n    dev_accuracy   : 0.9864462676962676\n    dev_eer        : 0.027505549706841416\n    dev_frr        : 0.027472527472527472\n    dev_far        : 0.027538571941155363\n    dev_thr        : 0.004133190494030714\n    eval_loss      : 0.43657308453343224\n    eval_accuracy  : 0.9007633587786259\n    eval_eer       : 0.0845965489013128\n    eval_frr       : 0.08456832087015635\n    eval_far       : 0.08462477693246924\n    eval_thr       : 0.9550402164459229\nSaving checkpoint: saved/models/exp8_hints_mel_inv/1213_205519/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/config-exp/exp10.json","metadata":{"execution":{"iopub.status.busy":"2023-12-14T00:01:10.990349Z","iopub.execute_input":"2023-12-14T00:01:10.991012Z","iopub.status.idle":"2023-12-14T03:06:38.789962Z","shell.execute_reply.started":"2023-12-14T00:01:10.990973Z","shell.execute_reply":"2023-12-14T03:06:38.788769Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(20, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=20, out_features=20, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(20, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(20, 128, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (leaky_relu): LeakyReLU(negative_slope=0.1)\n  (gru): GRU(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231214_000117-batqxmcw\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvisionary-energy-13\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/batqxmcw\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.690679\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:34<01:39,  5.98it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.384174\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:08<01:07,  5.92it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.090976\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:41<00:33,  5.93it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.095910\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.05it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.098871\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:15<00:00,  5.87it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.76it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:47<00:00,  9.77it/s]\n    epoch          : 1\n    loss           : 0.1911932228208341\n    grad norm      : 11.107739896485299\n    accuracy       : 0.929135101010101\n    dev_loss       : 0.3138961374407282\n    dev_accuracy   : 0.8797055984555985\n    dev_eer        : 0.07535152837321067\n    dev_frr        : 0.07535321821036106\n    dev_far        : 0.07534983853606028\n    dev_thr        : 0.8049383759498596\n    eval_loss      : 0.31173882302570943\n    eval_accuracy  : 0.8573894252357431\n    eval_eer       : 0.1155465706006939\n    eval_frr       : 0.11556764106050306\n    eval_far       : 0.11552550014088475\n    eval_thr       : 0.829434335231781\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.046482\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.039664\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.095132\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.040126\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.097840\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 2\n    loss           : 0.12970046995141815\n    grad norm      : 8.219867706750378\n    accuracy       : 0.9513888888888888\n    dev_loss       : 0.10509962863031118\n    dev_accuracy   : 0.9607866795366795\n    dev_eer        : 0.056182860657718416\n    dev_frr        : 0.05612244897959184\n    dev_far        : 0.056243272335844995\n    dev_thr        : 0.19019566476345062\n    eval_loss      : 0.34095881090277397\n    eval_accuracy  : 0.8903233048944769\n    eval_eer       : 0.10890471152720799\n    eval_frr       : 0.1089055064581917\n    eval_far       : 0.10890391659622428\n    eval_thr       : 0.5268785357475281\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.070611\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.412220\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.012129\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.258303\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.00it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.076222\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 3\n    loss           : 0.0903744287977014\n    grad norm      : 6.315361164322104\n    accuracy       : 0.9725378787878788\n    dev_loss       : 0.1260401875790037\n    dev_accuracy   : 0.9546734234234234\n    dev_eer        : 0.047801127572002555\n    dev_frr        : 0.047880690737833596\n    dev_far        : 0.04772156440617151\n    dev_thr        : 0.43778178095817566\n    eval_loss      : 0.342520922639871\n    eval_accuracy  : 0.8769504939380333\n    eval_eer       : 0.10060959926305321\n    eval_frr       : 0.10061182868796736\n    eval_far       : 0.10060736983813907\n    eval_thr       : 0.8833708763122559\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.055629\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.036935\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.041773\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.026132\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.089063\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 4\n    loss           : 0.07023901319968505\n    grad norm      : 5.687573325754416\n    accuracy       : 0.9745896464646465\n    dev_loss       : 0.08077692659403211\n    dev_accuracy   : 0.9701174388674388\n    dev_eer        : 0.04112377127716202\n    dev_frr        : 0.04120879120879121\n    dev_far        : 0.04103875134553283\n    dev_thr        : 0.25717583298683167\n    eval_loss      : 0.35708129038778313\n    eval_accuracy  : 0.8792096991468343\n    eval_eer       : 0.10170133214896065\n    eval_frr       : 0.1016995241332427\n    eval_far       : 0.10170314016467863\n    eval_thr       : 0.8316615223884583\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.018352\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.98it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.003852\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.95it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.058073\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.019798\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.003372\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 5\n    loss           : 0.05191244244824794\n    grad norm      : 4.5800564268020665\n    accuracy       : 0.9818497474747475\n    dev_loss       : 0.06321591871515543\n    dev_accuracy   : 0.979689510939511\n    dev_eer        : 0.039598798863753504\n    dev_frr        : 0.039638932496075356\n    dev_far        : 0.039558665231431644\n    dev_thr        : 0.03558048605918884\n    eval_loss      : 0.3912509751927639\n    eval_accuracy  : 0.8961186573866188\n    eval_eer       : 0.0995491741007612\n    eval_frr       : 0.09952413324269205\n    eval_far       : 0.09957421495883034\n    eval_thr       : 0.6349599361419678\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.007680\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.003337\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.025285\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.028833\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.009798\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 6\n    loss           : 0.05024353372705677\n    grad norm      : 3.748301961826104\n    accuracy       : 0.9846906565656566\n    dev_loss       : 0.06264653385530988\n    dev_accuracy   : 0.9805072930328634\n    dev_eer        : 0.04041734893841614\n    dev_frr        : 0.04042386185243328\n    dev_far        : 0.040410836024398995\n    dev_thr        : 0.0321059376001358\n    eval_loss      : 0.3440889275419937\n    eval_accuracy  : 0.8970307588684329\n    eval_eer       : 0.09435952942724893\n    eval_frr       : 0.09435757987763427\n    eval_far       : 0.09436147897686359\n    eval_thr       : 0.7293543219566345\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.011790\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.002311\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.94it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.038234\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.003288\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.01it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.001443\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 7\n    loss           : 0.03953700096168875\n    grad norm      : 4.20786639198548\n    accuracy       : 0.9851641414141414\n    dev_loss       : 0.06354220004540011\n    dev_accuracy   : 0.9821294509305917\n    dev_eer        : 0.03608351513164676\n    dev_frr        : 0.03610675039246468\n    dev_far        : 0.03606027987082885\n    dev_thr        : 0.011007029563188553\n    eval_loss      : 0.3841543162616543\n    eval_accuracy  : 0.902489335428828\n    eval_eer       : 0.09299877678531655\n    eval_frr       : 0.09299796057104011\n    eval_far       : 0.092999592999593\n    eval_thr       : 0.6441665291786194\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.006664\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.89it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.160256\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.210149\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.017455\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.02it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.005383\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 8\n    loss           : 0.030639375546462646\n    grad norm      : 3.450315018250334\n    accuracy       : 0.9900568181818182\n    dev_loss       : 0.20915375915627915\n    dev_accuracy   : 0.9311856499356499\n    dev_eer        : 0.03367271600202555\n    dev_frr        : 0.033751962323390894\n    dev_far        : 0.03359346968066021\n    dev_thr        : 0.9396318197250366\n    eval_loss      : 0.4630192867437353\n    eval_accuracy  : 0.8482403457566232\n    eval_eer       : 0.0991025963467526\n    eval_frr       : 0.0991162474507138\n    eval_far       : 0.0990889452427914\n    eval_thr       : 0.989532470703125\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.003152\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.000423\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000845\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.008732\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.000219\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 9\n    loss           : 0.01725792527606539\n    grad norm      : 2.077675949271787\n    accuracy       : 0.9933712121212122\n    dev_loss       : 0.07224868953947793\n    dev_accuracy   : 0.9836845774601478\n    dev_eer        : 0.03256823139954003\n    dev_frr        : 0.032574568288854\n    dev_far        : 0.03256189451022605\n    dev_thr        : 0.0015546047361567616\n    eval_loss      : 0.5081711490899763\n    eval_accuracy  : 0.8997951279748541\n    eval_eer       : 0.09681201495508875\n    eval_frr       : 0.09680489462950374\n    eval_far       : 0.09681913528067375\n    eval_thr       : 0.6975116729736328\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.002314\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.112980\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:06,  5.97it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.005069\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.001182\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.026900\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 10\n    loss           : 0.03535899680131056\n    grad norm      : 3.281276875798769\n    accuracy       : 0.9906881313131313\n    dev_loss       : 0.045633343251259034\n    dev_accuracy   : 0.9861647361647362\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.2982773184776306\n    eval_loss      : 0.2650544128834877\n    eval_accuracy  : 0.8835737539290526\n    eval_eer       : 0.08687930336207281\n    eval_frr       : 0.08687967369136641\n    eval_far       : 0.08687893303277919\n    eval_thr       : 0.8806667327880859\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.085683\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.92it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.001109\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.93it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.002779\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.92it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.001546\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.030736\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 11\n    loss           : 0.026666887822552734\n    grad norm      : 2.189327226326133\n    accuracy       : 0.9925820707070707\n    dev_loss       : 0.045221606653664814\n    dev_accuracy   : 0.9881756756756757\n    dev_eer        : 0.03062277117520851\n    dev_frr        : 0.030612244897959183\n    dev_far        : 0.03063329745245784\n    dev_thr        : 0.022549187764525414\n    eval_loss      : 0.4320559225748472\n    eval_accuracy  : 0.8872361921867984\n    eval_eer       : 0.0886318452416868\n    eval_frr       : 0.08864717878993882\n    eval_far       : 0.08861651169343478\n    eval_thr       : 0.9709987640380859\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.000715\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.003343\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.000469\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.009323\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.00it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.000789\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 12\n    loss           : 0.020214189457644784\n    grad norm      : 1.4632428133733233\n    accuracy       : 0.9951073232323232\n    dev_loss       : 0.032145698684329656\n    dev_accuracy   : 0.9904279279279279\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.018501881510019302\n    eval_loss      : 0.35832983839662413\n    eval_accuracy  : 0.8938173551863493\n    eval_eer       : 0.08647968719348734\n    eval_frr       : 0.08647178789938817\n    eval_far       : 0.08648758648758649\n    eval_thr       : 0.9288864135742188\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.001307\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.91it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.027606\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.008202\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.94it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000779\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.073854\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 13\n    loss           : 0.01393697804407125\n    grad norm      : 1.351526501904844\n    accuracy       : 0.9958964646464646\n    dev_loss       : 0.04214528301493033\n    dev_accuracy   : 0.9888191763191764\n    dev_eer        : 0.02120383012855718\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.021214567635450304\n    dev_thr        : 0.018677890300750732\n    eval_loss      : 0.4599819846607152\n    eval_accuracy  : 0.89176863493489\n    eval_eer       : 0.0825045448875392\n    eval_frr       : 0.08252889191026512\n    eval_far       : 0.08248019786481325\n    eval_thr       : 0.9843995571136475\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.000311\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.025134\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.94it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.000648\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000256\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.037217\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 14\n    loss           : 0.0241109752750337\n    grad norm      : 2.507466287493254\n    accuracy       : 0.9922664141414141\n    dev_loss       : 0.047825483977996915\n    dev_accuracy   : 0.9847704847960552\n    dev_eer        : 0.023547352616628336\n    dev_frr        : 0.023547880690737835\n    dev_far        : 0.023546824542518836\n    dev_thr        : 0.17780274152755737\n    eval_loss      : 0.36433430554457746\n    eval_accuracy  : 0.8833913336326897\n    eval_eer       : 0.08661811053695173\n    eval_frr       : 0.08660774983004758\n    eval_far       : 0.08662847124385586\n    eval_thr       : 0.9643081426620483\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.017142\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.90it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.007206\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.003056\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.024321\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.03it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000394\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 15\n    loss           : 0.015527191480905091\n    grad norm      : 1.4301652520791523\n    accuracy       : 0.9952651515151515\n    dev_loss       : 0.033215867016670335\n    dev_accuracy   : 0.9910312097812097\n    dev_eer        : 0.017268058585527445\n    dev_frr        : 0.01726844583987441\n    dev_far        : 0.01726767133118048\n    dev_thr        : 0.007779322098940611\n    eval_loss      : 0.39492150922375013\n    eval_accuracy  : 0.895809946115851\n    eval_eer       : 0.08144411972524716\n    eval_frr       : 0.0814411964649898\n    eval_far       : 0.08144704298550452\n    eval_thr       : 0.9745445847511292\nSaving checkpoint: saved/models/exp10_hints_lin/1214_000114/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.011806\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.86it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.018674\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.89it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000783\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:41<00:33,  5.89it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000227\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.03it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.006612\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.89it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:20<00:00,  9.71it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 16\n    loss           : 0.021732276079413654\n    grad norm      : 1.576081302922426\n    accuracy       : 0.99447601010101\n    dev_loss       : 0.034828630356350164\n    dev_accuracy   : 0.988497425997426\n    dev_eer        : 0.018064183113006733\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018074991029781128\n    dev_thr        : 0.24309229850769043\n    eval_loss      : 0.33005715439505506\n    eval_accuracy  : 0.8777643691064212\n    eval_eer       : 0.09897982686509592\n    eval_frr       : 0.09898028552005439\n    eval_far       : 0.09897936821013745\n    eval_thr       : 0.8842223882675171\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.001880\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.95it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000322\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.93it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.005510\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.96it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.110253\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.006205\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.94it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.72it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 17\n    loss           : 0.02623756600216365\n    grad norm      : 2.543980867258565\n    accuracy       : 0.9910037878787878\n    dev_loss       : 0.056974591135247846\n    dev_accuracy   : 0.9809765122265123\n    dev_eer        : 0.03062277117520851\n    dev_frr        : 0.030612244897959183\n    dev_far        : 0.03063329745245784\n    dev_thr        : 0.17827171087265015\n    eval_loss      : 0.36140189559172153\n    eval_accuracy  : 0.8766558149977548\n    eval_eer       : 0.0852495309641155\n    eval_frr       : 0.08524813052345344\n    eval_far       : 0.08525093140477756\n    eval_thr       : 0.9770393967628479\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.011306\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.000797\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000604\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000575\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  5.99it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.000571\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 18\n    loss           : 0.02213858905915086\n    grad norm      : 1.427895863065402\n    accuracy       : 0.9936868686868687\n    dev_loss       : 0.04906703962361266\n    dev_accuracy   : 0.9874919562419563\n    dev_eer        : 0.025913300651882847\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.025923932543954073\n    dev_thr        : 0.005496435333043337\n    eval_loss      : 0.3975681452563807\n    eval_accuracy  : 0.8924702514593623\n    eval_eer       : 0.0831888346739573\n    eval_frr       : 0.0832087015635622\n    eval_far       : 0.0831689677843524\n    eval_thr       : 0.9818285703659058\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.001504\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:41,  5.85it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.003253\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000399\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.93it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.000363\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.000177\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.91it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 19\n    loss           : 0.01107497745220881\n    grad norm      : 1.3506227176921028\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.041720378419060296\n    dev_accuracy   : 0.9894224581724582\n    dev_eer        : 0.02120383012855718\n    dev_frr        : 0.02119309262166405\n    dev_far        : 0.021214567635450304\n    dev_thr        : 0.010690500028431416\n    eval_loss      : 0.43164121673544126\n    eval_accuracy  : 0.8959362370902559\n    eval_eer       : 0.08633343691911907\n    eval_frr       : 0.08633582596872875\n    eval_far       : 0.0863310478695094\n    eval_thr       : 0.9737981557846069\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.000416\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.94it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000258\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.009964\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000075\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:14<00:00,  6.01it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.000259\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.90it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.74it/s]\n    epoch          : 20\n    loss           : 0.020430706932621442\n    grad norm      : 1.6615908713411596\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.032474296456293135\n    dev_accuracy   : 0.9911518661518661\n    dev_eer        : 0.018064183113006733\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018074991029781128\n    dev_thr        : 0.006958313751965761\n    eval_loss      : 0.37300181221440654\n    eval_accuracy  : 0.9021806241580602\n    eval_eer       : 0.07926848088433613\n    eval_frr       : 0.07926580557443916\n    eval_far       : 0.07927115619423311\n    eval_thr       : 0.9589897990226746\nSaving checkpoint: saved/models/exp10_hints_lin/1214_000114/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000584\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000432\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.90it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.015932\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.90it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.004579\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.02it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000455\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.73it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.73it/s]\n    epoch          : 21\n    loss           : 0.017409109739490287\n    grad norm      : 1.4061770980091144\n    accuracy       : 0.9958964646464646\n    dev_loss       : 0.04378518485744144\n    dev_accuracy   : 0.9885778635778636\n    dev_eer        : 0.018064183113006733\n    dev_frr        : 0.01805337519623234\n    dev_far        : 0.018074991029781128\n    dev_thr        : 0.0020341691561043262\n    eval_loss      : 0.3761287009563502\n    eval_accuracy  : 0.9062219353390211\n    eval_eer       : 0.08484208786462616\n    eval_frr       : 0.08484024473147518\n    eval_far       : 0.08484393099777715\n    eval_thr       : 0.8081523776054382\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000596\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.96it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.002086\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:06,  5.96it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.001112\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.97it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.001004\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000344\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 22\n    loss           : 0.01246744185438288\n    grad norm      : 1.2680279780249817\n    accuracy       : 0.9957386363636364\n    dev_loss       : 0.031701075832934716\n    dev_accuracy   : 0.9909105534105535\n    dev_eer        : 0.016959698510521207\n    dev_frr        : 0.016875981161695447\n    dev_far        : 0.017043415859346968\n    dev_thr        : 0.008265232667326927\n    eval_loss      : 0.3396867667304846\n    eval_accuracy  : 0.9050151549169286\n    eval_eer       : 0.07694659176905685\n    eval_frr       : 0.0769544527532291\n    eval_far       : 0.07693873078488463\n    eval_thr       : 0.9412559866905212\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000203\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:40,  5.93it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000063\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.91it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000147\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.91it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.000072\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.03it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.001664\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 23\n    loss           : 0.011127472597285984\n    grad norm      : 1.1318416792480157\n    accuracy       : 0.9973169191919192\n    dev_loss       : 0.041413739412435153\n    dev_accuracy   : 0.9901866151866152\n    dev_eer        : 0.024012691521918032\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.024085037674919266\n    dev_thr        : 0.018870171159505844\n    eval_loss      : 0.4201627408546263\n    eval_accuracy  : 0.8883868432869331\n    eval_eer       : 0.07802267079315658\n    eval_frr       : 0.07804214819850441\n    eval_far       : 0.07800319338780877\n    eval_thr       : 0.9927460551261902\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.002314\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000617\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:07<01:07,  5.92it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.000536\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.98it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000119\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.04it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000809\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:14<00:00,  5.92it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.75it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.76it/s]\n    epoch          : 24\n    loss           : 0.018764789218333345\n    grad norm      : 2.0615594546910905\n    accuracy       : 0.9941603535353535\n    dev_loss       : 0.06778526700368784\n    dev_accuracy   : 0.9802123552123552\n    dev_eer        : 0.024674262766297212\n    dev_frr        : 0.024725274725274724\n    dev_far        : 0.0246232508073197\n    dev_thr        : 0.22817474603652954\n    eval_loss      : 0.4188147610225913\n    eval_accuracy  : 0.8825914907947912\n    eval_eer       : 0.09133769666374383\n    eval_frr       : 0.09136641740312712\n    eval_far       : 0.09130897592436053\n    eval_thr       : 0.9818019270896912\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000680\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [00:33<01:39,  5.96it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000661\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [01:06<01:07,  5.89it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000123\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [01:40<00:33,  5.95it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.033384\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [02:13<00:00,  6.06it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.060100\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [02:13<00:00,  5.93it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:19<00:00,  9.74it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [03:48<00:00,  9.75it/s]\n    epoch          : 25\n    loss           : 0.023774369478493523\n    grad norm      : 2.393639507740524\n    accuracy       : 0.9917929292929293\n    dev_loss       : 0.039789366710240665\n    dev_accuracy   : 0.9858161733417438\n    dev_eer        : 0.02040770560107789\n    dev_frr        : 0.02040816326530612\n    dev_far        : 0.02040724793684966\n    dev_thr        : 0.18079498410224915\n    eval_loss      : 0.3677723252374295\n    eval_accuracy  : 0.8760804894476875\n    eval_eer       : 0.08375035497871873\n    eval_frr       : 0.08375254928619986\n    eval_far       : 0.0837481606712376\n    eval_thr       : 0.9817836880683899\nSaving checkpoint: saved/models/exp10_hints_lin/1214_000114/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 train.py -c /kaggle/input/exp12/exp12.json","metadata":{"execution":{"iopub.status.busy":"2023-12-14T08:36:21.479392Z","iopub.execute_input":"2023-12-14T08:36:21.480243Z","iopub.status.idle":"2023-12-14T13:12:03.210773Z","shell.execute_reply.started":"2023-12-14T08:36:21.480210Z","shell.execute_reply":"2023-12-14T13:12:03.209763Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"RawNet2(\n  (sinc_block): SincBlock(\n    (sinc_filters): SincConv()\n    (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.1)\n  )\n  (resblocks1): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=128, out_features=128, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (resblocks2): Sequential(\n    (0): ResBlock(\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (down): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (2): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (3): ResBlock(\n      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (leaky_relu): LeakyReLU(negative_slope=0.1)\n      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (max_pool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n      (fms): FMS(\n        (fc): Linear(in_features=512, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (gru): GRU(512, 512, batch_first=True, dropout=0.1, bidirectional=True)\n  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcrazy_ocean\u001b[0m (\u001b[33mcrazy_ocean_ahead\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231214_083632-yby1n83i\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-durian-15\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/crazy_ocean_ahead/cm_project/runs/yby1n83i\u001b[0m\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 1 [0/794 (0%)] Loss: 0.650352\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:16<03:36,  2.75it/s]Train Epoch: 1 [198/794 (25%)] Loss: 0.173444\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:28<02:24,  2.75it/s]Train Epoch: 1 [396/794 (50%)] Loss: 0.136766\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:40<01:12,  2.74it/s]Train Epoch: 1 [594/794 (75%)] Loss: 0.008872\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:53<00:00,  2.76it/s]Train Epoch: 1 [792/794 (100%)] Loss: 0.036223\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:53<00:00,  2.71it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 1\n    loss           : 0.05514593750257233\n    grad norm      : 2.3860580418447053\n    accuracy       : 0.9816919191919192\n    dev_loss       : 0.07902252995256248\n    dev_accuracy   : 0.9714848777348777\n    dev_eer        : 0.034934179434794536\n    dev_frr        : 0.034929356357927786\n    dev_far        : 0.034939002511661287\n    dev_thr        : 0.21705852448940277\n    eval_loss      : 0.1379986776161954\n    eval_accuracy  : 0.9424955096542433\n    eval_eer       : 0.07085842606942852\n    eval_frr       : 0.0708361658735554\n    eval_far       : 0.07088068626530165\n    eval_thr       : 0.32225316762924194\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 2 [0/794 (0%)] Loss: 0.044218\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 2 [198/794 (25%)] Loss: 0.085938\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:24,  2.75it/s]Train Epoch: 2 [396/794 (50%)] Loss: 0.006558\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.74it/s]Train Epoch: 2 [594/794 (75%)] Loss: 0.117696\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 2 [792/794 (100%)] Loss: 0.003579\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.15it/s]\n    epoch          : 2\n    loss           : 0.031847232114582444\n    grad norm      : 1.1976089333137028\n    accuracy       : 0.9902146464646465\n    dev_loss       : 0.14159238572709473\n    dev_accuracy   : 0.9526892964904373\n    dev_eer        : 0.04050705112714954\n    dev_frr        : 0.04042386185243328\n    dev_far        : 0.040590240401865804\n    dev_thr        : 0.6572253108024597\n    eval_loss      : 0.3730444727565041\n    eval_accuracy  : 0.9021525594970813\n    eval_eer       : 0.07301058411762798\n    eval_frr       : 0.07301155676410605\n    eval_far       : 0.07300961147114993\n    eval_thr       : 0.9104900360107422\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 3 [0/794 (0%)] Loss: 0.004694\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 3 [198/794 (25%)] Loss: 0.013803\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 3 [396/794 (50%)] Loss: 0.001666\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.74it/s]Train Epoch: 3 [594/794 (75%)] Loss: 0.036130\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 3 [792/794 (100%)] Loss: 0.002192\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 3\n    loss           : 0.020180869239148438\n    grad norm      : 1.0338378640061074\n    accuracy       : 0.9935290404040404\n    dev_loss       : 0.2782771128433659\n    dev_accuracy   : 0.9298584298584298\n    dev_eer        : 0.08163082240431156\n    dev_frr        : 0.08163265306122448\n    dev_far        : 0.08162899174739864\n    dev_thr        : 0.0010638564126566052\n    eval_loss      : 0.22105697063717353\n    eval_accuracy  : 0.935515828474145\n    eval_eer       : 0.07246471767467427\n    eval_frr       : 0.07246770904146839\n    eval_far       : 0.07246172630788016\n    eval_thr       : 0.002196486806496978\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 4 [0/794 (0%)] Loss: 0.011862\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 4 [198/794 (25%)] Loss: 0.003127\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:24,  2.75it/s]Train Epoch: 4 [396/794 (50%)] Loss: 0.002519\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.74it/s]Train Epoch: 4 [594/794 (75%)] Loss: 0.001239\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 4 [792/794 (100%)] Loss: 0.000451\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.16it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.16it/s]\n    epoch          : 4\n    loss           : 0.019730991841546103\n    grad norm      : 0.7850124560051945\n    accuracy       : 0.9936868686868687\n    dev_loss       : 0.07781674230934854\n    dev_accuracy   : 0.9808558558558559\n    dev_eer        : 0.04041734893841614\n    dev_frr        : 0.04042386185243328\n    dev_far        : 0.040410836024398995\n    dev_thr        : 0.002685560379177332\n    eval_loss      : 0.1413402693003431\n    eval_accuracy  : 0.9628002918724742\n    eval_eer       : 0.055913627800883985\n    eval_frr       : 0.05588035350101971\n    eval_far       : 0.05594690210074826\n    eval_thr       : 0.04518929123878479\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 5 [0/794 (0%)] Loss: 0.001417\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:36,  2.75it/s]Train Epoch: 5 [198/794 (25%)] Loss: 0.001241\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 5 [396/794 (50%)] Loss: 0.000964\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.75it/s]Train Epoch: 5 [594/794 (75%)] Loss: 0.000387\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 5 [792/794 (100%)] Loss: 0.003197\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.14it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 5\n    loss           : 0.01891333203262419\n    grad norm      : 0.8390938497590598\n    accuracy       : 0.99447601010101\n    dev_loss       : 0.0707506443736402\n    dev_accuracy   : 0.974501287001287\n    dev_eer        : 0.023945414880367978\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.02395048439181916\n    dev_thr        : 0.008941229432821274\n    eval_loss      : 0.08699374677731309\n    eval_accuracy  : 0.9664907947911989\n    eval_eer       : 0.04688726416488796\n    eval_frr       : 0.0469068660774983\n    eval_far       : 0.046867662252277634\n    eval_thr       : 0.08100873976945877\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 6 [0/794 (0%)] Loss: 0.020381\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 6 [198/794 (25%)] Loss: 0.020945\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 6 [396/794 (50%)] Loss: 0.022529\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:12,  2.74it/s]Train Epoch: 6 [594/794 (75%)] Loss: 0.001040\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 6 [792/794 (100%)] Loss: 0.000322\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.10it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 6\n    loss           : 0.009429259294517\n    grad norm      : 0.3872544441661431\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.03714981562320101\n    dev_accuracy   : 0.9891409266409267\n    dev_eer        : 0.018439819829563026\n    dev_frr        : 0.018445839874411302\n    dev_far        : 0.01843379978471475\n    dev_thr        : 0.004890012089163065\n    eval_loss      : 0.12307377982941155\n    eval_accuracy  : 0.9624635159407274\n    eval_eer       : 0.041875177489359365\n    eval_frr       : 0.04187627464309993\n    eval_far       : 0.0418740803356188\n    eval_thr       : 0.3489781320095062\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 7 [0/794 (0%)] Loss: 0.000843\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:36,  2.75it/s]Train Epoch: 7 [198/794 (25%)] Loss: 0.000393\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 7 [396/794 (50%)] Loss: 0.000825\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:13,  2.73it/s]Train Epoch: 7 [594/794 (75%)] Loss: 0.022674\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 7 [792/794 (100%)] Loss: 0.018586\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.15it/s]\n    epoch          : 7\n    loss           : 0.011213457435863374\n    grad norm      : 0.4795585910606226\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.052237071192807266\n    dev_accuracy   : 0.980815637065637\n    dev_eer        : 0.024343477144107624\n    dev_frr        : 0.02433281004709576\n    dev_far        : 0.024354144241119483\n    dev_thr        : 0.2840864360332489\n    eval_loss      : 0.3229708287745842\n    eval_accuracy  : 0.9126206780422093\n    eval_eer       : 0.06719143817402459\n    eval_frr       : 0.0671651937457512\n    eval_far       : 0.06721768260229799\n    eval_thr       : 0.8703961372375488\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 8 [0/794 (0%)] Loss: 0.002524\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 8 [198/794 (25%)] Loss: 0.000630\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:24,  2.75it/s]Train Epoch: 8 [396/794 (50%)] Loss: 0.000204\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.74it/s]Train Epoch: 8 [594/794 (75%)] Loss: 0.013314\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:48<00:00,  2.76it/s]Train Epoch: 8 [792/794 (100%)] Loss: 0.003014\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.16it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:32<00:00,  8.17it/s]\n    epoch          : 8\n    loss           : 0.014185038780484282\n    grad norm      : 0.46999554595594867\n    accuracy       : 0.9962121212121212\n    dev_loss       : 0.02581274936608473\n    dev_accuracy   : 0.991192084942085\n    dev_eer        : 0.013820051494970762\n    dev_frr        : 0.013736263736263736\n    dev_far        : 0.01390383925367779\n    dev_thr        : 0.19707703590393066\n    eval_loss      : 0.261572336534341\n    eval_accuracy  : 0.925965424337674\n    eval_eer       : 0.04799465091260312\n    eval_frr       : 0.04799456152277362\n    eval_far       : 0.04799474030243261\n    eval_thr       : 0.9211680889129639\nSaving current best: model_best.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 9 [0/794 (0%)] Loss: 0.001513\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 9 [198/794 (25%)] Loss: 0.000228\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 9 [396/794 (50%)] Loss: 0.000187\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.75it/s]Train Epoch: 9 [594/794 (75%)] Loss: 0.000102\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 9 [792/794 (100%)] Loss: 0.000269\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 9\n    loss           : 0.011828313000469187\n    grad norm      : 0.416181774884627\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.05475900222976039\n    dev_accuracy   : 0.9853201415701416\n    dev_eer        : 0.023900563786001278\n    dev_frr        : 0.023940345368916798\n    dev_far        : 0.023860782203085754\n    dev_thr        : 0.0022839743178337812\n    eval_loss      : 0.16964395443312313\n    eval_accuracy  : 0.9553631567130669\n    eval_eer       : 0.05248435193788956\n    eval_frr       : 0.05248130523453433\n    eval_far       : 0.0524873986412448\n    eval_thr       : 0.1747991293668747\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 10 [0/794 (0%)] Loss: 0.000459\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.73it/s]Train Epoch: 10 [198/794 (25%)] Loss: 0.002684\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 10 [396/794 (50%)] Loss: 0.002055\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.73it/s]Train Epoch: 10 [594/794 (75%)] Loss: 0.039001\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 10 [792/794 (100%)] Loss: 0.082684\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:50<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 10\n    loss           : 0.01053718591782569\n    grad norm      : 0.3753159284389418\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.0319733168992698\n    dev_accuracy   : 0.9901866151866152\n    dev_eer        : 0.015743086172118927\n    dev_frr        : 0.015698587127158554\n    dev_far        : 0.015787585217079295\n    dev_thr        : 0.1503039300441742\n    eval_loss      : 0.2873675381029215\n    eval_accuracy  : 0.9269757521329143\n    eval_eer       : 0.04337435347475613\n    eval_frr       : 0.0433718558803535\n    eval_far       : 0.04337685106915876\n    eval_thr       : 0.9631814360618591\nSaving checkpoint: saved/models/exp12_no_hints/1214_083626/checkpoint-epoch10.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 11 [0/794 (0%)] Loss: 0.014900\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 11 [198/794 (25%)] Loss: 0.000149\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 11 [396/794 (50%)] Loss: 0.000126\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:12,  2.74it/s]Train Epoch: 11 [594/794 (75%)] Loss: 0.002918\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 11 [792/794 (100%)] Loss: 0.002088\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 11\n    loss           : 0.011877251090151152\n    grad norm      : 0.4732990851978574\n    accuracy       : 0.9966856060606061\n    dev_loss       : 0.03161713628473422\n    dev_accuracy   : 0.9903072715572716\n    dev_eer        : 0.017268058585527445\n    dev_frr        : 0.01726844583987441\n    dev_far        : 0.01726767133118048\n    dev_thr        : 0.029019178822636604\n    eval_loss      : 0.2172632960690044\n    eval_accuracy  : 0.9466911764705882\n    eval_eer       : 0.041997946971016054\n    eval_frr       : 0.04201223657375935\n    eval_far       : 0.04198365736827275\n    eval_thr       : 0.8634153008460999\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 12 [0/794 (0%)] Loss: 0.001223\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 12 [198/794 (25%)] Loss: 0.000538\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 12 [396/794 (50%)] Loss: 0.000587\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.74it/s]Train Epoch: 12 [594/794 (75%)] Loss: 0.000368\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 12 [792/794 (100%)] Loss: 0.001732\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 12\n    loss           : 0.007841528809490917\n    grad norm      : 0.4053156547003774\n    accuracy       : 0.9968434343434344\n    dev_loss       : 0.03422647096906902\n    dev_accuracy   : 0.9900659588159588\n    dev_eer        : 0.018439819829563026\n    dev_frr        : 0.018445839874411302\n    dev_far        : 0.01843379978471475\n    dev_thr        : 0.025983940809965134\n    eval_loss      : 0.24267713572328073\n    eval_accuracy  : 0.941793893129771\n    eval_eer       : 0.05193848549493584\n    eval_frr       : 0.05193745751189667\n    eval_far       : 0.05193951347797501\n    eval_thr       : 0.7300644516944885\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 13 [0/794 (0%)] Loss: 0.002655\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 13 [198/794 (25%)] Loss: 0.053656\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 13 [396/794 (50%)] Loss: 0.000807\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.74it/s]Train Epoch: 13 [594/794 (75%)] Loss: 0.000168\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 13 [792/794 (100%)] Loss: 0.060428\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 13\n    loss           : 0.01007258034409497\n    grad norm      : 0.4123870112111256\n    accuracy       : 0.9965277777777778\n    dev_loss       : 0.0706532644477799\n    dev_accuracy   : 0.9741795366795367\n    dev_eer        : 0.025913300651882847\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.025923932543954073\n    dev_thr        : 0.014814630150794983\n    eval_loss      : 0.12217274144627271\n    eval_accuracy  : 0.9507605523125281\n    eval_eer       : 0.06270173714873814\n    eval_frr       : 0.06267845003399049\n    eval_far       : 0.0627250242634858\n    eval_thr       : 0.16327758133411407\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 14 [0/794 (0%)] Loss: 0.006609\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 14 [198/794 (25%)] Loss: 0.000591\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:24,  2.75it/s]Train Epoch: 14 [396/794 (50%)] Loss: 0.001204\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.74it/s]Train Epoch: 14 [594/794 (75%)] Loss: 0.000674\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 14 [792/794 (100%)] Loss: 0.000185\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.11it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:34<00:00,  8.13it/s]\n    epoch          : 14\n    loss           : 0.004759221276624958\n    grad norm      : 0.21424052258130313\n    accuracy       : 0.9984217171717171\n    dev_loss       : 0.043617687733300756\n    dev_accuracy   : 0.9886180823680824\n    dev_eer        : 0.01225022798719554\n    dev_frr        : 0.01216640502354788\n    dev_far        : 0.0123340509508432\n    dev_thr        : 0.3539736270904541\n    eval_loss      : 0.4465608299808864\n    eval_accuracy  : 0.9279159182757072\n    eval_eer       : 0.04225131286523327\n    eval_frr       : 0.042284160435078176\n    eval_far       : 0.04221846529538837\n    eval_thr       : 0.997377872467041\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 15 [0/794 (0%)] Loss: 0.000075\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 15 [198/794 (25%)] Loss: 0.000028\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 15 [396/794 (50%)] Loss: 0.023900\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.73it/s]Train Epoch: 15 [594/794 (75%)] Loss: 0.000137\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.75it/s]Train Epoch: 15 [792/794 (100%)] Loss: 0.000445\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 15\n    loss           : 0.006688439207099498\n    grad norm      : 0.2091457861025272\n    accuracy       : 0.9981060606060606\n    dev_loss       : 0.053391679532091486\n    dev_accuracy   : 0.9880952380952381\n    dev_eer        : 0.03343163256856937\n    dev_frr        : 0.033359497645211934\n    dev_far        : 0.0335037674919268\n    dev_thr        : 0.006555591244250536\n    eval_loss      : 0.34840702939286716\n    eval_accuracy  : 0.9351706331387517\n    eval_eer       : 0.05576737752651574\n    eval_frr       : 0.0557443915703603\n    eval_far       : 0.055790363482671176\n    eval_thr       : 0.8863402009010315\nSaving checkpoint: saved/models/exp12_no_hints/1214_083626/checkpoint-epoch15.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 16 [0/794 (0%)] Loss: 0.005778\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:38,  2.73it/s]Train Epoch: 16 [198/794 (25%)] Loss: 0.001087\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 16 [396/794 (50%)] Loss: 0.000258\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.74it/s]Train Epoch: 16 [594/794 (75%)] Loss: 0.000032\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 16 [792/794 (100%)] Loss: 0.006408\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 16\n    loss           : 0.00643972252708574\n    grad norm      : 0.3397969713107085\n    accuracy       : 0.9979482323232324\n    dev_loss       : 0.02859314201321425\n    dev_accuracy   : 0.9913127413127413\n    dev_eer        : 0.020009643337338248\n    dev_frr        : 0.020015698587127158\n    dev_far        : 0.020003588087549335\n    dev_thr        : 0.048899322748184204\n    eval_loss      : 0.20838311486419575\n    eval_accuracy  : 0.9461860125729681\n    eval_eer       : 0.045004125872713435\n    eval_frr       : 0.04500339904826649\n    eval_far       : 0.04500485269716039\n    eval_thr       : 0.7493782043457031\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 17 [0/794 (0%)] Loss: 0.002486\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 17 [198/794 (25%)] Loss: 0.000093\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 17 [396/794 (50%)] Loss: 0.000420\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:12,  2.74it/s]Train Epoch: 17 [594/794 (75%)] Loss: 0.000472\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 17 [792/794 (100%)] Loss: 0.000363\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.15it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 17\n    loss           : 0.004929643552061705\n    grad norm      : 0.22623413399031217\n    accuracy       : 0.998895202020202\n    dev_loss       : 0.04253038875891958\n    dev_accuracy   : 0.987733268983269\n    dev_eer        : 0.018837882093302668\n    dev_frr        : 0.018838304552590265\n    dev_far        : 0.01883745963401507\n    dev_thr        : 0.00451216334477067\n    eval_loss      : 0.2617525679282483\n    eval_accuracy  : 0.944207453973956\n    eval_eer       : 0.05545922311597153\n    eval_frr       : 0.05547246770904147\n    eval_far       : 0.0554459785229016\n    eval_thr       : 0.5211986899375916\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 18 [0/794 (0%)] Loss: 0.000058\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 18 [198/794 (25%)] Loss: 0.002287\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 18 [396/794 (50%)] Loss: 0.000043\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:12,  2.75it/s]Train Epoch: 18 [594/794 (75%)] Loss: 0.000067\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 18 [792/794 (100%)] Loss: 0.001246\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:50<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.13it/s]\n    epoch          : 18\n    loss           : 0.008231294687507813\n    grad norm      : 0.47545990491911505\n    accuracy       : 0.9974747474747475\n    dev_loss       : 0.03414579951897086\n    dev_accuracy   : 0.9902670527670527\n    dev_eer        : 0.017666120849267088\n    dev_frr        : 0.017660910518053376\n    dev_far        : 0.017671331180480802\n    dev_thr        : 0.00996958278119564\n    eval_loss      : 0.18847639161405624\n    eval_accuracy  : 0.9519533004041311\n    eval_eer       : 0.04486570252924904\n    eval_frr       : 0.04486743711760707\n    eval_far       : 0.044863967940891016\n    eval_thr       : 0.6316184997558594\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 19 [0/794 (0%)] Loss: 0.001345\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:36,  2.75it/s]Train Epoch: 19 [198/794 (25%)] Loss: 0.006369\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 19 [396/794 (50%)] Loss: 0.000065\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.73it/s]Train Epoch: 19 [594/794 (75%)] Loss: 0.010213\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 19 [792/794 (100%)] Loss: 0.000591\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 19\n    loss           : 0.008009105159792605\n    grad norm      : 0.38135287405263324\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.02810571905844613\n    dev_accuracy   : 0.990696053247194\n    dev_eer        : 0.01649435960523151\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016505202726946538\n    dev_thr        : 0.06245332583785057\n    eval_loss      : 0.28090671527565864\n    eval_accuracy  : 0.9306522227211496\n    eval_eer       : 0.05043930950953908\n    eval_frr       : 0.0504418762746431\n    eval_far       : 0.050436742744435055\n    eval_thr       : 0.9074775576591492\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 20 [0/794 (0%)] Loss: 0.033156\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 20 [198/794 (25%)] Loss: 0.000062\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 20 [396/794 (50%)] Loss: 0.000083\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:13,  2.74it/s]Train Epoch: 20 [594/794 (75%)] Loss: 0.000168\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 20 [792/794 (100%)] Loss: 0.099566\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.14it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 20\n    loss           : 0.0055200876678683395\n    grad norm      : 0.31666034797113624\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.0321696222387627\n    dev_accuracy   : 0.9911518661518661\n    dev_eer        : 0.01649435960523151\n    dev_frr        : 0.016483516483516484\n    dev_far        : 0.016505202726946538\n    dev_thr        : 0.008026236668229103\n    eval_loss      : 0.2102865846952399\n    eval_accuracy  : 0.9528654018859453\n    eval_eer       : 0.04024540509140206\n    eval_frr       : 0.040244731475186944\n    eval_far       : 0.04024607870761717\n    eval_thr       : 0.7775550484657288\nSaving checkpoint: saved/models/exp12_no_hints/1214_083626/checkpoint-epoch20.pth ...\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 21 [0/794 (0%)] Loss: 0.000094\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 21 [198/794 (25%)] Loss: 0.000080\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 21 [396/794 (50%)] Loss: 0.000198\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:13,  2.74it/s]Train Epoch: 21 [594/794 (75%)] Loss: 0.000397\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 21 [792/794 (100%)] Loss: 0.000355\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.12it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.14it/s]\n    epoch          : 21\n    loss           : 0.005198227571340933\n    grad norm      : 0.3979583875584237\n    accuracy       : 0.9982638888888888\n    dev_loss       : 0.04924822344152396\n    dev_accuracy   : 0.9866071428571429\n    dev_eer        : 0.011784889081905843\n    dev_frr        : 0.011773940345368918\n    dev_far        : 0.01179583781844277\n    dev_thr        : 0.002675432711839676\n    eval_loss      : 0.14129016813701337\n    eval_accuracy  : 0.9644701392007184\n    eval_eer       : 0.03969171171754449\n    eval_frr       : 0.039700883752549286\n    eval_far       : 0.03968253968253968\n    eval_thr       : 0.25427836179733276\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 22 [0/794 (0%)] Loss: 0.000300\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 22 [198/794 (25%)] Loss: 0.000090\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 22 [396/794 (50%)] Loss: 0.000285\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:37<01:12,  2.74it/s]Train Epoch: 22 [594/794 (75%)] Loss: 0.000187\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 22 [792/794 (100%)] Loss: 0.000302\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.13it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.15it/s]\n    epoch          : 22\n    loss           : 0.004388260918913698\n    grad norm      : 0.19148083152531675\n    accuracy       : 0.9984217171717171\n    dev_loss       : 0.043033999725413635\n    dev_accuracy   : 0.9896637709137709\n    dev_eer        : 0.025890875104699493\n    dev_frr        : 0.025902668759811617\n    dev_far        : 0.02587908144958737\n    dev_thr        : 0.006466659717261791\n    eval_loss      : 0.24717016386297014\n    eval_accuracy  : 0.9433093848226314\n    eval_eer       : 0.05028523230426697\n    eval_frr       : 0.05030591434398368\n    eval_far       : 0.05026455026455026\n    eval_thr       : 0.7464317083358765\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 23 [0/794 (0%)] Loss: 0.000129\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:36,  2.75it/s]Train Epoch: 23 [198/794 (25%)] Loss: 0.000662\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:24,  2.75it/s]Train Epoch: 23 [396/794 (50%)] Loss: 0.000021\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:12,  2.74it/s]Train Epoch: 23 [594/794 (75%)] Loss: 0.001229\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 23 [792/794 (100%)] Loss: 0.000060\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.14it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.15it/s]\n    epoch          : 23\n    loss           : 0.008553024047978627\n    grad norm      : 0.4868204258790215\n    accuracy       : 0.9971590909090909\n    dev_loss       : 0.07578404874462084\n    dev_accuracy   : 0.9818613256113257\n    dev_eer        : 0.02162431793948017\n    dev_frr        : 0.021585557299843013\n    dev_far        : 0.02166307857911733\n    dev_thr        : 0.001656308420933783\n    eval_loss      : 0.17691621346596054\n    eval_accuracy  : 0.955335092052088\n    eval_eer       : 0.05190717777132042\n    eval_frr       : 0.05193745751189667\n    eval_far       : 0.05187689803074418\n    eval_thr       : 0.2282203733921051\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 24 [0/794 (0%)] Loss: 0.000188\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:36,  2.75it/s]Train Epoch: 24 [198/794 (25%)] Loss: 0.000219\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.74it/s]Train Epoch: 24 [396/794 (50%)] Loss: 0.074718\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:13,  2.74it/s]Train Epoch: 24 [594/794 (75%)] Loss: 0.000233\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 24 [792/794 (100%)] Loss: 0.000185\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.15it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.16it/s]\n    epoch          : 24\n    loss           : 0.004875897900634263\n    grad norm      : 0.3137863038050133\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.04192516068177818\n    dev_accuracy   : 0.9899855212355212\n    dev_eer        : 0.021977529108853117\n    dev_frr        : 0.02197802197802198\n    dev_far        : 0.02197703623968425\n    dev_thr        : 0.01405942253768444\n    eval_loss      : 0.16443832052742102\n    eval_accuracy  : 0.9545492815446789\n    eval_eer       : 0.04215202417628815\n    eval_frr       : 0.04214819850441876\n    eval_far       : 0.04215584984815754\n    eval_thr       : 0.6257127523422241\ntrain:   0%|                                            | 0/794 [00:00<?, ?it/s]Train Epoch: 25 [0/794 (0%)] Loss: 0.000785\ntrain:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 198/794 [01:12<03:37,  2.74it/s]Train Epoch: 25 [198/794 (25%)] Loss: 0.000337\ntrain:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 396/794 [02:24<02:25,  2.73it/s]Train Epoch: 25 [396/794 (50%)] Loss: 0.000976\ntrain:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 594/794 [03:36<01:13,  2.73it/s]Train Epoch: 25 [594/794 (75%)] Loss: 0.000612\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792/794 [04:49<00:00,  2.76it/s]Train Epoch: 25 [792/794 (100%)] Loss: 0.000042\ntrain: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 794/794 [04:49<00:00,  2.74it/s]\ndev: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 777/777 [01:35<00:00,  8.14it/s]\neval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2227/2227 [04:33<00:00,  8.15it/s]\n    epoch          : 25\n    loss           : 0.0032794982825171152\n    grad norm      : 0.17128527238188931\n    accuracy       : 0.9987373737373737\n    dev_loss       : 0.039662149668138025\n    dev_accuracy   : 0.9898648648648649\n    dev_eer        : 0.014526473833716644\n    dev_frr        : 0.014521193092621664\n    dev_far        : 0.014531754574811625\n    dev_thr        : 0.0007514334283769131\n    eval_loss      : 0.1092187622634745\n    eval_accuracy  : 0.9732122810956444\n    eval_eer       : 0.03140442638429356\n    eval_frr       : 0.03140720598232495\n    eval_far       : 0.03140164678626217\n    eval_thr       : 0.19506531953811646\nSaving checkpoint: saved/models/exp12_no_hints/1214_083626/checkpoint-epoch25.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}